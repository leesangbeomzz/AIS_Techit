{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954434002924965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "result_ori = -(10/16 * np.log2(10/16)) - (6/16 * np.log2(6/16))\n",
    "print(result_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7489992230622807\n"
     ]
    }
   ],
   "source": [
    "# R1 영역\n",
    "result1 = (8/16) * -((7/8) * np.log2(7/8) + (1/8) * np.log2(1/8))\n",
    "\n",
    "# R2 영역\n",
    "result2 = (8/16) * -((5/8) * np.log2(5/8) + (3/8) * np.log2(3/8))\n",
    "\n",
    "result_split = result1 + result2\n",
    "print(result_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20543477986268432\n"
     ]
    }
   ],
   "source": [
    "# 따라서 정보획등량은\n",
    "print(result_ori - result_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9402859586706311\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터에 대한 Entropy\n",
    "result = -((9/14) * np.log2(9/14) + (5/14) * np.log2(5/14))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8921589282623617\n"
     ]
    }
   ],
   "source": [
    "# Wind 영역\n",
    "result_wind_weak = 8/14 * (-6/8 * np.log2(6/8) - 2/8 * np.log2(2/8))\n",
    "result_wind_strong = 6/14 * (-3/6 * np.log2(3/6) - 3/6 * np.log2(3/6))\n",
    "\n",
    "result_wind = result_wind_weak + result_wind_strong\n",
    "print(result_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6935361388961918\n"
     ]
    }
   ],
   "source": [
    "# Outlook 영역\n",
    "result_outlook_sunny = 5/14 * (-2/5 * np.log2(2/5) - 3/5 * np.log2(3/5))\n",
    "result_outlook_overcast = 4/14 * (-4/4 * np.log2(4/4) )\n",
    "result_outlook_rain = 5/14 * (-3/5 * np.log2(3/5) - 2/5 * np.log2(2/5))\n",
    "\n",
    "result_outlook = result_outlook_sunny + result_outlook_overcast + result_outlook_rain\n",
    "print(result_outlook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7884504573082896\n"
     ]
    }
   ],
   "source": [
    "# Humidity 영역\n",
    "result_humidity_high = 7/14 * (-3/7 * np.log2(3/7) - 4/7 * np.log2(4/7))\n",
    "result_humidity_normal = 7/14 * (-6/7 * np.log2(6/7) - 1/7 * np.log2(1/7))\n",
    "\n",
    "result_humidity = result_humidity_high + result_humidity_normal\n",
    "print(result_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind 정보량은 : 0.04812703040826949\n",
      "Outlook 정보량은 : 0.24674981977443933\n",
      "Himidity 정보량은 : 0.15183550136234159\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터를 Wind로 분류했을때 우리가 얻을 수 있는 정보량은\n",
    "print(f'Wind 정보량은 : {result - result_wind}')\n",
    "\n",
    "# 전체 데이터를 outlook으로 분류했을때 우리가 얻을 수 있는 정보량은\n",
    "print(f'Outlook 정보량은 : {result - result_outlook}')\n",
    "\n",
    "# 전체 데이터를 습도(himidity)로 분류 했을때 우리가 얻을 수 있는 정보량은\n",
    "print(f'Himidity 정보량은 : {result - result_humidity}')\n",
    "\n",
    "# 따라서 정보획등량은 가장 많은 outlook으로 분류하는게 좋아요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at C:\\Users\\lee_0\\AppData\\Local\\Temp\\matplotlib-s69hzaet because the default path (C:\\Users\\lee_0\\.matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "# 이런 Decision Tree를 사용하려면 어떻게 해야 하나요?\n",
    "# sklearn을 이용해서 사용하면 되요!\n",
    "\n",
    "# iris 예제를 이용해서 Decision Tree를 구현해 보아요!\n",
    "# column을 2개만 사용할꺼예요. 꽃받침의 길이와 꽃잎의 길이만 사용할꺼예요!\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Loading\n",
    "iris = load_iris()\n",
    "\n",
    "# DataFrame으로 변환해서 처리하는게 쉽고 편해요!\n",
    "df = pd.DataFrame(iris.data,\n",
    "                  columns=iris.feature_names)\n",
    "\n",
    "df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "df['target'] = iris.target\n",
    "\n",
    "# 결측치와 이상치는 없다고 가정하고 진행!\n",
    "# 중복데이터 처리\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 이제 x_data와 t_data를 추출하면 될 거 같아요!\n",
    "# x_data는 4개의 feature\n",
    "x_data = df.drop(['target', 'sepal_width', 'petal_width'],\n",
    "                 axis=1,\n",
    "                 inplace=False).values\n",
    "t_data = df['target'].values\n",
    "\n",
    "# 데이터 분리보다 정규화를 먼저 진행하는게 조금 더 편해요!\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# 데이터 분리\n",
    "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data_norm,\n",
    "                 t_data,\n",
    "                 test_size=0.3,\n",
    "                 stratify=t_data,\n",
    "                 random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmh0lEQVR4nO3deXxU5aH/8c8zM8lkTyAhC2tQkMVWLbigdUGrFhWFFotUe91aUVv12uW2tvba5dd7a9tbf7bFqpSq6E9UrL1CERRc0KrVgghC2feQhOzbZJlkZp7fH3MShyUQMpNkAt/365UXZ848c85zmOR8z3me55xjrLWIiIi4+roCIiISHxQIIiICKBBERMShQBAREUCBICIiDk9fV6Azu2t32lLfvr6uhpzgmpuaqX/3Y6afPwGA369cxVlXXtDHtRLp3LlDLzTd/WzcBkJNSxV76nb1dTXkBNdY30jZhrVMH5sKwMdr15D7+aF9XCuRzp079MJuf1ZNRiIiAigQRETEoUAQEREgjvsQRET6irGGVDLwurwYut1H22MsFn/ITyP1WBO72w8pEEREDpJKBhkpGeCyxGEegAVvyAtN4KMuZotVk5GIyEG8Lm/8hgGE6+Wy4XrGkAJBROQgBhO/YdDOEPPmLAWCiIgACgQRkbj04cp/8rVLbub6i27k2T8+1yvrVCCIiMSZYDDIww/8gV8/9d/MX/Fn3lj8Fru37enx9WqUkYhIFO649rvU1jYdMj8rK4XH/vLbbi1z09otDBkxmMHDBwNwydWTeXf5exSOHhFVXY9GgSAiEoXa2iZOuePhQ+Zvfezebi+zsqyS3MG5Ha8HFQxi09rN3V5eV6nJSEREAAWCiEjcycnLobykvON1RWkFOXnZPb5eBYKISJwZe/oY9u0uprSolLbWNt7820o+f9l5Pb5e9SGIiMQZj8fNvT+/m+/deB+hYIgrZ05h5CmFPb/eHl+DiMhxLCsr5bAdyFlZKVEtd9LF5zDp4nOiWsaxUiCIiEShu0NL45H6EEREBFAgiIiIQ4EgIiKAAkFERBwKBBERARQIIiJx6cH/+A3TJl7LzZd/o9fWqUAQEYlDV1z7RX4z/5e9uk4FgohIDNRW1/GT235EXU1sHnp/+jmnkZ6ZHpNldZUCQUQkBla8uJRA0VaWL1za11XpNgWCiEiUaqvrWLV0Bb+bUcCqpStidpbQ2xQIIiJRWvHiUq4eZRidl8TVo0y/PUtQIIiIRKH97OCGiRkA3DAxo9+eJcQkEIwxTxhjyo0xGzp5f7Ixps4Ys9b5eSAW6xUR6WvtZwfZaeF7hWaneWJylvCzu/+Lb375HvbuLOLaSbN45YVlsajuEcXqbqdPAXOAp49Q5u/W2qkxWp+ISFxY9/4a3ipp4blPSg6YP7ByDV+5/avdXu5P/nB/tFU7ZjEJBGvtO8aYwlgsS0SkP/nF/N/0dRVipjf7EM41xqwzxiwzxpx6uALGmNnGmNXGmNUvPfO/vVg1ERHprQfkrAFGWGt9xpgrgZeB0QcXstbOBeYCfLx/ld1StbGXqiciIr1yhmCtrbfW+pzppUCCMSanN9YtIiJd0yuBYIzJN8YYZ/psZ71VvbFuERHpmpg0GRljngMmAznGmH3AT4AEAGvtY8C1wJ3GmADQDMyy1tpYrFtERGIjVqOMjji2ylo7h/CwVBER6YLyknL+6zu/oqayBmMMV3/1Kq699cs9us7e6lQWEZFj4Pa4+daP7+CUz4ymydfEbVffyZkXTKRw9IgeW6cCQUQkSh+s/CcvLXiJ0qL9FAzLZ8b1M5g0+eyolpmdm012bjYAKWkpjDh5OBX7KxUIIiLx6oOV/+RPj8+lcNpgho/8DLW7GvjT43MBog6FdqVF+9m2cTvjzxgbk+V1Rje3ExGJwksLXqJw2mAGjsrE5XYxcFQmhdMG89KCl2Ky/KbGZh6482fc/cA3SU1PjckyO6NAEBGJQmnRfrJGHvhks6yR6ZQW7Y962YG2AA/c8VMunf4FLpxyQdTLOxoFgohIFAqG5VO7q+GAebW7GigYlh/Vcq21/OoH/8OIUSO47hvXRrWsrlIgiIhEYcb1M9i9qITq7XWEgiGqt9exe1EJM66fEdVy16/ewPK/vs6af3zM16+4na9fcTsfvPVhjGp9eOpUFhGJQnvH8UsLXmJL0R4KhuVz2+2zo+5QPu2sz/L27tdjUcUuUyCIiERp0uSzYzaiqC+pyUhERAAFgojIISwW4v1ua9apZwwpEEREDuIP+SFk4jcULBAy4XrGkPoQREQO0kg9NIHX5cVg+ro6h7BY/CF/uJ4xpEAQETmINRYfdfji9QwB6ImcUpORiIgACgQREXEoEEREBFAgiIiIQ4EgIiKAAkFERBwKBBERARQIIiLiUCCIiAigQBAREYcCQUREAAWCiIg4FAgiIgLEKBCMMU8YY8qNMRs6ed8YY35vjNlujPnEGDMhFusVEZHYidUZwlPAlCO8fwUw2vmZDTwao/WKiEiMxCQQrLXvANVHKDINeNqGfQBkGWMKYrFuERGJjd56QM4QoCji9T5nXmkvrV9EHGvf/YRXFy6noqSSQYNzmDLzcs44/7S+rpbEgbh6YpoxZjbhJiXu//UP+cyVY/q4RiLHh/YQKN5ZQktrCyO/OISzbhtH3W4fLzy5EEChIL0WCMXAsIjXQ515B7DWzgXmAny8f5XdUrWxd2onchxb++4nvPDkQgqnF5DsKqC5roXiZRWk5aeQ/7kcmA6vLlyuQJBeG3a6GLjRGW00Caiz1qq5SKQXvLpwOYXTCxhwcgbBUICsMekMn5bL7jfDx2SZhWlUlFT2cS0lHsTkDMEY8xwwGcgxxuwDfgIkAFhrHwOWAlcC24Em4JZYrFdEjq6ipJLCwnEAeBISCPqDpI1IpqmiBYC63T4GDc4B1L9wootJIFhrv3qU9y3wrVisS0SOzaDBOdTt9jHg5AwyBmZQU1mNv7aN5EFJ1OyoZ/fLpVx3y8wDmpYKC9W/cCLSlcoix7kpMy9n98ul1OyoJynZi6shkT0vlNNaHKRmRTPX3TKTM84/7YCmJZfbxYCTMyicXsCrC5f39SZIL4mrUUYiEnvtR/evLlzO1pIiBg3O4fb/uO2Qo/7IpqV2mYVpbC0pQk4MCgSR40hnfQDtP5Flnnl4wQFlIpuW2kX2L8jxT4Eg0g8dbscPHLUP4Ej9BFNmXh6enh4+M6jb7evoX5ATgwJBJA50ZXTP0S4uMy1uCmcVdBzhDzg545BrDCL7CQ4uc9/vv9dRpr1pqb1/QU4MCgSRHtTZjj5yvtfrxU8zp8wa0aUj+2RXAU21LRQt2Y+fZrJPzSL/8oGsf3wbpxWedMD6D+4DOFo/QWTTkpx4NMpIpIe078QHXJbMWT8Zx4DLknnhyYX89fFFB8z32TqyLkzGm5fQ6eieyCP7tmAbaSO9DJ+eS/WGBtwZhmCKn1AgRN1u3wF1OLgPoL2f4Ehl5MSlQBDpIZ0N41zx8hukj09my8u7WHn/KuqLm0g/OYX66vqOzx589XBFSSWZhWnhF9ZiQ5BWmIS/shVPkpvWhgAer6djeGkoGOq4xqC9fwEOHILaWRk5canJSOQY7Nu7nwfv+Z8jNgElpyYRClhKi0o544ujafIlkJKWDIR39I21TZSurWD4tFzSRiSz/qGd1O1oJDU/qWM9nR3Zh9v+Da11AVpr2/DmJFK/s4niZVUkuBO57paZR+wDONwQVPUTSDsFgkgXLftgIx+t3cDpd405oK1/5792seqfqyicXkBuzki2/G0HFR/WYrFsmr+bQWdlkjkmjcTERGydC3eiiyFXZJNxUgoAQ7+YQ9GyCvIuyKLIFuGvCFK1soF/u/NrHeuOHAGU4EnAV9nEnpfKCDaFKF1WTcEZg3Dt8XapD0D9BNIZBYJIFz28aCVZY9M6Ruj461tpbPax6JklZA5PxV/fStnOcnx7mhl16xA8yW6a9rdQ9nYNCRkeAulBdj1fisftITHdQ6AliNvrJmNUKtkTW9i9sAxvViLetARc/gP/NCOP7It3lnaMMjrp8qERw0Ov7vX/Ezm+KBBEumjX/mqSPhs+qt//cSXbXt3D8C/nMoQgLtxsW7SHVl8rI68vIL0wmcZ9LWSNTcO4Xex8rpSBJ2cy4qIhFL1ehrvJSzAhhL+tmVAoRHJeEgNHZzLpu6cDULOj/pBbUh/u4rJVP9ukZh+JGQWCSBeNzB/Ittpwx+/uN4sZPi2XlMFemitaSB7kZfi0XP71h10k5STQXObHWkugJUTmKSkkpHiY9N3TCQVDFK+oZP/y6nATU+Egtr27k/L36xg9ZUTHuo52ywg1+0hPUCCIdNG90yZzw0MLqNlRT2NFM8l5ibTWtpGRlUFjbSPJeYkA1G5uJGt8KokJCdiQpXaDj4TU8J9a3W4fw04ZwimnjmbFH9+gpbEFDORPzAk/rMahoaDSFxQIIo6/Pr6IFS+Hd9Jut4fM7AxCwRBpIRcnZyWz8PV/ctr4sdSsaCLoC1G/uZnBp+d1jCAq/aScoD/I/jer8WZ6SB2WRMPOJvYtqcBfHeDdX3yEy+/hwssvYNU/V3HGN8eQWZhG2cYqNj67ne3L9nLS5UMp21jF5gW7cPk9PHjP/+iZBNJrFAhywoocKgpQW1vD6FuHEmwJse+1CtIvSiBn+ADK3qjg9icX0lrpJzEpmTt+MRtmhu8b5M9vIxS0lG2uZP/KGtzJbvIvHsi+VyrxV4bfy588gMyxqQRroGplA6vfWUPhrAIyClOpLK4gb/wguAE2P7Wb0reqDukw1jMJpLfowjQ5IR18FXHGxQkkZicQag1R9vdqRlybx8DT0mlo8NHqDTJ8Zi4DT0nBO9LNc39+AYDrbplJzYpm3r1vDcUrKhlyeTbphSkkZSdyyuyheHMSGHfHCIZcMojktGRGfb6QU2aNoLy0nMzCNHw1Pmjz01DTQN74bFJSUxhy0mDOvPtURl0xXM8kkF6nMwQ5obSfFWzfsIOTvjq443YRyYO9jJiRR8mySloqW0kbnoRxGYwb/DWt1G0MUbWjmTFXDyJhSEbHzeDOOP80vn7xnYy9YzjB1iBZp6aw9+Uyhk3LpaW6taOfoWljG/Uf7MRaS6uvjXVzNxN0tZKZZKhrqcYdSoSWELvW7aJtwCDKVlfgq28kLSMVA+xbV8Frjyzu6/8+6Qdm/fGmbn9WgSAnjMgbxLl3u8gYm0xNZTUwEJfL4Bngprncjzc7kbptTaTkJ2KDlsLr8mnY1kj5B3VUbmokw+OmZl8rwUCQVn8roWCQ6k0NDBiXSvZZmbi8bna9sJ/W+gA1nzSSNy6H5roKzplZSMWOepJ3hCjb30DhlAxGj01l2+ZGdr9az7y7r+PhRStJ+lwKoQFQV59AZkY6rhoYWpHEk1+b3Nf/hXKcUyDICSPy3kKpg5JpLmslZbCX+up6XI0etj1XRLAlREKah+1PFpN+cjLGbfCkumkuauGUrxXgzfCw/cUyGotbWPCfTzLppAJosRS9XI5vRxreAQn4a9poqw9g/FC5pBq7u43TrhxCxY56di4q48dfuoz/fuJl3CuqWLmwhOEDvAxs8nD2uBHcy2S+u2AR3nMTGTc2mU2bqmh+z092WyJVdY1kZ6b29X+jHMfUhyAnjMgbxBVeMoS9i8ppKvHT1tKKvzSIp96QGHRTt96HN+iiZXMz9evqqfqonrzJA0kbn4Y7z0vu5AF4E2Dzui3858wLyBmUyrApObRVt1G1up626jaGTckhLy+dp+79Kvl1ybz6s3U0LG3g17OupriskpvOSOb5azJY9qUknr8mg5vOSGb+kve4YtJ4zi8YRsuSclb/ZjctS8oZ6Pfg9dcwf8l7ffw/KMc7nSFIv7F+5Toq1+3E7e7ecYyrJcSGeVtIHuAFIDXVy+Y/7qXNFyAvO4tHZl/LzEs+B8BDzy6H4o949ONq2kalUr+5ifrNTbhchmBrAFfA0lhdzbaickYPGURlip9xM/NpDVoS3YbaPX6GDhnEFZPGs2nHPqjYz9QzxnDFpPE8+uKb7Nvfwv9dWc/AZBfVzU0MGpDB0LKt3HjVeWzftYe/3zKEnDQPW8r8XPXnIhbdMpS7l63ipqmf11mC9BgFgsStgx8uk5ucwfIfzer28q4encf3n/8bIy7KoiHRz4jWLHY2uxjgT2Dxr+/s2NFW1vpY8vYqFs5M57U9PhLOyaQ2PZHWYIikRA/BkgbSqls4ZyB8+6EX2Lu3nJbyNkbOyid7WBJVRS3sXFFJky+BrXvLWfL2Kh79cg53Lgnv0Bf/9q6OwPnOhZk89E4dDJnId264nIeeXc7UUS5y0sJ/mq9s8nH9ZzxkJ7YydZSL+Uve4zs36FbV0jPUZCRx6XAPl1m9dgPLPtjYreVV1vqY9/I7/Pjqy9jxbDEf/2obO54t5vyCYYc0xzz9yvsdO+V7z8pkz5IKmoobcYeCVO6sp2ZFFfeekcCdZyexcdtOkkI+AhUB3nmsmAX/sYV3HismUBEgy9XED+a8yNRRLsbkepk6ysUjL77F1d99hP9940OuGpPEjCeLmDo2iSVvr6KqrpGVa7ayYL2fMx8p54zf72fOezV8cZSHhqYWbpyQ2lFOpCfoDEHi0uGe/TtgbBoPL1rJFZPGH/Pynn7lfWr2F7Fl11AKPIaXZw9l9qJGNm3bxbyIo/fszFRWrtlKSbmfBevLAfA1hKh8tpTMJIPPb3n80iSuGJVICMusU92sLnORm5jJxZNO5613/sHFF5zLa+99TErIx9qN2/nV7OEA3DghlQsef59MTxsFGYm8sglqGltZstHH1FEe5i95j8W/vaujzu1nEZ8fn9kxT2cJ0pMUCBKXDvfs36SsRHatrz7mZbU3AT365RymP/M+t05MY0yul4uG1PBRcYAfvdLExcPTOna07Tvlyloftz/4/8j3tzEhuYhrx7mZt6aVby1p4juvtWBDFrAkelzcOgleWv4PXrg+h+sW/IMhqZbGtjbGZhuWbPTxndxwv4XX+vnx+V6+tbSJdcVN/OHKJO5eVkNGehrDy7YesKM/OJjaDT6onEisKBAkLh34hLCwltpWRuUPPOZltTcBZae48Vo/V56cSlsgxJUjgyza0EKGFwh6WfL2gZ22T7/yPvv37aGkpoU/3ZZOQZqbH16UwNIdPp795T388HfPsnBmOjlpHv7Pa+V8YVgbI7LcfGFYG69saWPhV5K4fUkLv/t7NU9/0kZ9k59po1yMyU1kwlDDZ/PcXDUhny2+T/sQIkWeLYj0BvUhSFw63LN/azb7uHfa5GNaTvvZwY0TUnl6dR03fDYBd7CFrXvLGJrh4tKTXJw/3MNb2xu5eDg88uJbzLjvsY7O4In5MH2Mm0Ep4T+VgjQ313/Gwx0PPt3Rz1DpC/DW9kZu/Vwi+8pruO5UN0keGJKZyFdOTWLC0BS+fMnZFOZmcP+UYQwYMJBqn58rRwYJBEPqG5C4Yay10S/EmCnA7wA3MM9a++BB798M/AYodmbNsdbOO9IyP96/ym6p6l4HohwfYjHKqL0d/qoxSZz7h90MzXDT1GZpbA1hLaQmQmGWm9Py3Sza7iI1OZmkYAN5Qwu5JN/H0vWV7KoJ0NRmcLlMeKEWmtpCjMzPwuUyVDc0M21UiNsmegkEQhgsi7cGaPDD1WMT+Lf/bSE1NYNbJnjDo4pWVkFrE9eflgAJKeRnZxww0kgkKufdbbr70agDwRjjBrYClwH7gFXAV621GyPK3Aycaa3t8jmwAkEOtvyRxTxxjLdvuOa7cygpr6S4sp6ClBAljS4SXJaRAxMoqQ/w7l0jyM9IoNIXYMZz9VTVN/Hjc0P86E0/799T2PHezIUNvPibe8nOTOWhZ5ezZMXbTL3sIr5zw+Ud6wCob2yBQCsZSYbBGQks/sZwHnqnjqc/acNjQgAUVzbgIjztdrvIHZAOwODcHDUTSfSiCIRY9CGcDWy31u4EMMY8D0wDtDeXPrf4t3exZU8ZU771INkpLqqaQ1x/ZjaDUqC2vgHamoEEctI8XFDQwgf+FvbUe5h1qptQaxOQSU6ap2N0z41XnXfY6wraRYZDiR/OfCTcITw8Tzt7iX+xCIQhQOSz/vYB5xym3AxjzIWEzya+ba095PmAxpjZwGyAe358N0Mn5sWgenK8aKht6Nbn7nvkL4zNNvgDlrHZhvX7fLhchn21QZ5cW8agAc0AlFX5GJvj4r09QfbUBZm/roy87JaOpqLBZVsBIq4raDlkCKh2+tKf9dYoo78Bz1lr/caY24H5wCUHF7LWzgXmAny09Cm7da3u3SKfunTKxGP+zJY9ZazduJ1h6fD41CRmL2lhX3ULy+8YyehBiR1t940trdRufocHL0shwWVoC1nuW9FE1riz+M9bpwLhDuqZ3/8dC2eGm3hunJDKzIW6nYQcP2IRCMXAsIjXQ/m08xgAa21VxMt5wK+PttCJ405mYlb3jghF2rWfHVw60s0p2S6mjfGwdFsbZz28i8K8TDxuF4PLtrK3rJqm+gBv7/n0d66+xZJSuqYjECKvYAYOaEpSZ7AcD2IRCKuA0caYkYSDYBZwfWQBY0yBtbbUeXkNsCkG6xU5qtWb9uIKBPnBeYlsKA9xZoGb33/YyrAMw41Xnc+NV53H7Q/+PwqyM6lwOn3bZXhhcO6n1z3oQjE53kUdCNbagDHmLuA1wsNOn7DW/ssY83NgtbV2MXCPMeYaIABUAzdHu16Rrvj2rC9Qu+VdxuZBfpqbkvoAM8YHSUpOYcnbq2hsaaVmf1HHiKEjUf+AHO9ich1Cj9j1d0vp2r6uhfRzV/z779iwbTeDUly4XFDXHCJkLePzk7hwVDpPfNTIy/82iDuXNHUMKxXp16IYdqorlSWuVdb6mHHfY92+iveys8fx7cm5rPneybw6ewTDsjwsvj6NP30piytPDt9bKCf1074AkROZAkHiWvtdSru7s468nfTZc4o5PQ+MCV9A5gm2cMNnE5i/qla3jxBBTUYSx9qHeT46NSUmTTpduaJYt4+Qfk9NRnI8ah/m2f5wmcizhO40JS3+7V2sfuanrH7mp4wdOZSMzAzwplPiT+LMR8pZsN7PyjVbe2JTRPoF3f5a4lLkYyzh0IvAIpuSunNErxFDIofSGYLEpSNdBBb5wBu1+4vEjs4QJC4d6SIwOPL9hESke9SpLP1K5P2E2h9OE3lrapETnjqV5URxpKYkEYmOmoykX9H9hER6jgJB+hWNDhLpOWoyEhERQIEgIiKOuG0yevqDUl5/Y31fV0NEpF95+rzufzZuA2H02V/AP+TMvq6GiMgJQ01GIiICKBBERMQRt01GcuL55V1fxedrOGR+Wlo6P5zzXJfLiEj3KBAkbvh8DZz0jT8cMn/nvLuPqYyIdI+ajEREBNAZgvQzdVWVFO/edtj57e655hwCoUNv2uhxGX6/+MMerZ9If6ZAkD5zcH9AdVkp1b+8DmyQxIxBHfP9Nfu5/+apAAQCbZj03I73jAnf2DEYDHTMC4QsI+56+pD17ZlzY8y3QeR4okCQXhUZAjWV5eTP+gUAbrcbj99PYu5ISuffy8Cp38OGQgDsf+6H+FrCO3wbbKNswQ8ACNRXYlzhVk9rQ3xz6tkABFv9FD3574esO9TW2rMbJ9LPKRCkV+3ZthHj8QJgQ0GCgfCOPtjWCsYQavNjgwFCbX48A4c4n7IEAm3OtCHoq+5YXu514UCxwTYSs4cBsO/RWym46WHnoyHaG4/2zbmx40xDo5JEDqVAkN7l9jD0W/MBKJ1/L4m5IwFoLd8JGFwJXow7/GvpSggHh3G5GXzrHABKnrjrgOnEnOHhz5ftxHgSD1mdBYz5dOxE+wgljUoSOZQCQXpEZMeuDQax7c9wsuHmHQBrbUezUHjPbcPvRfkUPxsMUDr/3o51RM7/ZM6dAAQaKg/3UZETmgJBekRkx25z+V4ScsLNOUV/+NoBR+ztfQA4ncOR77WzNkRr5d6O16E2/6fvtQdKBOP2kHf9rw6ZX/zY1xl888PAoR3MuuBNRIEgMRS5Uw2FgjSXh3fiNhQ4bHlXYnLHkXygPnzEblwubChI2cIH8GTkhAtaSHD6B3C5D2wacoKk419HojcJgFZ/S0TTU+eX3eiCN5EYBYIxZgrwO8ANzLPWPnjQ+17gaWAiUAVcZ63dHYt1S/yI3KnWPvyNjrOC1vJdB5RrH+2T+5WfYTwJABT/8WYS07MZfPPD+Cv3UvLM9w/4jA1EjBBymoGMx0vpk+EddrCxFuNytxfA75xRBANt4HJ+zQ9z9iEin4o6EIwxbuAR4DJgH7DKGLPYWrsxotjXgRpr7ShjzCzgV8B10a5b+h8bDFAy97bwdCgYsRMHd1IKJU/dS5uvGrAd7fw2GGD/M98FINhYQ/GjN3d8vuPMIBRgYF4BEL5IbUjhaAD2bt9EQlY+AK6ktI6gcCkcRA4RizOEs4Ht1tqdAMaY54FpQGQgTAN+6kz/BZhjjDHWRtl7KP2OJyOHCffOA+CjB69j4n0vHFJm57y7+a+nlnS8vv/mqZ0250SWiyzfzu3xkJAYbjLyeBI6gsKfnRPdhogch2IRCEOAoojX+4BzOitjrQ0YY+qAbOCAoR7GmNnAbIDv/+K3jLpgegyqJ33BlZhEyRN3AeGj+o4j+WCwo13e4zKHbaNPS0uPat1paekdy62rqiTkjGoyNtQxP9p1iByP4qpT2Vo7F5gL8I8dVXZDcV0f10i664xvzumY7uxIvqsid/AHzz+c7owKOtZ1iByPYhEIxcCwiNdDnXmHK7PPGOMBMgl3LstxpKd2qr0x7FNDS0ViEwirgNHGmJGEd/yzgOsPKrMYuAn4B3At8Kb6D44/2qmK9G9RB4LTJ3AX8BrhYadPWGv/ZYz5ObDaWrsY+DPwjDFmO1BNODRERCSOxKQPwVq7FFh60LwHIqZbgK/EYl0iItIzNBhbREQABYKIiDgUCCIiAigQRETEoUAQERFAgSAiIg4FgoiIAAoEERFxKBBERARQIIiIiEOBICIigAJBREQcCgQREQEUCCIi4lAgiIgIoEAQERGHAkFERAAFgoiIOBQIIiICKBBERMShQBAREUCBICIiDgWCiIgACgQREXEoEEREBFAgiIiIQ4EgIiKAAkFERBxRBYIxZqAxZoUxZpvz74BOygWNMWudn8XRrFNERHpGtGcI9wFvWGtHA284rw+n2Vp7hvNzTZTrFBGRHhBtIEwD5jvT84HpUS5PRET6SLSBkGetLXWm9wN5nZRLMsasNsZ8YIyZ3tnCjDGznXKrX35+fmfFRESkB3iOVsAY8zqQf5i37o98Ya21xhjbyWJGWGuLjTEnAW8aY9Zba3ccXMhaOxeYC/CPHVV2Q3HdUTdARERi46iBYK29tLP3jDFlxpgCa22pMaYAKO9kGcXOvzuNMSuBzwGHBIKIiPSdaJuMFgM3OdM3AYsOLmCMGWCM8TrTOcDngY1RrldERGIs2kB4ELjMGLMNuNR5jTHmTGPMPKfMOGC1MWYd8BbwoLVWgSAiEmeO2mR0JNbaKuALh5m/GviGM/0+8Nlo1iMiIj1PVyqLiAigQBAREYcCQUREAAWCiIg4FAgiIgIoEERExKFAEBERQIEgIiIOBYKIiAAKBBERcSgQREQEUCCIiIhDgSAiIoACQUREHAoEEREBFAgiIuJQIIiICKBAEBERhwJBREQABYKIiDgUCCIiAigQRETEoUAQERFAgSAiIg4FgoiIAAoEERFxKBBERARQIIiIiEOBICIiAHj6ugKdSfN6yElP7OtqiIicMIy1tq/rcFjGmNnW2rl9XY+eou3r37R9/dfxvG0Q3fbFc5PR7L6uQA/T9vVv2r7+63jeNohi++I5EEREpBcpEEREBIjvQDhu2/gc2r7+TdvXfx3P2wZRbF/cdiqLiEjviuczBBER6UUKBBERAeIoEIwxXzHG/MsYEzLGnHmEclOMMVuMMduNMff1Zh2jYYwZaIxZYYzZ5vw7oJNyQWPMWudncW/X81gd7fswxniNMS84739ojCnsg2p2Wxe272ZjTEXEd/aNvqhndxhjnjDGlBtjNnTyvjHG/N7Z9k+MMRN6u47R6ML2TTbG1EV8dw/0dh27yxgzzBjzljFmo7Pf/PfDlDn2789aGxc/wDhgDLASOLOTMm5gB3ASkAisA8b3dd27uH2/Bu5zpu8DftVJOV9f1/UYtumo3wfwTeAxZ3oW8EJf1zvG23czMKev69rN7bsQmABs6OT9K4FlgAEmAR/2dZ1jvH2TgSV9Xc9ublsBMMGZTge2HuZ385i/v7g5Q7DWbrLWbjlKsbOB7dbandbaVuB5YFrP1y4mpgHznen5wPS+q0rMdOX7iNzuvwBfMMaYXqxjNPrz79tRWWvfAaqPUGQa8LQN+wDIMsYU9E7toteF7eu3rLWl1to1znQDsAkYclCxY/7+4iYQumgIUBTxeh+H/ifEqzxrbakzvR/I66RckjFmtTHmA2PM9N6pWrd15fvoKGOtDQB1QHav1C56Xf19m+Gckv/FGDOsd6rWK/rz31tXnWuMWWeMWWaMObWvK9MdTjPs54APD3rrmL+/Xr25nTHmdSD/MG/db61d1Jt16QlH2r7IF9Zaa4zpbLzvCGttsTHmJOBNY8x6a+2OWNdVYuZvwHPWWr8x5nbCZ0OX9HGdpGvWEP578xljrgReBkb3bZWOjTEmDXgJuNdaWx/t8no1EKy1l0a5iGIg8ghsqDMvLhxp+4wxZcaYAmttqXPaVt7JMoqdf3caY1YSTv54DYSufB/tZfYZYzxAJlDVO9WL2lG3z1obuS3zCPcVHS/i+u8tWpE7UGvtUmPMH40xOdbayr6sV1cZYxIIh8Gz1tq/HqbIMX9//a3JaBUw2hgz0hiTSLiTMu5H4jgWAzc50zcBh5wRGWMGGGO8znQO8HlgY6/V8Nh15fuI3O5rgTet0+PVDxx1+w5qk72GcFvu8WIxcKMzWmUSUBfR7NnvGWPy2/uzjDFnE94f9ouDFafefwY2WWsf6qTYsX9/fd1bHtEj/iXCbVx+oAx4zZk/GFh6UM/5VsJHzff3db2PYfuygTeAbcDrwEBn/pnAPGf6PGA94dEs64Gv93W9u7Bdh3wfwM+Ba5zpJOBFYDvwT+Ckvq5zjLfvl8C/nO/sLWBsX9f5GLbtOaAUaHP+9r4O3AHc4bxvgEecbV9PJ6P/4vWnC9t3V8R39wFwXl/X+Ri27XzAAp8Aa52fK6P9/nTrChERAfpfk5GIiPQQBYKIiAAKBBERcSgQREQEUCCIiIhDgSAiIoACQUREHP8f4vO9FK5ReCkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(x_data_train_norm,\n",
    "          t_data_train)\n",
    "\n",
    "# Evaluation\n",
    "print(accuracy_score(t_data_test, model.predict(x_data_test_norm)))\n",
    "\n",
    "# 시각화\n",
    "plot_decision_regions(X=x_data_train_norm,\n",
    "                      y=t_data_train,\n",
    "                      clf=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리가 했던 데이터중에 MNIST Data가 있어요!\n",
    "# 이 데이터셋을 이용해서 다중분류작업을 수행해 볼꺼예요!\n",
    "# 3가지로 구현해 볼꺼예요!\n",
    "\n",
    "# 1. Regression을 이용해서 구현(Tensorflow로 구현, sklearn 구현)\n",
    "# 2. SVM을 이용해서 구현(sklearn으로 구현) - GridSearchCV 활용\n",
    "# 3. DecisionTreee를 이용해서 구현!\n",
    "\n",
    "# 각 모델의 정확도는 어떻게 된느지 비교해 보아요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 module import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Loading\n",
    "df = pd.read_csv(r\"C:\\Users\\lee_0\\Desktop\\코딩\\ML\\12.07\\train.csv\")\n",
    "# display(df)  # 42000 rows × 785 columns\n",
    "\n",
    "x_data = df.drop('label', axis=1, inplace=False).values\n",
    "t_data = df['label'].values\n",
    "\n",
    "# MinMaNormalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# Data Split\n",
    "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data_norm,\n",
    "                 t_data,\n",
    "                 test_size=0.3,\n",
    "                 stratify=t_data,\n",
    "                 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917063492063492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lee_0\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model(sklearn)\n",
    "logistic_model = LogisticRegression(solver='saga')\n",
    "logistic_model.fit(x_data_train_norm,\n",
    "                   t_data_train)\n",
    "logistic_result = accuracy_score(t_data_test,\n",
    "                                 logistic_model.predict(x_data_test_norm))\n",
    "\n",
    "print(logistic_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9737301587301588\n"
     ]
    }
   ],
   "source": [
    "# SVM Model(sklearn)\n",
    "svm_model = SVC()\n",
    "svm_model.fit(x_data_train_norm,\n",
    "              t_data_train)\n",
    "svm_model_result = accuracy_score(t_data_test,\n",
    "                                  svm_model.predict(x_data_test_norm))\n",
    "\n",
    "print(svm_model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8523809523809524\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree Model(sklearn)\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "decision_tree_model.fit(x_data_train_norm,\n",
    "                        t_data_train)\n",
    "decision_tree_model_result = accuracy_score(t_data_test,\n",
    "                                            decision_tree_model.predict(x_data_test_norm))\n",
    "\n",
    "print(decision_tree_model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "206/206 [==============================] - 1s 2ms/step - loss: 0.4321 - acc: 0.8735 - val_loss: 0.3085 - val_acc: 0.9107\n",
      "Epoch 2/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.2918 - acc: 0.9152 - val_loss: 0.3004 - val_acc: 0.9159\n",
      "Epoch 3/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.2773 - acc: 0.9201 - val_loss: 0.2939 - val_acc: 0.9159\n",
      "Epoch 4/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.2589 - acc: 0.9251 - val_loss: 0.2923 - val_acc: 0.9192\n",
      "Epoch 5/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.2512 - acc: 0.9278 - val_loss: 0.3001 - val_acc: 0.9170\n",
      "Epoch 6/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.2424 - acc: 0.9289 - val_loss: 0.2975 - val_acc: 0.9209\n",
      "Epoch 7/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.2413 - acc: 0.9280 - val_loss: 0.2989 - val_acc: 0.9170\n",
      "Epoch 8/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2346 - acc: 0.9302 - val_loss: 0.3089 - val_acc: 0.9173\n",
      "Epoch 9/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.2272 - acc: 0.9348 - val_loss: 0.3078 - val_acc: 0.9152\n",
      "Epoch 10/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2244 - acc: 0.9354 - val_loss: 0.3315 - val_acc: 0.9091\n",
      "Epoch 11/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2201 - acc: 0.9341 - val_loss: 0.3354 - val_acc: 0.9105\n",
      "Epoch 12/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2196 - acc: 0.9362 - val_loss: 0.3302 - val_acc: 0.9109\n",
      "Epoch 13/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2133 - acc: 0.9378 - val_loss: 0.3164 - val_acc: 0.9175\n",
      "Epoch 14/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2136 - acc: 0.9368 - val_loss: 0.3442 - val_acc: 0.9096\n",
      "Epoch 15/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2069 - acc: 0.9383 - val_loss: 0.3285 - val_acc: 0.9155\n",
      "Epoch 16/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2030 - acc: 0.9379 - val_loss: 0.3197 - val_acc: 0.9187\n",
      "Epoch 17/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2070 - acc: 0.9356 - val_loss: 0.3354 - val_acc: 0.9105\n",
      "Epoch 18/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2017 - acc: 0.9403 - val_loss: 0.3311 - val_acc: 0.9153\n",
      "Epoch 19/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2038 - acc: 0.9385 - val_loss: 0.3525 - val_acc: 0.9100\n",
      "Epoch 20/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.2042 - acc: 0.9382 - val_loss: 0.3673 - val_acc: 0.9044\n",
      "Epoch 21/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1989 - acc: 0.9406 - val_loss: 0.3427 - val_acc: 0.9127\n",
      "Epoch 22/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1945 - acc: 0.9426 - val_loss: 0.3576 - val_acc: 0.9125\n",
      "Epoch 23/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1929 - acc: 0.9424 - val_loss: 0.3620 - val_acc: 0.9098\n",
      "Epoch 24/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1936 - acc: 0.9422 - val_loss: 0.3491 - val_acc: 0.9128\n",
      "Epoch 25/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1892 - acc: 0.9442 - val_loss: 0.3545 - val_acc: 0.9110\n",
      "Epoch 26/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1892 - acc: 0.9434 - val_loss: 0.3862 - val_acc: 0.9039\n",
      "Epoch 27/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1877 - acc: 0.9422 - val_loss: 0.3849 - val_acc: 0.9046\n",
      "Epoch 28/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1869 - acc: 0.9434 - val_loss: 0.3807 - val_acc: 0.9053\n",
      "Epoch 29/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1861 - acc: 0.9436 - val_loss: 0.3693 - val_acc: 0.9129\n",
      "Epoch 30/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1830 - acc: 0.9459 - val_loss: 0.3985 - val_acc: 0.9011\n",
      "Epoch 31/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1809 - acc: 0.9459 - val_loss: 0.3763 - val_acc: 0.9085\n",
      "Epoch 32/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1787 - acc: 0.9462 - val_loss: 0.3971 - val_acc: 0.9017\n",
      "Epoch 33/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1821 - acc: 0.9448 - val_loss: 0.3752 - val_acc: 0.9102\n",
      "Epoch 34/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1797 - acc: 0.9464 - val_loss: 0.3789 - val_acc: 0.9109\n",
      "Epoch 35/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1820 - acc: 0.9462 - val_loss: 0.3924 - val_acc: 0.9082\n",
      "Epoch 36/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1784 - acc: 0.9448 - val_loss: 0.3929 - val_acc: 0.9085\n",
      "Epoch 37/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1764 - acc: 0.9460 - val_loss: 0.3792 - val_acc: 0.9112\n",
      "Epoch 38/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1760 - acc: 0.9477 - val_loss: 0.3893 - val_acc: 0.9073\n",
      "Epoch 39/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1749 - acc: 0.9468 - val_loss: 0.3886 - val_acc: 0.9110\n",
      "Epoch 40/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1770 - acc: 0.9473 - val_loss: 0.3897 - val_acc: 0.9108\n",
      "Epoch 41/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1721 - acc: 0.9480 - val_loss: 0.3956 - val_acc: 0.9105\n",
      "Epoch 42/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1719 - acc: 0.9471 - val_loss: 0.3909 - val_acc: 0.9118\n",
      "Epoch 43/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1682 - acc: 0.9502 - val_loss: 0.3977 - val_acc: 0.9119\n",
      "Epoch 44/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.1716 - acc: 0.9486 - val_loss: 0.3923 - val_acc: 0.9116\n",
      "Epoch 45/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1692 - acc: 0.9498 - val_loss: 0.4311 - val_acc: 0.9007\n",
      "Epoch 46/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1711 - acc: 0.9489 - val_loss: 0.4087 - val_acc: 0.9071\n",
      "Epoch 47/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1695 - acc: 0.9504 - val_loss: 0.4372 - val_acc: 0.8992\n",
      "Epoch 48/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1681 - acc: 0.9489 - val_loss: 0.4140 - val_acc: 0.9051\n",
      "Epoch 49/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1644 - acc: 0.9509 - val_loss: 0.4084 - val_acc: 0.9077\n",
      "Epoch 50/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1663 - acc: 0.9493 - val_loss: 0.4155 - val_acc: 0.9075\n",
      "Epoch 51/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.1670 - acc: 0.9496 - val_loss: 0.4192 - val_acc: 0.9054\n",
      "Epoch 52/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1640 - acc: 0.9512 - val_loss: 0.4180 - val_acc: 0.9049\n",
      "Epoch 53/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1672 - acc: 0.9488 - val_loss: 0.4297 - val_acc: 0.9071\n",
      "Epoch 54/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1654 - acc: 0.9508 - val_loss: 0.4276 - val_acc: 0.9059\n",
      "Epoch 55/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1629 - acc: 0.9496 - val_loss: 0.4293 - val_acc: 0.9082\n",
      "Epoch 56/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1621 - acc: 0.9495 - val_loss: 0.4511 - val_acc: 0.8984\n",
      "Epoch 57/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1669 - acc: 0.9488 - val_loss: 0.4364 - val_acc: 0.9051\n",
      "Epoch 58/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1588 - acc: 0.9518 - val_loss: 0.4295 - val_acc: 0.9043\n",
      "Epoch 59/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1612 - acc: 0.9526 - val_loss: 0.4477 - val_acc: 0.9028\n",
      "Epoch 60/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1629 - acc: 0.9513 - val_loss: 0.4321 - val_acc: 0.9078\n",
      "Epoch 61/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1637 - acc: 0.9495 - val_loss: 0.4416 - val_acc: 0.9060\n",
      "Epoch 62/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1586 - acc: 0.9517 - val_loss: 0.4536 - val_acc: 0.9019\n",
      "Epoch 63/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1593 - acc: 0.9516 - val_loss: 0.4528 - val_acc: 0.9023\n",
      "Epoch 64/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1586 - acc: 0.9512 - val_loss: 0.4372 - val_acc: 0.9062\n",
      "Epoch 65/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1591 - acc: 0.9512 - val_loss: 0.4585 - val_acc: 0.8995\n",
      "Epoch 66/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1574 - acc: 0.9537 - val_loss: 0.4451 - val_acc: 0.9082\n",
      "Epoch 67/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1587 - acc: 0.9527 - val_loss: 0.4710 - val_acc: 0.9005\n",
      "Epoch 68/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1566 - acc: 0.9527 - val_loss: 0.4692 - val_acc: 0.9026\n",
      "Epoch 69/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1551 - acc: 0.9535 - val_loss: 0.4568 - val_acc: 0.9041\n",
      "Epoch 70/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1581 - acc: 0.9528 - val_loss: 0.4731 - val_acc: 0.8988\n",
      "Epoch 71/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1589 - acc: 0.9525 - val_loss: 0.4602 - val_acc: 0.9039\n",
      "Epoch 72/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1543 - acc: 0.9521 - val_loss: 0.4581 - val_acc: 0.9063\n",
      "Epoch 73/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1536 - acc: 0.9535 - val_loss: 0.4531 - val_acc: 0.9059\n",
      "Epoch 74/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1541 - acc: 0.9532 - val_loss: 0.4819 - val_acc: 0.8991\n",
      "Epoch 75/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1512 - acc: 0.9543 - val_loss: 0.4769 - val_acc: 0.9009\n",
      "Epoch 76/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1559 - acc: 0.9538 - val_loss: 0.4795 - val_acc: 0.8995\n",
      "Epoch 77/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1570 - acc: 0.9530 - val_loss: 0.4749 - val_acc: 0.9019\n",
      "Epoch 78/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1550 - acc: 0.9532 - val_loss: 0.4863 - val_acc: 0.9007\n",
      "Epoch 79/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1522 - acc: 0.9545 - val_loss: 0.4682 - val_acc: 0.9040\n",
      "Epoch 80/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1516 - acc: 0.9529 - val_loss: 0.4769 - val_acc: 0.9033\n",
      "Epoch 81/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1508 - acc: 0.9552 - val_loss: 0.4791 - val_acc: 0.9015\n",
      "Epoch 82/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1508 - acc: 0.9531 - val_loss: 0.4809 - val_acc: 0.9027\n",
      "Epoch 83/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.1484 - acc: 0.9557 - val_loss: 0.4782 - val_acc: 0.9020\n",
      "Epoch 84/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1487 - acc: 0.9562 - val_loss: 0.4919 - val_acc: 0.8991\n",
      "Epoch 85/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1496 - acc: 0.9549 - val_loss: 0.4761 - val_acc: 0.9056\n",
      "Epoch 86/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1481 - acc: 0.9561 - val_loss: 0.4874 - val_acc: 0.9008\n",
      "Epoch 87/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1475 - acc: 0.9549 - val_loss: 0.4883 - val_acc: 0.9034\n",
      "Epoch 88/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.1459 - acc: 0.9554 - val_loss: 0.4987 - val_acc: 0.8978\n",
      "Epoch 89/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.1501 - acc: 0.9530 - val_loss: 0.4967 - val_acc: 0.9011\n",
      "Epoch 90/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.1489 - acc: 0.9538 - val_loss: 0.4994 - val_acc: 0.9019\n",
      "Epoch 91/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.1495 - acc: 0.9560 - val_loss: 0.5216 - val_acc: 0.8948\n",
      "Epoch 92/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1481 - acc: 0.9546 - val_loss: 0.5007 - val_acc: 0.9000\n",
      "Epoch 93/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1465 - acc: 0.9541 - val_loss: 0.4986 - val_acc: 0.9026\n",
      "Epoch 94/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1469 - acc: 0.9548 - val_loss: 0.5016 - val_acc: 0.9007\n",
      "Epoch 95/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1454 - acc: 0.9567 - val_loss: 0.4991 - val_acc: 0.8999\n",
      "Epoch 96/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1430 - acc: 0.9586 - val_loss: 0.4980 - val_acc: 0.9034\n",
      "Epoch 97/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1418 - acc: 0.9568 - val_loss: 0.5031 - val_acc: 0.9022\n",
      "Epoch 98/100\n",
      "206/206 [==============================] - 0s 1ms/step - loss: 0.1468 - acc: 0.9541 - val_loss: 0.5081 - val_acc: 0.9022\n",
      "Epoch 99/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1475 - acc: 0.9550 - val_loss: 0.5082 - val_acc: 0.9023\n",
      "Epoch 100/100\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 0.1447 - acc: 0.9556 - val_loss: 0.5119 - val_acc: 0.9018\n",
      "394/394 [==============================] - 0s 830us/step - loss: 0.5473 - acc: 0.8961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5473120808601379, 0.8961111307144165]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression (Tensorflow Keras)\n",
    "\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Flatten(input_shape=(784,)))\n",
    "keras_model.add(Dense(units=10,\n",
    "                      activation='softmax'))\n",
    "keras_model.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "keras_model.fit(x_data_train_norm,\n",
    "                t_data_train,\n",
    "                epochs=100,\n",
    "                batch_size=100,\n",
    "                validation_split=0.3,\n",
    "                verbose=1)\n",
    "\n",
    "keras_model.evaluate(x_data_test_norm,\n",
    "                     t_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9644444444444444\n"
     ]
    }
   ],
   "source": [
    "# KNN을 이용해서 모델구현하고 정확도를 측정해 보아요!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(x_data_train_norm,\n",
    "                        t_data_train)\n",
    "knn_model_result = accuracy_score(t_data_test,\n",
    "                                            knn_model.predict(x_data_test_norm))\n",
    "\n",
    "print(knn_model_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
