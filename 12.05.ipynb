{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at C:\\Users\\lee_0\\AppData\\Local\\Temp\\matplotlib-z4s9e1wb because the default path (C:\\Users\\lee_0\\.matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 구현\n",
    "# Wisconsin Breast Cancer Data\n",
    "\n",
    "# 필요한 module import \n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([42, 72], dtype=int64))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw Data Loading\n",
    "cancer = load_breast_cancer()\n",
    "# x_data(feature), t_data(0, 1) 데이터의 설명...\n",
    "\n",
    "# x_data => cancer.data\n",
    "# t_data => cancer.target\n",
    "# print(cancer.data.shape, cancer.target.shape)\n",
    "# (569, 30) => x_data는 총 569개의 행으로 구성, 컬럼(feature)은 30개\n",
    "# (569,) => t_data 역시 총 569개 있어요. 0과 1로 구성되어 있어요!\n",
    "\n",
    "# [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1]\n",
    "np.unique(cancer.target, return_counts=True)\n",
    "# (array([0, 1]), array([212, 357], dtype=int64))\n",
    "#                                0.37, 0.63\n",
    "# 0은 악성종양(나쁜거), 1은 양성종양(괜찮은거)\n",
    "# 약간의 데이터 불균형이 존재(imbalanced data)\n",
    "\n",
    "# 데이터셋 저장\n",
    "x_data = cancer.data\n",
    "t_data = cancer.target\n",
    "\n",
    "# boxplot을 이용해서 이상치와 데이터 분포를 간단하게 확인\n",
    "# plt.boxplot(x_data)\n",
    "# plt.show()\n",
    "\n",
    "# 데이터 정규화가 필요해요!\n",
    "# 원래 정규화는 당연히 이상치를 제거하고 진행하는게 맞아요!\n",
    "# 실제적인 이상치는 존재하지 않는다고 가정하고 진행!\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# plt.boxplot(x_data_norm)\n",
    "# plt.show()\n",
    "\n",
    "# 데이터를 분리해야 해요! 학습용과 평가용으로 분리\n",
    "# train data와 test data로 분리(데이터를 섞어서 분리)\n",
    "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data_norm,\n",
    "                 t_data,\n",
    "                 stratify=t_data,\n",
    "                 test_size=0.2,  # default값은 0.25\n",
    "                 random_state=3)\n",
    "\n",
    "# 섞어서 분리했기 때문에 데이터의 편향이 없을거라 생각되는데\n",
    "# 확인은 해야 겠죠.\n",
    "np.unique(t_data_test, return_counts=True)\n",
    "# (array([0, 1]), array([42, 72], dtype=int64)) 0.35, 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97802198 0.94505495 0.95604396 0.98901099 0.94505495]\n",
      "sklearn의 평균 validation accuracy : 0.9626373626373625\n",
      "모델의 최종 score : 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# sklearn model구현\n",
    "\n",
    "sklearn_model = linear_model.LogisticRegression()\n",
    "\n",
    "# 학습하기 전에 cross validation을 한번 수행해 볼꺼예요!\n",
    "# train data를 가지고 수행해요!\n",
    "score = cross_val_score(sklearn_model,\n",
    "                        x_data_train_norm,\n",
    "                        t_data_train,\n",
    "                        cv=5)\n",
    "\n",
    "print(score)  # [0.97802198 0.94505495 0.95604396 0.98901099 0.94505495]\n",
    "print(f'sklearn의 평균 validation accuracy : {np.mean(score)}')  # 0.9626373626373625\n",
    "\n",
    "# model 학습진행\n",
    "sklearn_model.fit(x_data_train_norm,\n",
    "                  t_data_train)\n",
    "\n",
    "# model 최종평가\n",
    "test_score = sklearn_model.score(x_data_test_norm,\n",
    "                                 t_data_test)\n",
    "print(f'모델의 최종 score : {test_score}')  # 0.9649122807017544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4817 - acc: 0.8462 - val_loss: 0.3663 - val_acc: 0.8681\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3004 - acc: 0.9093 - val_loss: 0.2792 - val_acc: 0.8791\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2492 - acc: 0.9121 - val_loss: 0.2495 - val_acc: 0.9121\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2197 - acc: 0.9011 - val_loss: 0.2574 - val_acc: 0.8791\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1996 - acc: 0.9313 - val_loss: 0.2053 - val_acc: 0.9231\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1844 - acc: 0.9368 - val_loss: 0.1929 - val_acc: 0.9121\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1721 - acc: 0.9451 - val_loss: 0.1776 - val_acc: 0.9231\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1584 - acc: 0.9533 - val_loss: 0.1814 - val_acc: 0.9121\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1550 - acc: 0.9478 - val_loss: 0.1648 - val_acc: 0.9341\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1448 - acc: 0.9615 - val_loss: 0.1524 - val_acc: 0.9560\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1361 - acc: 0.9643 - val_loss: 0.1498 - val_acc: 0.9670\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1330 - acc: 0.9505 - val_loss: 0.1401 - val_acc: 0.9670\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1276 - acc: 0.9588 - val_loss: 0.1361 - val_acc: 0.9560\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1210 - acc: 0.9670 - val_loss: 0.1318 - val_acc: 0.9560\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1165 - acc: 0.9808 - val_loss: 0.1274 - val_acc: 0.9670\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1143 - acc: 0.9725 - val_loss: 0.1232 - val_acc: 0.9670\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1092 - acc: 0.9780 - val_loss: 0.1268 - val_acc: 0.9451\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1144 - acc: 0.9615 - val_loss: 0.1183 - val_acc: 0.9560\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1040 - acc: 0.9753 - val_loss: 0.1168 - val_acc: 0.9560\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1027 - acc: 0.9808 - val_loss: 0.1163 - val_acc: 0.9451\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1003 - acc: 0.9780 - val_loss: 0.1117 - val_acc: 0.9670\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0982 - acc: 0.9808 - val_loss: 0.1080 - val_acc: 0.9670\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0958 - acc: 0.9753 - val_loss: 0.1059 - val_acc: 0.9560\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0935 - acc: 0.9780 - val_loss: 0.1025 - val_acc: 0.9670\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0918 - acc: 0.9808 - val_loss: 0.1016 - val_acc: 0.9670\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0922 - acc: 0.9753 - val_loss: 0.1007 - val_acc: 0.9670\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0899 - acc: 0.9835 - val_loss: 0.0984 - val_acc: 0.9670\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0876 - acc: 0.9780 - val_loss: 0.0974 - val_acc: 0.9670\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0891 - acc: 0.9780 - val_loss: 0.1002 - val_acc: 0.9560\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0865 - acc: 0.9780 - val_loss: 0.0994 - val_acc: 0.9670\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0831 - acc: 0.9753 - val_loss: 0.0968 - val_acc: 0.9451\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0875 - acc: 0.9780 - val_loss: 0.0961 - val_acc: 0.9670\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0816 - acc: 0.9780 - val_loss: 0.0938 - val_acc: 0.9560\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0836 - acc: 0.9835 - val_loss: 0.0932 - val_acc: 0.9670\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0788 - acc: 0.9835 - val_loss: 0.0936 - val_acc: 0.9560\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0795 - acc: 0.9808 - val_loss: 0.0923 - val_acc: 0.9670\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0822 - acc: 0.9835 - val_loss: 0.0917 - val_acc: 0.9560\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0769 - acc: 0.9835 - val_loss: 0.0893 - val_acc: 0.9670\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0760 - acc: 0.9835 - val_loss: 0.0885 - val_acc: 0.9560\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0761 - acc: 0.9835 - val_loss: 0.0883 - val_acc: 0.9560\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0752 - acc: 0.9780 - val_loss: 0.0906 - val_acc: 0.9670\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0810 - acc: 0.9808 - val_loss: 0.0884 - val_acc: 0.9670\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0720 - acc: 0.9863 - val_loss: 0.0871 - val_acc: 0.9670\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0728 - acc: 0.9863 - val_loss: 0.0856 - val_acc: 0.9560\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0721 - acc: 0.9808 - val_loss: 0.0861 - val_acc: 0.9560\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0723 - acc: 0.9835 - val_loss: 0.0832 - val_acc: 0.9670\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0737 - acc: 0.9753 - val_loss: 0.0864 - val_acc: 0.9670\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0725 - acc: 0.9808 - val_loss: 0.0830 - val_acc: 0.9670\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0753 - acc: 0.9863 - val_loss: 0.0849 - val_acc: 0.9670\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0695 - acc: 0.9780 - val_loss: 0.0859 - val_acc: 0.9670\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0725 - acc: 0.9808 - val_loss: 0.0867 - val_acc: 0.9560\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0685 - acc: 0.9863 - val_loss: 0.0844 - val_acc: 0.9670\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0696 - acc: 0.9835 - val_loss: 0.0830 - val_acc: 0.9560\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0671 - acc: 0.9863 - val_loss: 0.0826 - val_acc: 0.9670\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0725 - acc: 0.9780 - val_loss: 0.0820 - val_acc: 0.9560\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0679 - acc: 0.9808 - val_loss: 0.0819 - val_acc: 0.9670\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0706 - acc: 0.9780 - val_loss: 0.0835 - val_acc: 0.9670\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0716 - acc: 0.9725 - val_loss: 0.0819 - val_acc: 0.9670\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0700 - acc: 0.9835 - val_loss: 0.0807 - val_acc: 0.9670\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0647 - acc: 0.9835 - val_loss: 0.0807 - val_acc: 0.9560\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0649 - acc: 0.9835 - val_loss: 0.0794 - val_acc: 0.9670\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0655 - acc: 0.9835 - val_loss: 0.0799 - val_acc: 0.9670\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0643 - acc: 0.9863 - val_loss: 0.0784 - val_acc: 0.9670\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0637 - acc: 0.9835 - val_loss: 0.0790 - val_acc: 0.9670\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0631 - acc: 0.9863 - val_loss: 0.0791 - val_acc: 0.9670\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0637 - acc: 0.9835 - val_loss: 0.0786 - val_acc: 0.9670\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0662 - acc: 0.9808 - val_loss: 0.0783 - val_acc: 0.9670\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0645 - acc: 0.9835 - val_loss: 0.0802 - val_acc: 0.9560\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0651 - acc: 0.9808 - val_loss: 0.0779 - val_acc: 0.9670\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0642 - acc: 0.9753 - val_loss: 0.0790 - val_acc: 0.9670\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0651 - acc: 0.9780 - val_loss: 0.0804 - val_acc: 0.9670\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0634 - acc: 0.9808 - val_loss: 0.0816 - val_acc: 0.9670\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0626 - acc: 0.9808 - val_loss: 0.0806 - val_acc: 0.9670\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0623 - acc: 0.9808 - val_loss: 0.0796 - val_acc: 0.9670\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0649 - acc: 0.9808 - val_loss: 0.0790 - val_acc: 0.9670\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0714 - acc: 0.9753 - val_loss: 0.0795 - val_acc: 0.9670\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0621 - acc: 0.9863 - val_loss: 0.0788 - val_acc: 0.9670\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0593 - acc: 0.9863 - val_loss: 0.0789 - val_acc: 0.9670\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0599 - acc: 0.9863 - val_loss: 0.0775 - val_acc: 0.9670\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0610 - acc: 0.9808 - val_loss: 0.0798 - val_acc: 0.9670\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0657 - acc: 0.9808 - val_loss: 0.0802 - val_acc: 0.9670\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0603 - acc: 0.9835 - val_loss: 0.0795 - val_acc: 0.9670\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0585 - acc: 0.9863 - val_loss: 0.0775 - val_acc: 0.9670\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0605 - acc: 0.9808 - val_loss: 0.0781 - val_acc: 0.9670\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0584 - acc: 0.9835 - val_loss: 0.0790 - val_acc: 0.9670\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0582 - acc: 0.9863 - val_loss: 0.0784 - val_acc: 0.9670\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0655 - acc: 0.9780 - val_loss: 0.0809 - val_acc: 0.9670\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0586 - acc: 0.9863 - val_loss: 0.0794 - val_acc: 0.9670\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0573 - acc: 0.9890 - val_loss: 0.0784 - val_acc: 0.9670\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0578 - acc: 0.9835 - val_loss: 0.0790 - val_acc: 0.9670\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0582 - acc: 0.9863 - val_loss: 0.0785 - val_acc: 0.9670\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0564 - acc: 0.9835 - val_loss: 0.0783 - val_acc: 0.9670\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0613 - acc: 0.9835 - val_loss: 0.0788 - val_acc: 0.9670\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0702 - acc: 0.9698 - val_loss: 0.0796 - val_acc: 0.9670\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0567 - acc: 0.9863 - val_loss: 0.0793 - val_acc: 0.9670\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0560 - acc: 0.9808 - val_loss: 0.0800 - val_acc: 0.9670\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0567 - acc: 0.9863 - val_loss: 0.0795 - val_acc: 0.9670\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0550 - acc: 0.9890 - val_loss: 0.0800 - val_acc: 0.9670\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0569 - acc: 0.9835 - val_loss: 0.0792 - val_acc: 0.9670\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0563 - acc: 0.9890 - val_loss: 0.0795 - val_acc: 0.9670\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0562 - acc: 0.9808 - val_loss: 0.0799 - val_acc: 0.9670\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0557 - acc: 0.9863 - val_loss: 0.0785 - val_acc: 0.9670\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0546 - acc: 0.9835 - val_loss: 0.0791 - val_acc: 0.9670\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0566 - acc: 0.9863 - val_loss: 0.0802 - val_acc: 0.9670\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0556 - acc: 0.9808 - val_loss: 0.0792 - val_acc: 0.9670\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0561 - acc: 0.9863 - val_loss: 0.0802 - val_acc: 0.9670\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0551 - acc: 0.9835 - val_loss: 0.0796 - val_acc: 0.9670\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0552 - acc: 0.9808 - val_loss: 0.0796 - val_acc: 0.9670\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0545 - acc: 0.9890 - val_loss: 0.0814 - val_acc: 0.9670\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0552 - acc: 0.9863 - val_loss: 0.0811 - val_acc: 0.9670\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0548 - acc: 0.9835 - val_loss: 0.0800 - val_acc: 0.9670\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0543 - acc: 0.9890 - val_loss: 0.0797 - val_acc: 0.9670\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0588 - acc: 0.9835 - val_loss: 0.0800 - val_acc: 0.9670\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0588 - acc: 0.9863 - val_loss: 0.0794 - val_acc: 0.9670\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0577 - acc: 0.9835 - val_loss: 0.0770 - val_acc: 0.9670\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0555 - acc: 0.9835 - val_loss: 0.0771 - val_acc: 0.9670\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0549 - acc: 0.9808 - val_loss: 0.0776 - val_acc: 0.9670\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0534 - acc: 0.9863 - val_loss: 0.0777 - val_acc: 0.9670\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0530 - acc: 0.9835 - val_loss: 0.0783 - val_acc: 0.9670\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0526 - acc: 0.9835 - val_loss: 0.0796 - val_acc: 0.9670\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0559 - acc: 0.9863 - val_loss: 0.0812 - val_acc: 0.9670\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0535 - acc: 0.9835 - val_loss: 0.0816 - val_acc: 0.9670\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0523 - acc: 0.9890 - val_loss: 0.0813 - val_acc: 0.9670\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0532 - acc: 0.9890 - val_loss: 0.0813 - val_acc: 0.9670\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0568 - acc: 0.9780 - val_loss: 0.0818 - val_acc: 0.9670\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0546 - acc: 0.9835 - val_loss: 0.0813 - val_acc: 0.9670\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0514 - acc: 0.9890 - val_loss: 0.0812 - val_acc: 0.9670\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0518 - acc: 0.9890 - val_loss: 0.0813 - val_acc: 0.9670\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0522 - acc: 0.9863 - val_loss: 0.0830 - val_acc: 0.9670\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0524 - acc: 0.9890 - val_loss: 0.0834 - val_acc: 0.9670\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0516 - acc: 0.9890 - val_loss: 0.0830 - val_acc: 0.9670\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0519 - acc: 0.9863 - val_loss: 0.0841 - val_acc: 0.9670\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0532 - acc: 0.9835 - val_loss: 0.0836 - val_acc: 0.9670\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0535 - acc: 0.9863 - val_loss: 0.0823 - val_acc: 0.9670\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0511 - acc: 0.9863 - val_loss: 0.0820 - val_acc: 0.9670\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0512 - acc: 0.9835 - val_loss: 0.0832 - val_acc: 0.9670\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0516 - acc: 0.9863 - val_loss: 0.0813 - val_acc: 0.9670\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0502 - acc: 0.9863 - val_loss: 0.0812 - val_acc: 0.9670\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0501 - acc: 0.9890 - val_loss: 0.0817 - val_acc: 0.9670\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0515 - acc: 0.9835 - val_loss: 0.0818 - val_acc: 0.9670\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0529 - acc: 0.9863 - val_loss: 0.0819 - val_acc: 0.9670\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0512 - acc: 0.9863 - val_loss: 0.0813 - val_acc: 0.9670\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0499 - acc: 0.9863 - val_loss: 0.0820 - val_acc: 0.9670\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0529 - acc: 0.9863 - val_loss: 0.0833 - val_acc: 0.9670\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0505 - acc: 0.9808 - val_loss: 0.0829 - val_acc: 0.9670\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0495 - acc: 0.9890 - val_loss: 0.0838 - val_acc: 0.9670\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0502 - acc: 0.9890 - val_loss: 0.0834 - val_acc: 0.9670\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0494 - acc: 0.9890 - val_loss: 0.0846 - val_acc: 0.9670\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0556 - acc: 0.9780 - val_loss: 0.0835 - val_acc: 0.9670\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0500 - acc: 0.9890 - val_loss: 0.0836 - val_acc: 0.9670\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0488 - acc: 0.9890 - val_loss: 0.0889 - val_acc: 0.9451\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0551 - acc: 0.9780 - val_loss: 0.0851 - val_acc: 0.9670\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0497 - acc: 0.9835 - val_loss: 0.0858 - val_acc: 0.9670\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0491 - acc: 0.9890 - val_loss: 0.0850 - val_acc: 0.9670\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0514 - acc: 0.9863 - val_loss: 0.0840 - val_acc: 0.9670\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0512 - acc: 0.9890 - val_loss: 0.0829 - val_acc: 0.9670\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0505 - acc: 0.9890 - val_loss: 0.0883 - val_acc: 0.9560\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0540 - acc: 0.9863 - val_loss: 0.0872 - val_acc: 0.9670\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0499 - acc: 0.9835 - val_loss: 0.0864 - val_acc: 0.9560\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0485 - acc: 0.9890 - val_loss: 0.0829 - val_acc: 0.9670\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0484 - acc: 0.9890 - val_loss: 0.0839 - val_acc: 0.9670\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0486 - acc: 0.9863 - val_loss: 0.0843 - val_acc: 0.9670\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0501 - acc: 0.9835 - val_loss: 0.0847 - val_acc: 0.9670\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0513 - acc: 0.9835 - val_loss: 0.0884 - val_acc: 0.9560\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0492 - acc: 0.9863 - val_loss: 0.0858 - val_acc: 0.9670\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0484 - acc: 0.9863 - val_loss: 0.0852 - val_acc: 0.9670\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0484 - acc: 0.9890 - val_loss: 0.0848 - val_acc: 0.9670\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0486 - acc: 0.9890 - val_loss: 0.0851 - val_acc: 0.9670\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0475 - acc: 0.9890 - val_loss: 0.0902 - val_acc: 0.9560\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0483 - acc: 0.9890 - val_loss: 0.0894 - val_acc: 0.9670\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0536 - acc: 0.9835 - val_loss: 0.0899 - val_acc: 0.9560\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0496 - acc: 0.9835 - val_loss: 0.0867 - val_acc: 0.9670\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0484 - acc: 0.9835 - val_loss: 0.0876 - val_acc: 0.9670\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0496 - acc: 0.9890 - val_loss: 0.0873 - val_acc: 0.9670\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0554 - acc: 0.9835 - val_loss: 0.0891 - val_acc: 0.9670\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0475 - acc: 0.9890 - val_loss: 0.0894 - val_acc: 0.9670\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0500 - acc: 0.9863 - val_loss: 0.0902 - val_acc: 0.9670\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0488 - acc: 0.9890 - val_loss: 0.0898 - val_acc: 0.9670\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0466 - acc: 0.9890 - val_loss: 0.0918 - val_acc: 0.9670\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0474 - acc: 0.9890 - val_loss: 0.0899 - val_acc: 0.9670\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0514 - acc: 0.9863 - val_loss: 0.0909 - val_acc: 0.9670\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0475 - acc: 0.9863 - val_loss: 0.0904 - val_acc: 0.9670\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0477 - acc: 0.9835 - val_loss: 0.0904 - val_acc: 0.9670\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1381 - acc: 0.968 - 0s 3ms/step - loss: 0.0462 - acc: 0.9890 - val_loss: 0.0906 - val_acc: 0.9670\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0488 - acc: 0.9890 - val_loss: 0.0906 - val_acc: 0.9670\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0473 - acc: 0.9863 - val_loss: 0.0915 - val_acc: 0.9560\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0457 - acc: 0.9890 - val_loss: 0.0923 - val_acc: 0.9670\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0465 - acc: 0.9890 - val_loss: 0.0914 - val_acc: 0.9670\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0460 - acc: 0.9863 - val_loss: 0.0936 - val_acc: 0.9670\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0460 - acc: 0.9890 - val_loss: 0.0932 - val_acc: 0.9560\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0477 - acc: 0.9835 - val_loss: 0.0932 - val_acc: 0.9670\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0494 - acc: 0.9863 - val_loss: 0.0942 - val_acc: 0.9560\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0478 - acc: 0.9863 - val_loss: 0.0909 - val_acc: 0.9670\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0476 - acc: 0.9890 - val_loss: 0.0910 - val_acc: 0.9670\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0453 - acc: 0.9890 - val_loss: 0.0933 - val_acc: 0.9560\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0464 - acc: 0.9808 - val_loss: 0.0918 - val_acc: 0.9670\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0483 - acc: 0.9890 - val_loss: 0.0915 - val_acc: 0.9670\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0473 - acc: 0.9835 - val_loss: 0.0914 - val_acc: 0.9670\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0493 - acc: 0.9863 - val_loss: 0.0910 - val_acc: 0.9670\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0461 - acc: 0.9863 - val_loss: 0.0898 - val_acc: 0.9670\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0453 - acc: 0.9890 - val_loss: 0.0901 - val_acc: 0.9670\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0450 - acc: 0.9890 - val_loss: 0.0896 - val_acc: 0.9670\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0462 - acc: 0.9863 - val_loss: 0.0908 - val_acc: 0.9670\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0462 - acc: 0.9890 - val_loss: 0.0915 - val_acc: 0.9670\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0475 - acc: 0.9863 - val_loss: 0.0920 - val_acc: 0.9560\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0477 - acc: 0.9890 - val_loss: 0.0905 - val_acc: 0.9670\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0443 - acc: 0.9890 - val_loss: 0.0934 - val_acc: 0.9560\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0471 - acc: 0.9835 - val_loss: 0.0924 - val_acc: 0.9670\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0508 - acc: 0.9835 - val_loss: 0.0935 - val_acc: 0.9560\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0479 - acc: 0.9835 - val_loss: 0.0931 - val_acc: 0.9670\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0475 - acc: 0.9890 - val_loss: 0.0921 - val_acc: 0.9670\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0474 - acc: 0.9890 - val_loss: 0.0910 - val_acc: 0.9670\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0456 - acc: 0.9808 - val_loss: 0.0906 - val_acc: 0.9670\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0472 - acc: 0.9863 - val_loss: 0.0934 - val_acc: 0.9560\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0472 - acc: 0.9808 - val_loss: 0.0913 - val_acc: 0.9670\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0477 - acc: 0.9863 - val_loss: 0.0895 - val_acc: 0.9670\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0517 - acc: 0.9780 - val_loss: 0.0896 - val_acc: 0.9670\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0534 - acc: 0.9780 - val_loss: 0.0889 - val_acc: 0.9670\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0463 - acc: 0.9808 - val_loss: 0.0901 - val_acc: 0.9560\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0439 - acc: 0.9890 - val_loss: 0.0885 - val_acc: 0.9670\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0459 - acc: 0.9890 - val_loss: 0.0891 - val_acc: 0.9670\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0434 - acc: 0.9890 - val_loss: 0.0931 - val_acc: 0.9560\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0440 - acc: 0.9863 - val_loss: 0.0913 - val_acc: 0.9670\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0462 - acc: 0.9863 - val_loss: 0.0936 - val_acc: 0.9670\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0488 - acc: 0.9835 - val_loss: 0.0926 - val_acc: 0.9670\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0441 - acc: 0.9835 - val_loss: 0.0951 - val_acc: 0.9670\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0492 - acc: 0.9835 - val_loss: 0.0936 - val_acc: 0.9670\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0446 - acc: 0.9863 - val_loss: 0.0946 - val_acc: 0.9670\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0428 - acc: 0.9890 - val_loss: 0.0947 - val_acc: 0.9670\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0441 - acc: 0.9890 - val_loss: 0.0942 - val_acc: 0.9670\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0441 - acc: 0.9890 - val_loss: 0.0955 - val_acc: 0.9670\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0435 - acc: 0.9890 - val_loss: 0.0953 - val_acc: 0.9670\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0451 - acc: 0.9863 - val_loss: 0.0947 - val_acc: 0.9670\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0456 - acc: 0.9890 - val_loss: 0.0947 - val_acc: 0.9670\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0442 - acc: 0.9890 - val_loss: 0.0957 - val_acc: 0.9670\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0457 - acc: 0.9863 - val_loss: 0.0947 - val_acc: 0.9670\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0439 - acc: 0.9808 - val_loss: 0.0939 - val_acc: 0.9670\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0440 - acc: 0.9890 - val_loss: 0.0947 - val_acc: 0.9670\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0459 - acc: 0.9808 - val_loss: 0.0953 - val_acc: 0.9670\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0458 - acc: 0.9890 - val_loss: 0.0941 - val_acc: 0.9670\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0434 - acc: 0.9890 - val_loss: 0.0968 - val_acc: 0.9560\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0435 - acc: 0.9863 - val_loss: 0.0978 - val_acc: 0.9670\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0461 - acc: 0.9863 - val_loss: 0.0995 - val_acc: 0.9560\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0463 - acc: 0.9863 - val_loss: 0.0982 - val_acc: 0.9670\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0454 - acc: 0.9890 - val_loss: 0.0973 - val_acc: 0.9670\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0429 - acc: 0.9890 - val_loss: 0.0974 - val_acc: 0.9670\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0430 - acc: 0.9890 - val_loss: 0.0965 - val_acc: 0.9670\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0425 - acc: 0.9890 - val_loss: 0.0961 - val_acc: 0.9670\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0458 - acc: 0.9863 - val_loss: 0.0990 - val_acc: 0.9560\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0470 - acc: 0.9835 - val_loss: 0.0988 - val_acc: 0.9670\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0442 - acc: 0.9890 - val_loss: 0.0990 - val_acc: 0.9560\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0438 - acc: 0.9863 - val_loss: 0.0968 - val_acc: 0.9670\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0422 - acc: 0.9890 - val_loss: 0.0969 - val_acc: 0.9670\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0433 - acc: 0.9890 - val_loss: 0.0992 - val_acc: 0.9560\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0442 - acc: 0.9890 - val_loss: 0.0973 - val_acc: 0.9670\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0438 - acc: 0.9808 - val_loss: 0.0968 - val_acc: 0.9670\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0420 - acc: 0.9890 - val_loss: 0.0971 - val_acc: 0.9670\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0431 - acc: 0.9890 - val_loss: 0.0974 - val_acc: 0.9670\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0416 - acc: 0.9890 - val_loss: 0.0990 - val_acc: 0.9560\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0482 - acc: 0.9863 - val_loss: 0.0985 - val_acc: 0.9670\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0416 - acc: 0.9863 - val_loss: 0.1004 - val_acc: 0.9560\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0415 - acc: 0.9890 - val_loss: 0.0993 - val_acc: 0.9670\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0435 - acc: 0.9890 - val_loss: 0.0999 - val_acc: 0.9670\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0419 - acc: 0.9890 - val_loss: 0.1017 - val_acc: 0.9560\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0429 - acc: 0.9890 - val_loss: 0.0994 - val_acc: 0.9670\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0428 - acc: 0.9863 - val_loss: 0.1030 - val_acc: 0.9560\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0481 - acc: 0.9835 - val_loss: 0.0993 - val_acc: 0.9670\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0491 - acc: 0.9808 - val_loss: 0.0985 - val_acc: 0.9670\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0444 - acc: 0.9890 - val_loss: 0.0995 - val_acc: 0.9560\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0484 - acc: 0.9808 - val_loss: 0.0986 - val_acc: 0.9670\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0462 - acc: 0.9863 - val_loss: 0.0994 - val_acc: 0.9560\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0487 - acc: 0.9835 - val_loss: 0.0986 - val_acc: 0.9670\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0422 - acc: 0.9890 - val_loss: 0.1019 - val_acc: 0.9560\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0422 - acc: 0.9863 - val_loss: 0.0978 - val_acc: 0.9670\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0415 - acc: 0.9890 - val_loss: 0.1011 - val_acc: 0.9560\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0414 - acc: 0.9890 - val_loss: 0.0983 - val_acc: 0.9670\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0417 - acc: 0.9890 - val_loss: 0.0991 - val_acc: 0.9670\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0418 - acc: 0.9835 - val_loss: 0.0993 - val_acc: 0.9670\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0452 - acc: 0.9808 - val_loss: 0.0994 - val_acc: 0.9670\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0438 - acc: 0.9808 - val_loss: 0.1016 - val_acc: 0.9560\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0481 - acc: 0.9890 - val_loss: 0.1012 - val_acc: 0.9560\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0446 - acc: 0.9835 - val_loss: 0.1020 - val_acc: 0.9560\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0408 - acc: 0.9890 - val_loss: 0.1000 - val_acc: 0.9670\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0438 - acc: 0.9863 - val_loss: 0.1017 - val_acc: 0.9670\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0423 - acc: 0.9890 - val_loss: 0.1013 - val_acc: 0.9670\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0413 - acc: 0.9890 - val_loss: 0.1028 - val_acc: 0.9560\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0415 - acc: 0.9835 - val_loss: 0.1010 - val_acc: 0.9670\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0417 - acc: 0.9890 - val_loss: 0.1030 - val_acc: 0.9560\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0427 - acc: 0.9808 - val_loss: 0.1014 - val_acc: 0.9670\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0407 - acc: 0.9890 - val_loss: 0.1025 - val_acc: 0.9560\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0408 - acc: 0.9890 - val_loss: 0.1007 - val_acc: 0.9670\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0408 - acc: 0.9890 - val_loss: 0.1044 - val_acc: 0.9560\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0526 - acc: 0.9780 - val_loss: 0.1028 - val_acc: 0.9670\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0452 - acc: 0.9835 - val_loss: 0.1042 - val_acc: 0.9670\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0410 - acc: 0.9863 - val_loss: 0.1037 - val_acc: 0.9670\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0443 - acc: 0.9835 - val_loss: 0.1041 - val_acc: 0.9670\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0480 - acc: 0.9753 - val_loss: 0.1026 - val_acc: 0.9670\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0450 - acc: 0.9863 - val_loss: 0.1032 - val_acc: 0.9670\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0509 - acc: 0.9780 - val_loss: 0.1027 - val_acc: 0.9670\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0422 - acc: 0.9890 - val_loss: 0.1053 - val_acc: 0.9451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20bbc6edba8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow 구현\n",
    "\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(30,)))\n",
    "keras_model.add(Dense(units=1,\n",
    "                      activation='sigmoid'))\n",
    "\n",
    "# 학습할 때 매 epoch마다 validation을 수행하고\n",
    "# validation의 평가 기준은 accuracy를 사용하겠어요!\n",
    "keras_model.compile(optimizer=Adam(learning_rate=1e-1),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "keras_model.fit(x_data_train_norm,\n",
    "                t_data_train,\n",
    "                epochs=300,\n",
    "                verbose=1,\n",
    "                validation_split=0.2)\n",
    "\n",
    "# training data로 학습한 후\n",
    "# training data로 평가 vs validation data로 평가\n",
    "\n",
    "# loss : training data로 학습한 후 training data를 이용해서 계산한 loss\n",
    "# val_loss : validation data로 계산한 loss\n",
    "\n",
    "# learning_rate=1e-1\n",
    "# loss: 0.0423 - acc: 0.9890 - val_loss: 0.0983 - val_acc: 0.9670\n",
    "\n",
    "# learning_rate=1e-2\n",
    "# loss: 0.0793 - acc: 0.9808 - val_loss: 0.0947 - val_acc: 0.9560\n",
    "\n",
    "# learning_rate=1e-4\n",
    "# loss: 0.5635 - acc: 0.8489 - val_loss: 0.5667 - val_acc: 0.8352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1378 - acc: 0.9649\n",
      "[0.1377609223127365, 0.9649122953414917]\n"
     ]
    }
   ],
   "source": [
    "# 학습이 다 끝났어요!\n",
    "# Evaluation(평가)\n",
    "result = keras_model.evaluate(x_data_test_norm,\n",
    "                              t_data_test)\n",
    "\n",
    "print(result)\n",
    "# loss 값                      , accuracy 값\n",
    "# [0.13803397119045258, 0.9649122953414917]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic data를 이용한 Logistic Regression 구현\n",
    "# Kaggle에 있는 데이터를 이용\n",
    "# Kaggle에 있는 데이터를 전처리 한 후\n",
    "# 모델을 만들어서 학습을 진행\n",
    "# 자체 평가를 진행(validation)\n",
    "# 모델을 이용해서 예측값을 추출(test.csv)\n",
    "# 예측된 결과를 Kaggle에 upload해서 우리 모델의 성능을 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Loading\n",
    "df = pd.read_csv(r\"C:\\Users\\lee_0\\Desktop\\코딩\\ML\\12.05\\train.csv\")\n",
    "\n",
    "# display(df)  # 891 rows × 12 columns\n",
    "\n",
    "# 데이터 전처리!(feature engineering)\n",
    "train = df\n",
    "\n",
    "# 사용하는 column만 추출, 사용되지 않는(불필요한) column을 삭제\n",
    "# print(train.columns) \n",
    "# Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
    "# 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], dtype='object')\n",
    "# 필요없는 컬럼은(종속변수에 영향을 주지 않거나 의미상 중복 컬럼)\n",
    "\n",
    "train.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'],\n",
    "           axis=1,\n",
    "           inplace=True)\n",
    "# display(df)  # 891 rows × 7 columns\n",
    "\n",
    "# 성별처리 (male=0, female=1)\n",
    "gender_mapping = {'male' : 0,\n",
    "                  'female' : 1}\n",
    "train['Sex'] = train['Sex'].map(gender_mapping)\n",
    "# display(df)\n",
    "\n",
    "train['Falmily'] = train['SibSp'] + train['Parch']\n",
    "# display(df)  # 891 rows × 8 columns\n",
    "\n",
    "train.drop(['SibSp', 'Parch'],\n",
    "           axis=1,\n",
    "           inplace=True)\n",
    "# display(df)  # 891 rows × 6 columns\n",
    "\n",
    "# df.info()\n",
    "\n",
    "# Embarked의 결측치를 처리해 보아요!\n",
    "train['Embarked'] = train['Embarked'].fillna('Q')\n",
    "\n",
    "# Embarked 처리\n",
    "Embarked_mapping = {'S' : 0,\n",
    "                    'C' : 1,\n",
    "                    'Q' : 2}\n",
    "train['Embarked'] = train['Embarked'].map(Embarked_mapping)\n",
    "# display(df)\n",
    "\n",
    "# 나이를 처리해야 해요! 나이에는 결측치가 많아요!\n",
    "train['Age'] = train['Age'].fillna(train['Age'].mean())\n",
    "# display(df)\n",
    "\n",
    "# 나이에 대해서는...Binning 처리를 해요!\n",
    "train.loc[train['Age'] < 8, 'Age'] = 0\n",
    "train.loc[(train['Age'] >= 8) & (train['Age'] < 20), 'Age'] = 1\n",
    "train.loc[(train['Age'] >= 20) & (train['Age'] < 65), 'Age'] = 2\n",
    "train.loc[train['Age'] >= 65, 'Age'] = 3\n",
    "# display(df)\n",
    "\n",
    "x_data = train.drop('Survived', axis=1, inplace=False).values\n",
    "t_data = train['Survived'].values.reshape(-1, 1)\n",
    "\n",
    "# 정규화!\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# train 데이터와 test 데이터를 분리하나요?\n",
    "# 원래 내가 만든 모델의 최종 평가를 하기 위해서는 test 데이터가 당연히 있어야 해요!\n",
    "# 하지만 우리 예제는 Kaggle에서 제공한 test 데이터를 이용한 예측결과값을\n",
    "# 파일로 만들어서 Kaggle에 제출하는 것이기 때문에 test 데이터가 필요 없어요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5620 - acc: 0.7247 - val_loss: 0.4412 - val_acc: 0.8101\n",
      "Epoch 2/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4707 - acc: 0.7949 - val_loss: 0.4227 - val_acc: 0.8101\n",
      "Epoch 3/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4672 - acc: 0.7949 - val_loss: 0.4194 - val_acc: 0.8101\n",
      "Epoch 4/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4656 - acc: 0.7907 - val_loss: 0.4137 - val_acc: 0.8212\n",
      "Epoch 5/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4662 - acc: 0.7949 - val_loss: 0.4125 - val_acc: 0.8156\n",
      "Epoch 6/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4630 - acc: 0.7921 - val_loss: 0.4093 - val_acc: 0.8156\n",
      "Epoch 7/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4610 - acc: 0.8062 - val_loss: 0.4252 - val_acc: 0.8045\n",
      "Epoch 8/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4722 - acc: 0.7865 - val_loss: 0.4018 - val_acc: 0.8268\n",
      "Epoch 9/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4594 - acc: 0.7851 - val_loss: 0.4052 - val_acc: 0.8324\n",
      "Epoch 10/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4707 - acc: 0.7935 - val_loss: 0.4061 - val_acc: 0.8156\n",
      "Epoch 11/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4580 - acc: 0.7963 - val_loss: 0.4028 - val_acc: 0.8212\n",
      "Epoch 12/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4584 - acc: 0.7921 - val_loss: 0.3967 - val_acc: 0.8268\n",
      "Epoch 13/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4629 - acc: 0.7963 - val_loss: 0.3992 - val_acc: 0.8268\n",
      "Epoch 14/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4551 - acc: 0.7978 - val_loss: 0.4063 - val_acc: 0.8101\n",
      "Epoch 15/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4630 - acc: 0.7935 - val_loss: 0.4008 - val_acc: 0.8156\n",
      "Epoch 16/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4580 - acc: 0.8020 - val_loss: 0.4043 - val_acc: 0.8156\n",
      "Epoch 17/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4599 - acc: 0.7921 - val_loss: 0.3935 - val_acc: 0.8212\n",
      "Epoch 18/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4599 - acc: 0.8048 - val_loss: 0.3942 - val_acc: 0.8156\n",
      "Epoch 19/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4676 - acc: 0.7921 - val_loss: 0.3949 - val_acc: 0.8268\n",
      "Epoch 20/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4644 - acc: 0.7963 - val_loss: 0.3948 - val_acc: 0.8212\n",
      "Epoch 21/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4593 - acc: 0.8006 - val_loss: 0.3928 - val_acc: 0.8212\n",
      "Epoch 22/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4570 - acc: 0.7992 - val_loss: 0.3914 - val_acc: 0.8212\n",
      "Epoch 23/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4587 - acc: 0.7865 - val_loss: 0.4009 - val_acc: 0.8324\n",
      "Epoch 24/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4707 - acc: 0.7978 - val_loss: 0.3893 - val_acc: 0.8212\n",
      "Epoch 25/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4632 - acc: 0.8006 - val_loss: 0.4064 - val_acc: 0.8156\n",
      "Epoch 26/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4564 - acc: 0.7949 - val_loss: 0.3888 - val_acc: 0.8212\n",
      "Epoch 27/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4601 - acc: 0.7963 - val_loss: 0.3897 - val_acc: 0.8212\n",
      "Epoch 28/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4550 - acc: 0.7978 - val_loss: 0.3918 - val_acc: 0.8268\n",
      "Epoch 29/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4579 - acc: 0.7992 - val_loss: 0.3893 - val_acc: 0.8212\n",
      "Epoch 30/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4554 - acc: 0.7949 - val_loss: 0.3911 - val_acc: 0.8212\n",
      "Epoch 31/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4599 - acc: 0.7992 - val_loss: 0.4101 - val_acc: 0.8101\n",
      "Epoch 32/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4549 - acc: 0.7963 - val_loss: 0.3922 - val_acc: 0.8212\n",
      "Epoch 33/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4625 - acc: 0.7921 - val_loss: 0.3894 - val_acc: 0.8212\n",
      "Epoch 34/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4591 - acc: 0.7963 - val_loss: 0.3943 - val_acc: 0.8268\n",
      "Epoch 35/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4579 - acc: 0.7907 - val_loss: 0.3891 - val_acc: 0.8212\n",
      "Epoch 36/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4583 - acc: 0.7963 - val_loss: 0.3960 - val_acc: 0.8212\n",
      "Epoch 37/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4544 - acc: 0.8006 - val_loss: 0.3902 - val_acc: 0.8212\n",
      "Epoch 38/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4546 - acc: 0.7935 - val_loss: 0.4003 - val_acc: 0.8212\n",
      "Epoch 39/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4586 - acc: 0.7978 - val_loss: 0.3889 - val_acc: 0.8212\n",
      "Epoch 40/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4617 - acc: 0.7823 - val_loss: 0.3907 - val_acc: 0.8268\n",
      "Epoch 41/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4675 - acc: 0.7935 - val_loss: 0.3890 - val_acc: 0.8212\n",
      "Epoch 42/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4592 - acc: 0.7978 - val_loss: 0.3892 - val_acc: 0.8212\n",
      "Epoch 43/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4566 - acc: 0.7978 - val_loss: 0.3896 - val_acc: 0.8212\n",
      "Epoch 44/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4628 - acc: 0.8006 - val_loss: 0.3893 - val_acc: 0.8212\n",
      "Epoch 45/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4600 - acc: 0.7879 - val_loss: 0.3945 - val_acc: 0.8212\n",
      "Epoch 46/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4572 - acc: 0.7963 - val_loss: 0.3899 - val_acc: 0.8212\n",
      "Epoch 47/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4649 - acc: 0.8020 - val_loss: 0.4132 - val_acc: 0.8212\n",
      "Epoch 48/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4558 - acc: 0.7963 - val_loss: 0.3879 - val_acc: 0.8212\n",
      "Epoch 49/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4561 - acc: 0.7992 - val_loss: 0.3905 - val_acc: 0.8268\n",
      "Epoch 50/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4571 - acc: 0.8006 - val_loss: 0.3930 - val_acc: 0.8212\n",
      "Epoch 51/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4585 - acc: 0.7921 - val_loss: 0.3892 - val_acc: 0.8212\n",
      "Epoch 52/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4643 - acc: 0.7978 - val_loss: 0.3894 - val_acc: 0.8324\n",
      "Epoch 53/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4586 - acc: 0.7949 - val_loss: 0.3976 - val_acc: 0.8212\n",
      "Epoch 54/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4583 - acc: 0.8034 - val_loss: 0.3924 - val_acc: 0.8268\n",
      "Epoch 55/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4555 - acc: 0.8020 - val_loss: 0.3899 - val_acc: 0.8268\n",
      "Epoch 56/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4603 - acc: 0.7907 - val_loss: 0.3908 - val_acc: 0.8268\n",
      "Epoch 57/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4603 - acc: 0.8118 - val_loss: 0.4187 - val_acc: 0.8045\n",
      "Epoch 58/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4635 - acc: 0.7879 - val_loss: 0.3880 - val_acc: 0.8212\n",
      "Epoch 59/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4575 - acc: 0.7907 - val_loss: 0.3896 - val_acc: 0.8268\n",
      "Epoch 60/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4563 - acc: 0.7992 - val_loss: 0.3878 - val_acc: 0.8268\n",
      "Epoch 61/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4581 - acc: 0.7978 - val_loss: 0.3892 - val_acc: 0.8212\n",
      "Epoch 62/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4564 - acc: 0.7978 - val_loss: 0.3975 - val_acc: 0.8268\n",
      "Epoch 63/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4598 - acc: 0.7935 - val_loss: 0.3896 - val_acc: 0.8268\n",
      "Epoch 64/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4574 - acc: 0.7907 - val_loss: 0.3882 - val_acc: 0.8268\n",
      "Epoch 65/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4579 - acc: 0.7992 - val_loss: 0.3995 - val_acc: 0.8156\n",
      "Epoch 66/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4605 - acc: 0.7963 - val_loss: 0.3874 - val_acc: 0.8212\n",
      "Epoch 67/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4610 - acc: 0.7963 - val_loss: 0.3892 - val_acc: 0.8212\n",
      "Epoch 68/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4589 - acc: 0.8006 - val_loss: 0.3968 - val_acc: 0.8268\n",
      "Epoch 69/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4552 - acc: 0.7978 - val_loss: 0.3972 - val_acc: 0.8324\n",
      "Epoch 70/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4613 - acc: 0.7963 - val_loss: 0.3964 - val_acc: 0.8268\n",
      "Epoch 71/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4573 - acc: 0.8048 - val_loss: 0.4011 - val_acc: 0.8156\n",
      "Epoch 72/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4611 - acc: 0.7879 - val_loss: 0.3964 - val_acc: 0.8324\n",
      "Epoch 73/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4632 - acc: 0.7963 - val_loss: 0.3876 - val_acc: 0.8212\n",
      "Epoch 74/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4583 - acc: 0.7978 - val_loss: 0.3919 - val_acc: 0.8268\n",
      "Epoch 75/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4572 - acc: 0.8006 - val_loss: 0.3935 - val_acc: 0.8324\n",
      "Epoch 76/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4544 - acc: 0.7921 - val_loss: 0.3879 - val_acc: 0.8212\n",
      "Epoch 77/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4582 - acc: 0.7978 - val_loss: 0.3964 - val_acc: 0.8212\n",
      "Epoch 78/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4559 - acc: 0.7949 - val_loss: 0.3893 - val_acc: 0.8212\n",
      "Epoch 79/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4595 - acc: 0.7963 - val_loss: 0.3909 - val_acc: 0.8268\n",
      "Epoch 80/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4559 - acc: 0.8062 - val_loss: 0.4095 - val_acc: 0.8268\n",
      "Epoch 81/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4619 - acc: 0.7963 - val_loss: 0.3931 - val_acc: 0.8268\n",
      "Epoch 82/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4622 - acc: 0.7921 - val_loss: 0.4053 - val_acc: 0.8268\n",
      "Epoch 83/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4568 - acc: 0.8062 - val_loss: 0.3891 - val_acc: 0.8268\n",
      "Epoch 84/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4605 - acc: 0.7865 - val_loss: 0.3952 - val_acc: 0.8268\n",
      "Epoch 85/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4743 - acc: 0.7879 - val_loss: 0.3939 - val_acc: 0.8156\n",
      "Epoch 86/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4657 - acc: 0.7949 - val_loss: 0.4117 - val_acc: 0.8101\n",
      "Epoch 87/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4604 - acc: 0.7893 - val_loss: 0.3918 - val_acc: 0.8268\n",
      "Epoch 88/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4561 - acc: 0.7992 - val_loss: 0.3873 - val_acc: 0.8212\n",
      "Epoch 89/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4558 - acc: 0.8034 - val_loss: 0.3939 - val_acc: 0.8268\n",
      "Epoch 90/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4580 - acc: 0.7949 - val_loss: 0.3943 - val_acc: 0.8268\n",
      "Epoch 91/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4564 - acc: 0.8076 - val_loss: 0.4023 - val_acc: 0.8156\n",
      "Epoch 92/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4591 - acc: 0.7893 - val_loss: 0.3883 - val_acc: 0.8212\n",
      "Epoch 93/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4648 - acc: 0.7978 - val_loss: 0.3943 - val_acc: 0.8212\n",
      "Epoch 94/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4670 - acc: 0.7893 - val_loss: 0.3892 - val_acc: 0.8268\n",
      "Epoch 95/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4575 - acc: 0.7921 - val_loss: 0.3894 - val_acc: 0.8268\n",
      "Epoch 96/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4641 - acc: 0.8020 - val_loss: 0.3917 - val_acc: 0.8212\n",
      "Epoch 97/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4626 - acc: 0.8034 - val_loss: 0.3916 - val_acc: 0.8268\n",
      "Epoch 98/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4592 - acc: 0.8020 - val_loss: 0.3901 - val_acc: 0.8268\n",
      "Epoch 99/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4579 - acc: 0.7992 - val_loss: 0.3882 - val_acc: 0.8212\n",
      "Epoch 100/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4612 - acc: 0.8020 - val_loss: 0.3916 - val_acc: 0.8268\n",
      "Epoch 101/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4608 - acc: 0.7949 - val_loss: 0.3924 - val_acc: 0.8268\n",
      "Epoch 102/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4606 - acc: 0.7992 - val_loss: 0.3885 - val_acc: 0.8268\n",
      "Epoch 103/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4603 - acc: 0.7963 - val_loss: 0.3902 - val_acc: 0.8268\n",
      "Epoch 104/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4587 - acc: 0.8006 - val_loss: 0.3944 - val_acc: 0.8212\n",
      "Epoch 105/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4580 - acc: 0.8006 - val_loss: 0.3888 - val_acc: 0.8212\n",
      "Epoch 106/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4680 - acc: 0.8020 - val_loss: 0.4113 - val_acc: 0.8156\n",
      "Epoch 107/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4631 - acc: 0.7978 - val_loss: 0.3967 - val_acc: 0.8212\n",
      "Epoch 108/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4631 - acc: 0.7907 - val_loss: 0.3969 - val_acc: 0.8212\n",
      "Epoch 109/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4587 - acc: 0.7949 - val_loss: 0.3905 - val_acc: 0.8212\n",
      "Epoch 110/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4563 - acc: 0.7935 - val_loss: 0.3937 - val_acc: 0.8268\n",
      "Epoch 111/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4560 - acc: 0.7949 - val_loss: 0.3888 - val_acc: 0.8212\n",
      "Epoch 112/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4556 - acc: 0.8020 - val_loss: 0.3907 - val_acc: 0.8268\n",
      "Epoch 113/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4587 - acc: 0.7907 - val_loss: 0.3936 - val_acc: 0.8268\n",
      "Epoch 114/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4564 - acc: 0.7992 - val_loss: 0.3894 - val_acc: 0.8212\n",
      "Epoch 115/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4588 - acc: 0.7949 - val_loss: 0.3972 - val_acc: 0.8212\n",
      "Epoch 116/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4580 - acc: 0.7921 - val_loss: 0.4002 - val_acc: 0.8212\n",
      "Epoch 117/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4609 - acc: 0.7978 - val_loss: 0.3879 - val_acc: 0.8268\n",
      "Epoch 118/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4559 - acc: 0.8020 - val_loss: 0.3915 - val_acc: 0.8212\n",
      "Epoch 119/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4610 - acc: 0.7935 - val_loss: 0.3904 - val_acc: 0.8212\n",
      "Epoch 120/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4553 - acc: 0.8048 - val_loss: 0.4039 - val_acc: 0.8156\n",
      "Epoch 121/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4607 - acc: 0.7963 - val_loss: 0.3919 - val_acc: 0.8268\n",
      "Epoch 122/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4580 - acc: 0.8034 - val_loss: 0.3912 - val_acc: 0.8324\n",
      "Epoch 123/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4651 - acc: 0.7992 - val_loss: 0.3972 - val_acc: 0.8324\n",
      "Epoch 124/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4549 - acc: 0.8034 - val_loss: 0.4088 - val_acc: 0.8156\n",
      "Epoch 125/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4607 - acc: 0.7992 - val_loss: 0.3887 - val_acc: 0.8212\n",
      "Epoch 126/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4581 - acc: 0.7935 - val_loss: 0.3909 - val_acc: 0.8212\n",
      "Epoch 127/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4645 - acc: 0.7921 - val_loss: 0.3902 - val_acc: 0.8212\n",
      "Epoch 128/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4582 - acc: 0.7949 - val_loss: 0.3904 - val_acc: 0.8268\n",
      "Epoch 129/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4583 - acc: 0.7978 - val_loss: 0.3915 - val_acc: 0.8268\n",
      "Epoch 130/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4603 - acc: 0.7935 - val_loss: 0.3891 - val_acc: 0.8268\n",
      "Epoch 131/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4569 - acc: 0.7949 - val_loss: 0.4005 - val_acc: 0.8212\n",
      "Epoch 132/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4616 - acc: 0.7963 - val_loss: 0.3884 - val_acc: 0.8212\n",
      "Epoch 133/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4575 - acc: 0.7992 - val_loss: 0.3909 - val_acc: 0.8268\n",
      "Epoch 134/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4596 - acc: 0.8006 - val_loss: 0.3894 - val_acc: 0.8212\n",
      "Epoch 135/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4602 - acc: 0.7992 - val_loss: 0.3903 - val_acc: 0.8212\n",
      "Epoch 136/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4620 - acc: 0.8020 - val_loss: 0.4027 - val_acc: 0.8156\n",
      "Epoch 137/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4518 - acc: 0.8006 - val_loss: 0.3887 - val_acc: 0.8212\n",
      "Epoch 138/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4553 - acc: 0.7921 - val_loss: 0.3887 - val_acc: 0.8268\n",
      "Epoch 139/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4559 - acc: 0.7992 - val_loss: 0.3894 - val_acc: 0.8268\n",
      "Epoch 140/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4583 - acc: 0.7921 - val_loss: 0.3879 - val_acc: 0.8268\n",
      "Epoch 141/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4576 - acc: 0.8020 - val_loss: 0.3972 - val_acc: 0.8212\n",
      "Epoch 142/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4643 - acc: 0.8062 - val_loss: 0.3884 - val_acc: 0.8212\n",
      "Epoch 143/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4573 - acc: 0.7992 - val_loss: 0.3901 - val_acc: 0.8156\n",
      "Epoch 144/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4588 - acc: 0.7963 - val_loss: 0.3887 - val_acc: 0.8268\n",
      "Epoch 145/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4586 - acc: 0.8006 - val_loss: 0.3889 - val_acc: 0.8268\n",
      "Epoch 146/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4650 - acc: 0.7935 - val_loss: 0.3892 - val_acc: 0.8324\n",
      "Epoch 147/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4579 - acc: 0.7949 - val_loss: 0.3890 - val_acc: 0.8268\n",
      "Epoch 148/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4615 - acc: 0.7978 - val_loss: 0.3892 - val_acc: 0.8212\n",
      "Epoch 149/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4577 - acc: 0.7992 - val_loss: 0.3897 - val_acc: 0.8268\n",
      "Epoch 150/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4570 - acc: 0.7949 - val_loss: 0.3892 - val_acc: 0.8268\n",
      "Epoch 151/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4581 - acc: 0.7963 - val_loss: 0.3941 - val_acc: 0.8324\n",
      "Epoch 152/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4568 - acc: 0.7921 - val_loss: 0.3937 - val_acc: 0.8268\n",
      "Epoch 153/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4588 - acc: 0.8076 - val_loss: 0.4215 - val_acc: 0.8045\n",
      "Epoch 154/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4640 - acc: 0.7879 - val_loss: 0.3902 - val_acc: 0.8268\n",
      "Epoch 155/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4574 - acc: 0.7907 - val_loss: 0.3882 - val_acc: 0.8212\n",
      "Epoch 156/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4586 - acc: 0.7949 - val_loss: 0.3885 - val_acc: 0.8212\n",
      "Epoch 157/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4583 - acc: 0.7949 - val_loss: 0.3885 - val_acc: 0.8212\n",
      "Epoch 158/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4619 - acc: 0.8020 - val_loss: 0.3941 - val_acc: 0.8268\n",
      "Epoch 159/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4599 - acc: 0.7907 - val_loss: 0.3900 - val_acc: 0.8268\n",
      "Epoch 160/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4573 - acc: 0.7879 - val_loss: 0.3920 - val_acc: 0.8212\n",
      "Epoch 161/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4559 - acc: 0.7963 - val_loss: 0.3906 - val_acc: 0.8212\n",
      "Epoch 162/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4607 - acc: 0.8062 - val_loss: 0.3978 - val_acc: 0.8212\n",
      "Epoch 163/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4586 - acc: 0.8006 - val_loss: 0.3919 - val_acc: 0.8212\n",
      "Epoch 164/300\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5419 - acc: 0.718 - 0s 3ms/step - loss: 0.4555 - acc: 0.7992 - val_loss: 0.3903 - val_acc: 0.8212\n",
      "Epoch 165/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4577 - acc: 0.8006 - val_loss: 0.4127 - val_acc: 0.8101\n",
      "Epoch 166/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4600 - acc: 0.7879 - val_loss: 0.3919 - val_acc: 0.8268\n",
      "Epoch 167/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4604 - acc: 0.8034 - val_loss: 0.3897 - val_acc: 0.8212\n",
      "Epoch 168/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4591 - acc: 0.7949 - val_loss: 0.3943 - val_acc: 0.8268\n",
      "Epoch 169/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4584 - acc: 0.7992 - val_loss: 0.3905 - val_acc: 0.8212\n",
      "Epoch 170/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4616 - acc: 0.7978 - val_loss: 0.4014 - val_acc: 0.8156\n",
      "Epoch 171/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4620 - acc: 0.7935 - val_loss: 0.3995 - val_acc: 0.8156\n",
      "Epoch 172/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4649 - acc: 0.7921 - val_loss: 0.3881 - val_acc: 0.8268\n",
      "Epoch 173/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4632 - acc: 0.7935 - val_loss: 0.3966 - val_acc: 0.8268\n",
      "Epoch 174/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4591 - acc: 0.7949 - val_loss: 0.3947 - val_acc: 0.8268\n",
      "Epoch 175/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4569 - acc: 0.7963 - val_loss: 0.3904 - val_acc: 0.8268\n",
      "Epoch 176/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4576 - acc: 0.7949 - val_loss: 0.4005 - val_acc: 0.8156\n",
      "Epoch 177/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4599 - acc: 0.8020 - val_loss: 0.3930 - val_acc: 0.8268\n",
      "Epoch 178/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4615 - acc: 0.7963 - val_loss: 0.3877 - val_acc: 0.8212\n",
      "Epoch 179/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4597 - acc: 0.7921 - val_loss: 0.3898 - val_acc: 0.8212\n",
      "Epoch 180/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4550 - acc: 0.7963 - val_loss: 0.3929 - val_acc: 0.8268\n",
      "Epoch 181/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4556 - acc: 0.7949 - val_loss: 0.3952 - val_acc: 0.8268\n",
      "Epoch 182/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4567 - acc: 0.7992 - val_loss: 0.3898 - val_acc: 0.8268\n",
      "Epoch 183/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4570 - acc: 0.7907 - val_loss: 0.3915 - val_acc: 0.8212\n",
      "Epoch 184/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4562 - acc: 0.8006 - val_loss: 0.3921 - val_acc: 0.8324\n",
      "Epoch 185/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4568 - acc: 0.7921 - val_loss: 0.3980 - val_acc: 0.8324\n",
      "Epoch 186/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4654 - acc: 0.7921 - val_loss: 0.3891 - val_acc: 0.8212\n",
      "Epoch 187/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4644 - acc: 0.8006 - val_loss: 0.3969 - val_acc: 0.8212\n",
      "Epoch 188/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4552 - acc: 0.8006 - val_loss: 0.3895 - val_acc: 0.8212\n",
      "Epoch 189/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4577 - acc: 0.7893 - val_loss: 0.3936 - val_acc: 0.8268\n",
      "Epoch 190/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4557 - acc: 0.7978 - val_loss: 0.3931 - val_acc: 0.8212\n",
      "Epoch 191/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4554 - acc: 0.7992 - val_loss: 0.3919 - val_acc: 0.8212\n",
      "Epoch 192/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4613 - acc: 0.7907 - val_loss: 0.4091 - val_acc: 0.8156\n",
      "Epoch 193/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4599 - acc: 0.7949 - val_loss: 0.3894 - val_acc: 0.8268\n",
      "Epoch 194/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4549 - acc: 0.8034 - val_loss: 0.4052 - val_acc: 0.8156\n",
      "Epoch 195/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4602 - acc: 0.8020 - val_loss: 0.3891 - val_acc: 0.8268\n",
      "Epoch 196/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4561 - acc: 0.7949 - val_loss: 0.3879 - val_acc: 0.8212\n",
      "Epoch 197/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4577 - acc: 0.7978 - val_loss: 0.3878 - val_acc: 0.8212\n",
      "Epoch 198/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4568 - acc: 0.8006 - val_loss: 0.4003 - val_acc: 0.8156\n",
      "Epoch 199/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4556 - acc: 0.7921 - val_loss: 0.3901 - val_acc: 0.8156\n",
      "Epoch 200/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4588 - acc: 0.7809 - val_loss: 0.3939 - val_acc: 0.8268\n",
      "Epoch 201/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4584 - acc: 0.7992 - val_loss: 0.3934 - val_acc: 0.8268\n",
      "Epoch 202/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4588 - acc: 0.7949 - val_loss: 0.3898 - val_acc: 0.8212\n",
      "Epoch 203/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4601 - acc: 0.7921 - val_loss: 0.3900 - val_acc: 0.8268\n",
      "Epoch 204/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4581 - acc: 0.7949 - val_loss: 0.3940 - val_acc: 0.8212\n",
      "Epoch 205/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4593 - acc: 0.8034 - val_loss: 0.3888 - val_acc: 0.8268\n",
      "Epoch 206/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4624 - acc: 0.8034 - val_loss: 0.3920 - val_acc: 0.8324\n",
      "Epoch 207/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4568 - acc: 0.7935 - val_loss: 0.3897 - val_acc: 0.8268\n",
      "Epoch 208/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4611 - acc: 0.8034 - val_loss: 0.3960 - val_acc: 0.8268\n",
      "Epoch 209/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4561 - acc: 0.8034 - val_loss: 0.3890 - val_acc: 0.8324\n",
      "Epoch 210/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4599 - acc: 0.7978 - val_loss: 0.3931 - val_acc: 0.8268\n",
      "Epoch 211/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4566 - acc: 0.8006 - val_loss: 0.4058 - val_acc: 0.8268\n",
      "Epoch 212/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4680 - acc: 0.7935 - val_loss: 0.3980 - val_acc: 0.8268\n",
      "Epoch 213/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4584 - acc: 0.7907 - val_loss: 0.3897 - val_acc: 0.8268\n",
      "Epoch 214/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4602 - acc: 0.7978 - val_loss: 0.3929 - val_acc: 0.8268\n",
      "Epoch 215/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4640 - acc: 0.7992 - val_loss: 0.3915 - val_acc: 0.8268\n",
      "Epoch 216/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4581 - acc: 0.7949 - val_loss: 0.3939 - val_acc: 0.8268\n",
      "Epoch 217/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4566 - acc: 0.7935 - val_loss: 0.3888 - val_acc: 0.8212\n",
      "Epoch 218/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4663 - acc: 0.7879 - val_loss: 0.3888 - val_acc: 0.8212\n",
      "Epoch 219/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4577 - acc: 0.7949 - val_loss: 0.3916 - val_acc: 0.8268\n",
      "Epoch 220/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4557 - acc: 0.8076 - val_loss: 0.4018 - val_acc: 0.8212\n",
      "Epoch 221/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4630 - acc: 0.7907 - val_loss: 0.3920 - val_acc: 0.8268\n",
      "Epoch 222/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4587 - acc: 0.7992 - val_loss: 0.3951 - val_acc: 0.8324\n",
      "Epoch 223/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4606 - acc: 0.7978 - val_loss: 0.3946 - val_acc: 0.8268\n",
      "Epoch 224/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4631 - acc: 0.7978 - val_loss: 0.4037 - val_acc: 0.8268\n",
      "Epoch 225/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4558 - acc: 0.8034 - val_loss: 0.3885 - val_acc: 0.8212\n",
      "Epoch 226/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4565 - acc: 0.7992 - val_loss: 0.3883 - val_acc: 0.8268\n",
      "Epoch 227/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4617 - acc: 0.7992 - val_loss: 0.3901 - val_acc: 0.8212\n",
      "Epoch 228/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4571 - acc: 0.8048 - val_loss: 0.3902 - val_acc: 0.8212\n",
      "Epoch 229/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4598 - acc: 0.8020 - val_loss: 0.3888 - val_acc: 0.8212\n",
      "Epoch 230/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4571 - acc: 0.7963 - val_loss: 0.3878 - val_acc: 0.8212\n",
      "Epoch 231/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4575 - acc: 0.7865 - val_loss: 0.3911 - val_acc: 0.8268\n",
      "Epoch 232/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4598 - acc: 0.7992 - val_loss: 0.3880 - val_acc: 0.8268\n",
      "Epoch 233/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4563 - acc: 0.8006 - val_loss: 0.3881 - val_acc: 0.8268\n",
      "Epoch 234/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4593 - acc: 0.7978 - val_loss: 0.3892 - val_acc: 0.8268\n",
      "Epoch 235/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4570 - acc: 0.7935 - val_loss: 0.3980 - val_acc: 0.8212\n",
      "Epoch 236/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4572 - acc: 0.8020 - val_loss: 0.3868 - val_acc: 0.8212\n",
      "Epoch 237/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4568 - acc: 0.7978 - val_loss: 0.3898 - val_acc: 0.8268\n",
      "Epoch 238/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4619 - acc: 0.7935 - val_loss: 0.3971 - val_acc: 0.8212\n",
      "Epoch 239/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4632 - acc: 0.7921 - val_loss: 0.3893 - val_acc: 0.8212\n",
      "Epoch 240/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4558 - acc: 0.7992 - val_loss: 0.3888 - val_acc: 0.8268\n",
      "Epoch 241/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4561 - acc: 0.8034 - val_loss: 0.3885 - val_acc: 0.8212\n",
      "Epoch 242/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4562 - acc: 0.7963 - val_loss: 0.3910 - val_acc: 0.8268\n",
      "Epoch 243/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4554 - acc: 0.7963 - val_loss: 0.3901 - val_acc: 0.8212\n",
      "Epoch 244/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4600 - acc: 0.8048 - val_loss: 0.3927 - val_acc: 0.8268\n",
      "Epoch 245/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4561 - acc: 0.7978 - val_loss: 0.3901 - val_acc: 0.8268\n",
      "Epoch 246/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4665 - acc: 0.7935 - val_loss: 0.3915 - val_acc: 0.8268\n",
      "Epoch 247/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4564 - acc: 0.7963 - val_loss: 0.3889 - val_acc: 0.8212\n",
      "Epoch 248/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4558 - acc: 0.7949 - val_loss: 0.3885 - val_acc: 0.8268\n",
      "Epoch 249/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4572 - acc: 0.7907 - val_loss: 0.3891 - val_acc: 0.8212\n",
      "Epoch 250/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4576 - acc: 0.8006 - val_loss: 0.3904 - val_acc: 0.8156\n",
      "Epoch 251/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4577 - acc: 0.7978 - val_loss: 0.3888 - val_acc: 0.8212\n",
      "Epoch 252/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4622 - acc: 0.7907 - val_loss: 0.3869 - val_acc: 0.8212\n",
      "Epoch 253/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4700 - acc: 0.7837 - val_loss: 0.4017 - val_acc: 0.8156\n",
      "Epoch 254/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4673 - acc: 0.7992 - val_loss: 0.3874 - val_acc: 0.8268\n",
      "Epoch 255/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4607 - acc: 0.7992 - val_loss: 0.4061 - val_acc: 0.8324\n",
      "Epoch 256/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4680 - acc: 0.7879 - val_loss: 0.4022 - val_acc: 0.8324\n",
      "Epoch 257/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4567 - acc: 0.7935 - val_loss: 0.3887 - val_acc: 0.8212\n",
      "Epoch 258/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4558 - acc: 0.7978 - val_loss: 0.3893 - val_acc: 0.8212\n",
      "Epoch 259/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4571 - acc: 0.7949 - val_loss: 0.3964 - val_acc: 0.8268\n",
      "Epoch 260/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4559 - acc: 0.7963 - val_loss: 0.3896 - val_acc: 0.8268\n",
      "Epoch 261/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4608 - acc: 0.8006 - val_loss: 0.3924 - val_acc: 0.8324\n",
      "Epoch 262/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4607 - acc: 0.7935 - val_loss: 0.3941 - val_acc: 0.8268\n",
      "Epoch 263/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4565 - acc: 0.8020 - val_loss: 0.3945 - val_acc: 0.8268\n",
      "Epoch 264/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4572 - acc: 0.7963 - val_loss: 0.4073 - val_acc: 0.8212\n",
      "Epoch 265/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4766 - acc: 0.7893 - val_loss: 0.3899 - val_acc: 0.8212\n",
      "Epoch 266/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4585 - acc: 0.7921 - val_loss: 0.3997 - val_acc: 0.8212\n",
      "Epoch 267/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4685 - acc: 0.7935 - val_loss: 0.3988 - val_acc: 0.8156\n",
      "Epoch 268/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4582 - acc: 0.7949 - val_loss: 0.3897 - val_acc: 0.8212\n",
      "Epoch 269/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4585 - acc: 0.8006 - val_loss: 0.3947 - val_acc: 0.8268\n",
      "Epoch 270/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4617 - acc: 0.7921 - val_loss: 0.4036 - val_acc: 0.8156\n",
      "Epoch 271/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4625 - acc: 0.7893 - val_loss: 0.4044 - val_acc: 0.8156\n",
      "Epoch 272/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4624 - acc: 0.7963 - val_loss: 0.3882 - val_acc: 0.8268\n",
      "Epoch 273/300\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4579 - acc: 0.7978 - val_loss: 0.4042 - val_acc: 0.8268\n",
      "Epoch 274/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4639 - acc: 0.8034 - val_loss: 0.3879 - val_acc: 0.8268\n",
      "Epoch 275/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4647 - acc: 0.7837 - val_loss: 0.3915 - val_acc: 0.8156\n",
      "Epoch 276/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4625 - acc: 0.8006 - val_loss: 0.3878 - val_acc: 0.8212\n",
      "Epoch 277/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4559 - acc: 0.7978 - val_loss: 0.3919 - val_acc: 0.8268\n",
      "Epoch 278/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4600 - acc: 0.7935 - val_loss: 0.3966 - val_acc: 0.8268\n",
      "Epoch 279/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4588 - acc: 0.7907 - val_loss: 0.3969 - val_acc: 0.8268\n",
      "Epoch 280/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4589 - acc: 0.7921 - val_loss: 0.4026 - val_acc: 0.8156\n",
      "Epoch 281/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4584 - acc: 0.7978 - val_loss: 0.3920 - val_acc: 0.8156\n",
      "Epoch 282/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4549 - acc: 0.7949 - val_loss: 0.3929 - val_acc: 0.8212\n",
      "Epoch 283/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4606 - acc: 0.7907 - val_loss: 0.3992 - val_acc: 0.8212\n",
      "Epoch 284/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4575 - acc: 0.7992 - val_loss: 0.3963 - val_acc: 0.8268\n",
      "Epoch 285/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4599 - acc: 0.8034 - val_loss: 0.3913 - val_acc: 0.8324\n",
      "Epoch 286/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4580 - acc: 0.7935 - val_loss: 0.3902 - val_acc: 0.8212\n",
      "Epoch 287/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4572 - acc: 0.8006 - val_loss: 0.3941 - val_acc: 0.8268\n",
      "Epoch 288/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4583 - acc: 0.7907 - val_loss: 0.3943 - val_acc: 0.8268\n",
      "Epoch 289/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4564 - acc: 0.7978 - val_loss: 0.3910 - val_acc: 0.8268\n",
      "Epoch 290/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4554 - acc: 0.8034 - val_loss: 0.4195 - val_acc: 0.8212\n",
      "Epoch 291/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4716 - acc: 0.7893 - val_loss: 0.4059 - val_acc: 0.8156\n",
      "Epoch 292/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4605 - acc: 0.7978 - val_loss: 0.3891 - val_acc: 0.8212\n",
      "Epoch 293/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4556 - acc: 0.7963 - val_loss: 0.3950 - val_acc: 0.8268\n",
      "Epoch 294/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4603 - acc: 0.7992 - val_loss: 0.4066 - val_acc: 0.8156\n",
      "Epoch 295/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4552 - acc: 0.7978 - val_loss: 0.3893 - val_acc: 0.8212\n",
      "Epoch 296/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4585 - acc: 0.7935 - val_loss: 0.4119 - val_acc: 0.8101\n",
      "Epoch 297/300\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4619 - acc: 0.8006 - val_loss: 0.3877 - val_acc: 0.8212\n",
      "Epoch 298/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4584 - acc: 0.7935 - val_loss: 0.3976 - val_acc: 0.8212\n",
      "Epoch 299/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4571 - acc: 0.7935 - val_loss: 0.4014 - val_acc: 0.8156\n",
      "Epoch 300/300\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4614 - acc: 0.7921 - val_loss: 0.3997 - val_acc: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20bbd943b70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keras Model을 만들어 보아요!\n",
    "\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(5,)))\n",
    "keras_model.add(Dense(units=1,\n",
    "                      activation='sigmoid'))\n",
    "\n",
    "keras_model.compile(optimizer=Adam(learning_rate=1e-1),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "keras_model.fit(x_data_norm,\n",
    "                t_data,\n",
    "                epochs=300,\n",
    "                verbose=1,\n",
    "                validation_split=0.2)\n",
    "\n",
    "# learning_rate=1e-1\n",
    "# loss: 0.4606 - acc: 0.7978 - val_loss: 0.4007 - val_acc: 0.8268\n",
    "\n",
    "# learning_rate=1e-2\n",
    "# loss: 0.4538 - acc: 0.8006 - val_loss: 0.3906 - val_acc: 0.8212\n",
    "\n",
    "# learning_rate=1e-4\n",
    "# loss: 0.6656 - acc: 0.6110 - val_loss: 0.6291 - val_acc: 0.6536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Survived', 'Pclass', 'Sex', 'Age', 'Embarked', 'Falmily'], dtype='object')\n",
      "14/14 [==============================] - 0s 734us/step\n"
     ]
    }
   ],
   "source": [
    "# 학습이 끝났으니... 제출파일을 생성해야 해요!\n",
    "# 모델이 만들어 졌으니 test 데이터로 예측된 결과를 csv파일로\n",
    "# 만들어서 Kaggle에 제출하고 그 결과를 확인해보아요!\n",
    "test = pd.read_csv(r\"C:\\Users\\lee_0\\Desktop\\코딩\\ML\\12.05\\test.csv\")\n",
    "submission = pd.read_csv(r\"C:\\Users\\lee_0\\Desktop\\코딩\\ML\\12.05\\gender_submission.csv\")\n",
    "\n",
    "# test 데이터 전처리\n",
    "# 사용하는 column만 추출, 사용되지 않는(불필요한) column을 삭제\n",
    "print(train.columns)\n",
    "# 필요없는 컬럼은(종속변수에 영향을 주지 않거나 의미상 중복 컬럼)\n",
    "\n",
    "test.drop(['PassengerId', 'Ticket', 'Name', 'Fare', 'Cabin'],\n",
    "          axis=1,\n",
    "          inplace=True)\n",
    "\n",
    "# 성별처리 (male=0, female=1)\n",
    "gender_mapping = {'male' : 0,\n",
    "                  'female' : 1}\n",
    "test['Sex'] = test['Sex'].map(gender_mapping)\n",
    "\n",
    "test['Family'] = test['SibSp'] + test['Parch']\n",
    "\n",
    "test.drop(['SibSp', 'Parch'],\n",
    "           axis=1,\n",
    "           inplace=True)\n",
    "\n",
    "# Embarked의 결측치를 처리해 보아요!\n",
    "test['Embarked'] = test['Embarked'].fillna('Q')\n",
    "\n",
    "# Embarked 처리\n",
    "Embarked_mapping = {'S' : 0,\n",
    "                    'C' : 1,\n",
    "                    'Q' : 2}\n",
    "test['Embarked'] = test['Embarked'].map(Embarked_mapping)\n",
    "\n",
    "# 나이를 처리해야 해요! 나이에는 결측치가 많아요!\n",
    "test['Age'] = test['Age'].fillna(test['Age'].mean())\n",
    "\n",
    "# 나이에 대해서는...Binning 처리를 해요!\n",
    "test.loc[test['Age'] < 8, 'Age'] = 0\n",
    "test.loc[(test['Age'] >= 8) & (test['Age'] < 20), 'Age'] = 1\n",
    "test.loc[(test['Age'] >= 20) & (test['Age'] < 65), 'Age'] = 2\n",
    "test.loc[test['Age'] >= 65, 'Age'] = 3\n",
    "# display(test)  # 418 rows × 5 columns\n",
    "\n",
    "x_data_test_norm = scaler.transform(test.values)\n",
    "\n",
    "predict = keras_model.predict(x_data_test_norm)\n",
    "\n",
    "submission['Survived'] = predict\n",
    "submission['Survived'] = np.where(submission['Survived'] >= 0.5, 1, 0)\n",
    "# display(submission)  # 418 rows × 2 columns\n",
    "\n",
    "submission.to_csv('./sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
