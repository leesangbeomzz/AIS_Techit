{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at C:\\Users\\lee_0\\AppData\\Local\\Temp\\matplotlib-zy4ral5b because the default path (C:\\Users\\lee_0\\.matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "# BMI 데이터를 이용해서 Multinomial Classification을 구현해 보아요!\n",
    "# sklearn과 tensorflow를 이용해서 구현할 꺼예요!\n",
    "\n",
    "# 필요한 module import \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Loading\n",
    "df = pd.read_csv(r\"C:\\Users\\lee_0\\Desktop\\코딩\\ML\\12.06\\bmi.csv\",\n",
    "                 skiprows=3)\n",
    "# display(df.head(), df.shape)  # (20000, 3)\n",
    "\n",
    "# 결측치 확인 및 처리\n",
    "# print(df.isnull().sum())  # 결측치는 없어요!\n",
    "\n",
    "# 이상치 확인\n",
    "zscore = 1.8\n",
    "df.loc[np.abs(stats.zscore(df['height'])) >= zscore]  # height의 이상치 처리\n",
    "df.loc[np.abs(stats.zscore(df['weight'])) >= zscore]  # weight의 이상치 처리\n",
    "df.loc[np.abs(stats.zscore(df['label'])) >= zscore]  #label의 이상치 처리\n",
    "\n",
    "x_data = df[['height', 'weight']].values  # 2차원 matrix\n",
    "t_data = df['label']                              # 1차원 vector\n",
    "\n",
    "# 정규화\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# 데이터 분할\n",
    "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data,\n",
    "                 t_data,\n",
    "                 stratify=t_data,\n",
    "                 test_size=0.3,\n",
    "                 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9851666666666666\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# sklearn으로 모델 학습하고 평가를 진행!\n",
    "sklearn_model = linear_model.LogisticRegression()\n",
    "\n",
    "sklearn_model.fit(x_data_train_norm,\n",
    "                  t_data_train)\n",
    "\n",
    "predict_value = sklearn_model.predict(x_data_test_norm)\n",
    "\n",
    "# 평가는 accuracy로 평가할 꺼예요!\n",
    "result = accuracy_score(t_data_test, predict_value)\n",
    "print(result)  # 0.9851666666666666\n",
    "\n",
    "# prediction 예측을 해 보아요!\n",
    "height = 184\n",
    "weight = 110\n",
    "my_state = np.array([[height, weight]])\n",
    "my_result = sklearn_model.predict(scaler.transform(my_state))\n",
    "print(my_result)  # [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "350/350 [==============================] - 1s 1ms/step - loss: 2.0686 - acc: 0.7007 - val_loss: 1.6002 - val_acc: 0.6371\n",
      "Epoch 2/200\n",
      "350/350 [==============================] - 0s 679us/step - loss: 0.9961 - acc: 0.7345 - val_loss: 0.4654 - val_acc: 0.8193\n",
      "Epoch 3/200\n",
      "350/350 [==============================] - 0s 694us/step - loss: 0.7411 - acc: 0.7711 - val_loss: 0.3397 - val_acc: 0.8443\n",
      "Epoch 4/200\n",
      "350/350 [==============================] - 0s 670us/step - loss: 0.6965 - acc: 0.7825 - val_loss: 0.3191 - val_acc: 0.8614\n",
      "Epoch 5/200\n",
      "350/350 [==============================] - 0s 624us/step - loss: 0.7285 - acc: 0.7944 - val_loss: 0.3948 - val_acc: 0.8761\n",
      "Epoch 6/200\n",
      "350/350 [==============================] - 0s 674us/step - loss: 0.6590 - acc: 0.8050 - val_loss: 0.6067 - val_acc: 0.7925\n",
      "Epoch 7/200\n",
      "350/350 [==============================] - 0s 698us/step - loss: 0.4907 - acc: 0.8273 - val_loss: 0.1676 - val_acc: 0.9268\n",
      "Epoch 8/200\n",
      "350/350 [==============================] - 0s 655us/step - loss: 0.7480 - acc: 0.8023 - val_loss: 0.3181 - val_acc: 0.8807\n",
      "Epoch 9/200\n",
      "350/350 [==============================] - 0s 713us/step - loss: 0.5083 - acc: 0.8375 - val_loss: 0.1843 - val_acc: 0.9093\n",
      "Epoch 10/200\n",
      "350/350 [==============================] - 0s 692us/step - loss: 0.5942 - acc: 0.8229 - val_loss: 0.3282 - val_acc: 0.8946\n",
      "Epoch 11/200\n",
      "350/350 [==============================] - 0s 844us/step - loss: 0.5688 - acc: 0.8401 - val_loss: 0.3820 - val_acc: 0.8807\n",
      "Epoch 12/200\n",
      "350/350 [==============================] - 0s 958us/step - loss: 0.3946 - acc: 0.8689 - val_loss: 0.3324 - val_acc: 0.8621\n",
      "Epoch 13/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5336 - acc: 0.8484 - val_loss: 0.3139 - val_acc: 0.8796TA: 0s - loss: 0.5584 - acc: 0.843\n",
      "Epoch 14/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.6256 - acc: 0.8351 - val_loss: 0.1851 - val_acc: 0.9104\n",
      "Epoch 15/200\n",
      "350/350 [==============================] - 0s 972us/step - loss: 0.5291 - acc: 0.8508 - val_loss: 1.4887 - val_acc: 0.7343\n",
      "Epoch 16/200\n",
      "350/350 [==============================] - 0s 871us/step - loss: 0.4387 - acc: 0.8774 - val_loss: 0.1564 - val_acc: 0.9225\n",
      "Epoch 17/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3447 - acc: 0.8907 - val_loss: 0.2187 - val_acc: 0.9011\n",
      "Epoch 18/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5953 - acc: 0.8602 - val_loss: 0.1555 - val_acc: 0.9346\n",
      "Epoch 19/200\n",
      "350/350 [==============================] - 1s 1ms/step - loss: 0.5086 - acc: 0.8628 - val_loss: 0.2851 - val_acc: 0.8954\n",
      "Epoch 20/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3835 - acc: 0.8848 - val_loss: 0.6753 - val_acc: 0.8007\n",
      "Epoch 21/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4171 - acc: 0.8796 - val_loss: 0.3366 - val_acc: 0.8861\n",
      "Epoch 22/200\n",
      "350/350 [==============================] - 0s 962us/step - loss: 0.4394 - acc: 0.8817 - val_loss: 0.3041 - val_acc: 0.9118\n",
      "Epoch 23/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5387 - acc: 0.8723 - val_loss: 1.9167 - val_acc: 0.7157\n",
      "Epoch 24/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4938 - acc: 0.8737 - val_loss: 0.1038 - val_acc: 0.9479\n",
      "Epoch 25/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3989 - acc: 0.8873 - val_loss: 0.1173 - val_acc: 0.9493\n",
      "Epoch 26/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4686 - acc: 0.8869 - val_loss: 0.4359 - val_acc: 0.8846\n",
      "Epoch 27/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4354 - acc: 0.8849 - val_loss: 0.2316 - val_acc: 0.9254\n",
      "Epoch 28/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3592 - acc: 0.8946 - val_loss: 0.8974 - val_acc: 0.8079\n",
      "Epoch 29/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5745 - acc: 0.8758 - val_loss: 0.0737 - val_acc: 0.9739\n",
      "Epoch 30/200\n",
      "350/350 [==============================] - 0s 969us/step - loss: 0.3549 - acc: 0.9018 - val_loss: 0.1964 - val_acc: 0.9164\n",
      "Epoch 31/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4230 - acc: 0.8939 - val_loss: 0.4352 - val_acc: 0.8857\n",
      "Epoch 32/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.6281 - acc: 0.8768 - val_loss: 0.9401 - val_acc: 0.8100\n",
      "Epoch 33/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4454 - acc: 0.8894 - val_loss: 0.2586 - val_acc: 0.9018\n",
      "Epoch 34/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3593 - acc: 0.9045 - val_loss: 0.0878 - val_acc: 0.9575\n",
      "Epoch 35/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4935 - acc: 0.8879 - val_loss: 0.4747 - val_acc: 0.8854\n",
      "Epoch 36/200\n",
      "350/350 [==============================] - 0s 910us/step - loss: 0.4207 - acc: 0.8952 - val_loss: 1.1843 - val_acc: 0.7729\n",
      "Epoch 37/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3314 - acc: 0.9069 - val_loss: 0.2523 - val_acc: 0.9150\n",
      "Epoch 38/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3668 - acc: 0.9001 - val_loss: 0.4798 - val_acc: 0.8686\n",
      "Epoch 39/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4871 - acc: 0.8857 - val_loss: 0.2918 - val_acc: 0.9064\n",
      "Epoch 40/200\n",
      "350/350 [==============================] - 0s 917us/step - loss: 0.4650 - acc: 0.8942 - val_loss: 0.1447 - val_acc: 0.9364\n",
      "Epoch 41/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4136 - acc: 0.9047 - val_loss: 0.2910 - val_acc: 0.9114\n",
      "Epoch 42/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4238 - acc: 0.8982 - val_loss: 0.0668 - val_acc: 0.9696\n",
      "Epoch 43/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3857 - acc: 0.9088 - val_loss: 0.0878 - val_acc: 0.9625\n",
      "Epoch 44/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5453 - acc: 0.8853 - val_loss: 0.1104 - val_acc: 0.9507\n",
      "Epoch 45/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5164 - acc: 0.8946 - val_loss: 0.3413 - val_acc: 0.8946\n",
      "Epoch 46/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4237 - acc: 0.9020 - val_loss: 0.4039 - val_acc: 0.9025\n",
      "Epoch 47/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3783 - acc: 0.9055 - val_loss: 0.0909 - val_acc: 0.9614\n",
      "Epoch 48/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3404 - acc: 0.9143 - val_loss: 0.2364 - val_acc: 0.9143\n",
      "Epoch 49/200\n",
      "350/350 [==============================] - 0s 996us/step - loss: 0.5611 - acc: 0.8893 - val_loss: 0.1188 - val_acc: 0.9636\n",
      "Epoch 50/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5163 - acc: 0.9028 - val_loss: 0.2730 - val_acc: 0.9182\n",
      "Epoch 51/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5713 - acc: 0.8999 - val_loss: 0.2773 - val_acc: 0.9079\n",
      "Epoch 52/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4792 - acc: 0.8999 - val_loss: 0.3625 - val_acc: 0.8982\n",
      "Epoch 53/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3403 - acc: 0.9154 - val_loss: 0.6475 - val_acc: 0.8646\n",
      "Epoch 54/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3588 - acc: 0.9137 - val_loss: 0.2182 - val_acc: 0.9179\n",
      "Epoch 55/200\n",
      "350/350 [==============================] - 0s 932us/step - loss: 0.4018 - acc: 0.9160 - val_loss: 0.1449 - val_acc: 0.9418\n",
      "Epoch 56/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3974 - acc: 0.9095 - val_loss: 0.3758 - val_acc: 0.9246\n",
      "Epoch 57/200\n",
      "350/350 [==============================] - 0s 975us/step - loss: 0.4595 - acc: 0.9029 - val_loss: 0.1359 - val_acc: 0.9454\n",
      "Epoch 58/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3913 - acc: 0.9109 - val_loss: 0.6895 - val_acc: 0.8639\n",
      "Epoch 59/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3054 - acc: 0.9226 - val_loss: 0.5175 - val_acc: 0.8779\n",
      "Epoch 60/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3982 - acc: 0.9090 - val_loss: 0.1016 - val_acc: 0.9543\n",
      "Epoch 61/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4243 - acc: 0.9111 - val_loss: 0.1401 - val_acc: 0.9479\n",
      "Epoch 62/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2654 - acc: 0.9278 - val_loss: 0.2491 - val_acc: 0.9186\n",
      "Epoch 63/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5345 - acc: 0.8980 - val_loss: 0.6785 - val_acc: 0.8721\n",
      "Epoch 64/200\n",
      "350/350 [==============================] - 0s 967us/step - loss: 0.3401 - acc: 0.9204 - val_loss: 0.0889 - val_acc: 0.9696\n",
      "Epoch 65/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5267 - acc: 0.8992 - val_loss: 0.2179 - val_acc: 0.9314\n",
      "Epoch 66/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4762 - acc: 0.9118 - val_loss: 0.3270 - val_acc: 0.9146\n",
      "Epoch 67/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2687 - acc: 0.9270 - val_loss: 0.1789 - val_acc: 0.9414\n",
      "Epoch 68/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2955 - acc: 0.9212 - val_loss: 0.0974 - val_acc: 0.9557\n",
      "Epoch 69/200\n",
      "350/350 [==============================] - 0s 904us/step - loss: 0.4362 - acc: 0.9097 - val_loss: 0.2694 - val_acc: 0.9168\n",
      "Epoch 70/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4066 - acc: 0.9132 - val_loss: 0.2669 - val_acc: 0.9396\n",
      "Epoch 71/200\n",
      "350/350 [==============================] - 0s 987us/step - loss: 0.5515 - acc: 0.9009 - val_loss: 0.3367 - val_acc: 0.9143\n",
      "Epoch 72/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3387 - acc: 0.9236 - val_loss: 0.7293 - val_acc: 0.8718\n",
      "Epoch 73/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5659 - acc: 0.8999 - val_loss: 0.0971 - val_acc: 0.9621\n",
      "Epoch 74/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4031 - acc: 0.9148 - val_loss: 0.1040 - val_acc: 0.9561\n",
      "Epoch 75/200\n",
      "350/350 [==============================] - 1s 1ms/step - loss: 0.4604 - acc: 0.9070 - val_loss: 0.3978 - val_acc: 0.8950\n",
      "Epoch 76/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4195 - acc: 0.9103 - val_loss: 0.8434 - val_acc: 0.8968\n",
      "Epoch 77/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4402 - acc: 0.9137 - val_loss: 0.0429 - val_acc: 0.9839\n",
      "Epoch 78/200\n",
      "350/350 [==============================] - 0s 885us/step - loss: 0.4570 - acc: 0.9105 - val_loss: 0.1468 - val_acc: 0.9618\n",
      "Epoch 79/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3354 - acc: 0.9245 - val_loss: 0.0629 - val_acc: 0.9725\n",
      "Epoch 80/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3040 - acc: 0.9288 - val_loss: 0.0457 - val_acc: 0.9796\n",
      "Epoch 81/200\n",
      "350/350 [==============================] - 0s 950us/step - loss: 0.2886 - acc: 0.9292 - val_loss: 0.1987 - val_acc: 0.9400\n",
      "Epoch 82/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3315 - acc: 0.9252 - val_loss: 0.0700 - val_acc: 0.9671\n",
      "Epoch 83/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2687 - acc: 0.9343 - val_loss: 0.0661 - val_acc: 0.9725\n",
      "Epoch 84/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3835 - acc: 0.9234 - val_loss: 0.2251 - val_acc: 0.9393\n",
      "Epoch 85/200\n",
      "350/350 [==============================] - 0s 814us/step - loss: 0.3602 - acc: 0.9215 - val_loss: 0.0797 - val_acc: 0.9625\n",
      "Epoch 86/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2149 - acc: 0.9391 - val_loss: 0.4252 - val_acc: 0.9000\n",
      "Epoch 87/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3574 - acc: 0.9241 - val_loss: 0.0846 - val_acc: 0.9621\n",
      "Epoch 88/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3059 - acc: 0.9292 - val_loss: 0.2219 - val_acc: 0.9339\n",
      "Epoch 89/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3361 - acc: 0.9258 - val_loss: 0.4770 - val_acc: 0.8968\n",
      "Epoch 90/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4587 - acc: 0.9142 - val_loss: 0.4373 - val_acc: 0.9064\n",
      "Epoch 91/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4438 - acc: 0.9241 - val_loss: 0.2112 - val_acc: 0.9500\n",
      "Epoch 92/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4121 - acc: 0.9196 - val_loss: 0.1627 - val_acc: 0.9529\n",
      "Epoch 93/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4617 - acc: 0.9139 - val_loss: 0.3061 - val_acc: 0.9168\n",
      "Epoch 94/200\n",
      "350/350 [==============================] - 0s 990us/step - loss: 0.3354 - acc: 0.9246 - val_loss: 0.1876 - val_acc: 0.9457\n",
      "Epoch 95/200\n",
      "350/350 [==============================] - 0s 958us/step - loss: 0.4213 - acc: 0.9163 - val_loss: 0.9328 - val_acc: 0.8668\n",
      "Epoch 96/200\n",
      "350/350 [==============================] - 0s 799us/step - loss: 0.3827 - acc: 0.9235 - val_loss: 1.9042 - val_acc: 0.8075\n",
      "Epoch 97/200\n",
      "350/350 [==============================] - 0s 909us/step - loss: 0.4131 - acc: 0.9212 - val_loss: 0.2989 - val_acc: 0.9318\n",
      "Epoch 98/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3286 - acc: 0.9282 - val_loss: 0.2912 - val_acc: 0.9325\n",
      "Epoch 99/200\n",
      "350/350 [==============================] - 0s 957us/step - loss: 0.2379 - acc: 0.9396 - val_loss: 2.1585 - val_acc: 0.8221\n",
      "Epoch 100/200\n",
      "350/350 [==============================] - 0s 989us/step - loss: 0.3532 - acc: 0.9325 - val_loss: 1.7351 - val_acc: 0.7918\n",
      "Epoch 101/200\n",
      "350/350 [==============================] - 0s 934us/step - loss: 0.4023 - acc: 0.9237 - val_loss: 0.3670 - val_acc: 0.9161\n",
      "Epoch 102/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4520 - acc: 0.9172 - val_loss: 1.7751 - val_acc: 0.7904\n",
      "Epoch 103/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2908 - acc: 0.9349 - val_loss: 0.1681 - val_acc: 0.9461\n",
      "Epoch 104/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4562 - acc: 0.9150 - val_loss: 0.1111 - val_acc: 0.9629\n",
      "Epoch 105/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5102 - acc: 0.9133 - val_loss: 0.2101 - val_acc: 0.9332\n",
      "Epoch 106/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3428 - acc: 0.9314 - val_loss: 0.0348 - val_acc: 0.9811\n",
      "Epoch 107/200\n",
      "350/350 [==============================] - 0s 990us/step - loss: 0.2944 - acc: 0.9341 - val_loss: 0.0809 - val_acc: 0.9654\n",
      "Epoch 108/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2638 - acc: 0.9393 - val_loss: 0.0351 - val_acc: 0.9854\n",
      "Epoch 109/200\n",
      "350/350 [==============================] - 0s 815us/step - loss: 0.5220 - acc: 0.9154 - val_loss: 0.0653 - val_acc: 0.9793\n",
      "Epoch 110/200\n",
      "350/350 [==============================] - 0s 844us/step - loss: 0.3678 - acc: 0.9279 - val_loss: 0.1334 - val_acc: 0.9557\n",
      "Epoch 111/200\n",
      "350/350 [==============================] - 0s 903us/step - loss: 0.3745 - acc: 0.9266 - val_loss: 0.1154 - val_acc: 0.9679\n",
      "Epoch 112/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.6934 - acc: 0.9081 - val_loss: 0.1645 - val_acc: 0.9614\n",
      "Epoch 113/200\n",
      "350/350 [==============================] - 0s 963us/step - loss: 0.3797 - acc: 0.9293 - val_loss: 0.0676 - val_acc: 0.9679\n",
      "Epoch 114/200\n",
      "350/350 [==============================] - 0s 876us/step - loss: 0.4634 - acc: 0.9218 - val_loss: 0.4631 - val_acc: 0.9004\n",
      "Epoch 115/200\n",
      "350/350 [==============================] - 0s 867us/step - loss: 0.4947 - acc: 0.9136 - val_loss: 0.4756 - val_acc: 0.9104\n",
      "Epoch 116/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2650 - acc: 0.9379 - val_loss: 0.6632 - val_acc: 0.8914\n",
      "Epoch 117/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5725 - acc: 0.9115 - val_loss: 0.1016 - val_acc: 0.9589\n",
      "Epoch 118/200\n",
      "350/350 [==============================] - 0s 862us/step - loss: 0.2562 - acc: 0.9423 - val_loss: 0.0472 - val_acc: 0.9793\n",
      "Epoch 119/200\n",
      "350/350 [==============================] - 0s 957us/step - loss: 0.3328 - acc: 0.9299 - val_loss: 0.2614 - val_acc: 0.9343\n",
      "Epoch 120/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2706 - acc: 0.9398 - val_loss: 0.1197 - val_acc: 0.9568\n",
      "Epoch 121/200\n",
      "350/350 [==============================] - 0s 990us/step - loss: 0.6144 - acc: 0.9094 - val_loss: 0.2938 - val_acc: 0.9282\n",
      "Epoch 122/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3456 - acc: 0.9335 - val_loss: 0.5818 - val_acc: 0.8936\n",
      "Epoch 123/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.6287 - acc: 0.9063 - val_loss: 1.0218 - val_acc: 0.8518\n",
      "Epoch 124/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3627 - acc: 0.9298 - val_loss: 0.0607 - val_acc: 0.9782\n",
      "Epoch 125/200\n",
      "350/350 [==============================] - 0s 874us/step - loss: 0.2764 - acc: 0.9369 - val_loss: 0.6064 - val_acc: 0.9161\n",
      "Epoch 126/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2756 - acc: 0.9388 - val_loss: 0.1591 - val_acc: 0.9557\n",
      "Epoch 127/200\n",
      "350/350 [==============================] - 0s 991us/step - loss: 0.3516 - acc: 0.9301 - val_loss: 0.0685 - val_acc: 0.9721\n",
      "Epoch 128/200\n",
      "350/350 [==============================] - 0s 955us/step - loss: 0.3743 - acc: 0.9309 - val_loss: 0.2899 - val_acc: 0.9368\n",
      "Epoch 129/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4855 - acc: 0.9162 - val_loss: 0.1113 - val_acc: 0.9589\n",
      "Epoch 130/200\n",
      "350/350 [==============================] - 0s 837us/step - loss: 0.2689 - acc: 0.9404 - val_loss: 0.5956 - val_acc: 0.9186\n",
      "Epoch 131/200\n",
      "350/350 [==============================] - 0s 998us/step - loss: 0.5307 - acc: 0.9156 - val_loss: 0.2292 - val_acc: 0.9411\n",
      "Epoch 132/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3889 - acc: 0.9273 - val_loss: 0.4111 - val_acc: 0.9204\n",
      "Epoch 133/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4564 - acc: 0.9279 - val_loss: 0.0889 - val_acc: 0.9629\n",
      "Epoch 134/200\n",
      "350/350 [==============================] - 0s 885us/step - loss: 0.2684 - acc: 0.9451 - val_loss: 0.6055 - val_acc: 0.8961\n",
      "Epoch 135/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3358 - acc: 0.9321 - val_loss: 0.7623 - val_acc: 0.9086\n",
      "Epoch 136/200\n",
      "350/350 [==============================] - 0s 990us/step - loss: 0.4851 - acc: 0.9254 - val_loss: 0.5897 - val_acc: 0.9068\n",
      "Epoch 137/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.6344 - acc: 0.9093 - val_loss: 0.2640 - val_acc: 0.9311\n",
      "Epoch 138/200\n",
      "350/350 [==============================] - 0s 918us/step - loss: 0.3153 - acc: 0.9366 - val_loss: 0.5637 - val_acc: 0.9057\n",
      "Epoch 139/200\n",
      "350/350 [==============================] - 0s 844us/step - loss: 0.3774 - acc: 0.9296 - val_loss: 0.3395 - val_acc: 0.9293\n",
      "Epoch 140/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5173 - acc: 0.9209 - val_loss: 0.2869 - val_acc: 0.9339\n",
      "Epoch 141/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3108 - acc: 0.9388 - val_loss: 0.0505 - val_acc: 0.9789\n",
      "Epoch 142/200\n",
      "350/350 [==============================] - 0s 840us/step - loss: 0.3529 - acc: 0.9335 - val_loss: 0.8960 - val_acc: 0.8836\n",
      "Epoch 143/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2693 - acc: 0.9431 - val_loss: 0.6233 - val_acc: 0.9193\n",
      "Epoch 144/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3409 - acc: 0.9361 - val_loss: 0.1594 - val_acc: 0.9564\n",
      "Epoch 145/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4660 - acc: 0.9269 - val_loss: 0.5068 - val_acc: 0.9004\n",
      "Epoch 146/200\n",
      "350/350 [==============================] - 0s 842us/step - loss: 0.6983 - acc: 0.9101 - val_loss: 0.0486 - val_acc: 0.9821\n",
      "Epoch 147/200\n",
      "350/350 [==============================] - 0s 810us/step - loss: 0.4000 - acc: 0.9306 - val_loss: 0.0491 - val_acc: 0.9804\n",
      "Epoch 148/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2117 - acc: 0.9515 - val_loss: 0.6007 - val_acc: 0.9043\n",
      "Epoch 149/200\n",
      "350/350 [==============================] - 0s 949us/step - loss: 0.3374 - acc: 0.9329 - val_loss: 0.3060 - val_acc: 0.9307\n",
      "Epoch 150/200\n",
      "350/350 [==============================] - 0s 998us/step - loss: 0.5542 - acc: 0.9133 - val_loss: 0.4136 - val_acc: 0.9132\n",
      "Epoch 151/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.6964 - acc: 0.9055 - val_loss: 0.7501 - val_acc: 0.9143\n",
      "Epoch 152/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4427 - acc: 0.9273 - val_loss: 0.1384 - val_acc: 0.9575\n",
      "Epoch 153/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.9496 - val_loss: 0.0941 - val_acc: 0.9646\n",
      "Epoch 154/200\n",
      "350/350 [==============================] - 0s 983us/step - loss: 0.2035 - acc: 0.9528 - val_loss: 1.0471 - val_acc: 0.8664\n",
      "Epoch 155/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5337 - acc: 0.9174 - val_loss: 0.1559 - val_acc: 0.9550\n",
      "Epoch 156/200\n",
      "350/350 [==============================] - 0s 912us/step - loss: 0.3634 - acc: 0.9334 - val_loss: 0.2617 - val_acc: 0.9386\n",
      "Epoch 157/200\n",
      "350/350 [==============================] - 0s 975us/step - loss: 0.3292 - acc: 0.9373 - val_loss: 0.0347 - val_acc: 0.9861\n",
      "Epoch 158/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3989 - acc: 0.9327 - val_loss: 0.2580 - val_acc: 0.9464\n",
      "Epoch 159/200\n",
      "350/350 [==============================] - 0s 849us/step - loss: 0.3817 - acc: 0.9303 - val_loss: 1.5449 - val_acc: 0.8289\n",
      "Epoch 160/200\n",
      "350/350 [==============================] - 0s 910us/step - loss: 0.6200 - acc: 0.9205 - val_loss: 1.0474 - val_acc: 0.8807\n",
      "Epoch 161/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4126 - acc: 0.9331 - val_loss: 0.3043 - val_acc: 0.9314\n",
      "Epoch 162/200\n",
      "350/350 [==============================] - 0s 961us/step - loss: 0.3962 - acc: 0.9339 - val_loss: 0.0980 - val_acc: 0.9671\n",
      "Epoch 163/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2496 - acc: 0.9466 - val_loss: 0.9916 - val_acc: 0.8693\n",
      "Epoch 164/200\n",
      "350/350 [==============================] - 0s 918us/step - loss: 0.3552 - acc: 0.9347 - val_loss: 0.0946 - val_acc: 0.9625\n",
      "Epoch 165/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3343 - acc: 0.9391 - val_loss: 0.0619 - val_acc: 0.9732\n",
      "Epoch 166/200\n",
      "350/350 [==============================] - 0s 962us/step - loss: 0.5464 - acc: 0.9228 - val_loss: 0.9746 - val_acc: 0.8771\n",
      "Epoch 167/200\n",
      "350/350 [==============================] - 0s 886us/step - loss: 0.4470 - acc: 0.9280 - val_loss: 0.1125 - val_acc: 0.9689\n",
      "Epoch 168/200\n",
      "350/350 [==============================] - 0s 908us/step - loss: 0.4746 - acc: 0.9256 - val_loss: 1.4063 - val_acc: 0.8646\n",
      "Epoch 169/200\n",
      "350/350 [==============================] - 0s 919us/step - loss: 0.3843 - acc: 0.9365 - val_loss: 0.3548 - val_acc: 0.9261\n",
      "Epoch 170/200\n",
      "350/350 [==============================] - 0s 910us/step - loss: 0.3043 - acc: 0.9412 - val_loss: 0.1831 - val_acc: 0.9507\n",
      "Epoch 171/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4329 - acc: 0.9280 - val_loss: 0.4800 - val_acc: 0.9146\n",
      "Epoch 172/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3185 - acc: 0.9433 - val_loss: 0.2108 - val_acc: 0.9479\n",
      "Epoch 173/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5855 - acc: 0.9212 - val_loss: 0.1614 - val_acc: 0.9625\n",
      "Epoch 174/200\n",
      "350/350 [==============================] - 0s 810us/step - loss: 0.4268 - acc: 0.9303 - val_loss: 0.0663 - val_acc: 0.9696\n",
      "Epoch 175/200\n",
      "350/350 [==============================] - 0s 914us/step - loss: 0.3556 - acc: 0.9346 - val_loss: 0.0584 - val_acc: 0.9786\n",
      "Epoch 176/200\n",
      "350/350 [==============================] - 0s 804us/step - loss: 0.2459 - acc: 0.9463 - val_loss: 0.1149 - val_acc: 0.9618\n",
      "Epoch 177/200\n",
      "350/350 [==============================] - 0s 987us/step - loss: 0.3073 - acc: 0.9406 - val_loss: 0.1307 - val_acc: 0.9575\n",
      "Epoch 178/200\n",
      "350/350 [==============================] - 0s 810us/step - loss: 0.5104 - acc: 0.9266 - val_loss: 0.0369 - val_acc: 0.9846\n",
      "Epoch 179/200\n",
      "350/350 [==============================] - 0s 804us/step - loss: 0.4048 - acc: 0.9324 - val_loss: 1.4362 - val_acc: 0.8489\n",
      "Epoch 180/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4026 - acc: 0.9316 - val_loss: 0.1692 - val_acc: 0.9507\n",
      "Epoch 181/200\n",
      "350/350 [==============================] - 0s 948us/step - loss: 0.5546 - acc: 0.9285 - val_loss: 0.0645 - val_acc: 0.9743\n",
      "Epoch 182/200\n",
      "350/350 [==============================] - 0s 997us/step - loss: 0.2797 - acc: 0.9471 - val_loss: 0.2661 - val_acc: 0.9439\n",
      "Epoch 183/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3459 - acc: 0.9366 - val_loss: 0.2655 - val_acc: 0.9429\n",
      "Epoch 184/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4341 - acc: 0.9279 - val_loss: 0.5823 - val_acc: 0.9204\n",
      "Epoch 185/200\n",
      "350/350 [==============================] - 0s 835us/step - loss: 0.3743 - acc: 0.9370 - val_loss: 0.0379 - val_acc: 0.9846\n",
      "Epoch 186/200\n",
      "350/350 [==============================] - 0s 927us/step - loss: 0.3674 - acc: 0.9388 - val_loss: 0.0368 - val_acc: 0.9836\n",
      "Epoch 187/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.3029 - acc: 0.9436 - val_loss: 1.2686 - val_acc: 0.8679\n",
      "Epoch 188/200\n",
      "350/350 [==============================] - 0s 847us/step - loss: 0.3868 - acc: 0.9344 - val_loss: 0.0661 - val_acc: 0.9707\n",
      "Epoch 189/200\n",
      "350/350 [==============================] - 0s 842us/step - loss: 0.3617 - acc: 0.9413 - val_loss: 0.0502 - val_acc: 0.9821\n",
      "Epoch 190/200\n",
      "350/350 [==============================] - 0s 834us/step - loss: 0.5549 - acc: 0.9254 - val_loss: 0.1320 - val_acc: 0.9639\n",
      "Epoch 191/200\n",
      "350/350 [==============================] - 0s 827us/step - loss: 0.4157 - acc: 0.9346 - val_loss: 0.2130 - val_acc: 0.9521\n",
      "Epoch 192/200\n",
      "350/350 [==============================] - 0s 903us/step - loss: 0.4204 - acc: 0.9314 - val_loss: 0.3054 - val_acc: 0.9421\n",
      "Epoch 193/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.4572 - acc: 0.9312 - val_loss: 0.1571 - val_acc: 0.9575\n",
      "Epoch 194/200\n",
      "350/350 [==============================] - 0s 944us/step - loss: 0.3055 - acc: 0.9486 - val_loss: 0.3228 - val_acc: 0.9343\n",
      "Epoch 195/200\n",
      "350/350 [==============================] - 0s 791us/step - loss: 0.2388 - acc: 0.9526 - val_loss: 0.0456 - val_acc: 0.9839\n",
      "Epoch 196/200\n",
      "350/350 [==============================] - 0s 802us/step - loss: 0.3368 - acc: 0.9418 - val_loss: 0.6275 - val_acc: 0.9018\n",
      "Epoch 197/200\n",
      "350/350 [==============================] - 0s 779us/step - loss: 0.4565 - acc: 0.9324 - val_loss: 0.7115 - val_acc: 0.8932\n",
      "Epoch 198/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.2881 - acc: 0.9452 - val_loss: 0.6431 - val_acc: 0.9054\n",
      "Epoch 199/200\n",
      "350/350 [==============================] - 0s 996us/step - loss: 0.3742 - acc: 0.9356 - val_loss: 0.1518 - val_acc: 0.9582\n",
      "Epoch 200/200\n",
      "350/350 [==============================] - 0s 1ms/step - loss: 0.5183 - acc: 0.9258 - val_loss: 0.1645 - val_acc: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2678571c940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터는 위에서 불러오고 전처리까지 진행이 끝났어요!\n",
    "\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(2,)))\n",
    "keras_model.add(Dense(units=3,\n",
    "                      activation='softmax'))\n",
    "\n",
    "keras_model.compile(optimizer=Adam(learning_rate=1e-1),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "keras_model.fit(x_data_train_norm,\n",
    "                t_data_train,\n",
    "                epochs=200,\n",
    "                verbose=1,\n",
    "                validation_split=0.2)\n",
    "\n",
    "# learning_rate=1e-1\n",
    "# loss: 0.4273 - acc: 0.9318 - val_loss: 0.0375 - val_acc: 0.9846\n",
    "\n",
    "# learning_rate=1e-2\n",
    "# loss: 0.1033 - acc: 0.9553 - val_loss: 0.1133 - val_acc: 0.9464\n",
    "\n",
    "# learning_rate = 1e-4\n",
    "# loss: 0.4016 - acc: 0.8069 - val_loss: 0.3792 - val_acc: 0.8179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 638us/step - loss: 0.1790 - acc: 0.9558\n",
      "[0.17895285785198212, 0.9558333158493042]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation을 해야 해요!\n",
    "model_eval = keras_model.evaluate(x_data_test_norm,\n",
    "                                  t_data_test)\n",
    "print(model_eval)  # [0.03814725577831268, 0.9838333129882812]\n",
    "\n",
    "# prediction 예측을 해 보아요!\n",
    "height = 184\n",
    "weight = 110\n",
    "my_state = np.array([[height, weight]])\n",
    "my_result = keras_model.predict(scaler.transform(my_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        thin       0.50      1.00      0.67         1\n",
      "      normal       0.00      0.00      0.00         1\n",
      "         fat       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.50      0.56      0.49         5\n",
      "weighted avg       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 다른 예제를 구현해 보아요! (Iris-붓꽃예제, MNIST-손글씨숫자예제)\n",
    "# 추가적으로 유용한 함수 하나 소개할꺼예요!\n",
    "# 지금까지 우리가 evaluation할때 accuracy만 구했어요!\n",
    "# 그런데 사실 presision, recall, f1과 같은 평가지표도 많이 사용되요!\n",
    "# 예제로 알아보아요!\n",
    "\n",
    "t_true = [0, 1, 2, 2, 2]\n",
    "t_pred = [0, 0, 2, 2, 1]\n",
    "\n",
    "label_names = ['thin', 'normal', 'fat']\n",
    "\n",
    "print(classification_report(t_true, t_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Classification (다중분류)\n",
    "# 첫번째 예제는 BMI예제\n",
    "\n",
    "# 두번째 예제는 Iris예제(붓꽃) 품종구별하는 예제!\n",
    "# 붓꽃은 3가지 종이 있어요!\n",
    "# setosa(세토사), versicolor(버시칼라), verginica(버지니카)\n",
    "# 붓꽃의 꽃받침과 꽃잎의 길이와 너비에 따라서 품종이 결정되요!\n",
    "\n",
    "# 데이터는 총 150개의 데이터가 있어요!\n",
    "# 꽃받침(sepal), 꽃잎(petal)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "# print(iris.data)  # x_data 즉, 꽃받침의 길이와 너비, 꽃잎의 길이와 너비\n",
    "# print(iris.feature_names)  # ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "# print(iris.target)\n",
    "\n",
    "df = pd.DataFrame(iris.data,\n",
    "                  columns=iris.feature_names)\n",
    "df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "# display(df)  # 150 rows × 4 columns\n",
    "\n",
    "# 혹시 결측치가 존재하나요?\n",
    "# df.isnull().sum()  # 결측치는 존재하지 않아요!\n",
    "\n",
    "df['target'] = iris.target\n",
    "\n",
    "# 중복행이 있을 수 있어요! 중복데이터가 있을 수 있어요!\n",
    "df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "# display(df)  # 149 rows × 5 columns\n",
    "\n",
    "# display(df.corr())   # DataFrame을 이용한 상관관계분석\n",
    "\n",
    "x_data = df.drop('target', axis=1, inplace=False).values\n",
    "t_data = df['target'].values\n",
    "\n",
    "# 이상치 체크도 해야해요...원래는 해야해요!\n",
    "# 정규화 처리를 해야 해요!\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "x_data_train_norm, x_data_test_norm, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data_norm,\n",
    "                 t_data,\n",
    "                 test_size=0.3,\n",
    "                 stratify=t_data,\n",
    "                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 1.1607 - acc: 0.1928 - val_loss: 1.1366 - val_acc: 0.1905\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9911 - acc: 0.3614 - val_loss: 1.0078 - val_acc: 0.1905\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8726 - acc: 0.5301 - val_loss: 0.8663 - val_acc: 0.6190\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7621 - acc: 0.6747 - val_loss: 0.7533 - val_acc: 0.6667\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6769 - acc: 0.6747 - val_loss: 0.6530 - val_acc: 0.6667\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6102 - acc: 0.7349 - val_loss: 0.5759 - val_acc: 0.7143\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5610 - acc: 0.8434 - val_loss: 0.5247 - val_acc: 0.8095\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5229 - acc: 0.8554 - val_loss: 0.4924 - val_acc: 0.8095\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4876 - acc: 0.8554 - val_loss: 0.4804 - val_acc: 0.7619\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4644 - acc: 0.8434 - val_loss: 0.4623 - val_acc: 0.8095\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4432 - acc: 0.8554 - val_loss: 0.4379 - val_acc: 0.8095\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4246 - acc: 0.8675 - val_loss: 0.4237 - val_acc: 0.8571\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4120 - acc: 0.8916 - val_loss: 0.3982 - val_acc: 0.9048\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3974 - acc: 0.9157 - val_loss: 0.3877 - val_acc: 0.9048\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3863 - acc: 0.8795 - val_loss: 0.3834 - val_acc: 0.9048\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3724 - acc: 0.8916 - val_loss: 0.3751 - val_acc: 0.9048\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3629 - acc: 0.9036 - val_loss: 0.3642 - val_acc: 0.9048\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3537 - acc: 0.8795 - val_loss: 0.3605 - val_acc: 0.9048\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3457 - acc: 0.8795 - val_loss: 0.3533 - val_acc: 0.9048\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3379 - acc: 0.9036 - val_loss: 0.3411 - val_acc: 0.9048\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3323 - acc: 0.9157 - val_loss: 0.3327 - val_acc: 0.9048\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3252 - acc: 0.9157 - val_loss: 0.3246 - val_acc: 0.9524\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3198 - acc: 0.9157 - val_loss: 0.3227 - val_acc: 0.9048\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3126 - acc: 0.9157 - val_loss: 0.3268 - val_acc: 0.9048\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3079 - acc: 0.9036 - val_loss: 0.3309 - val_acc: 0.9048\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3048 - acc: 0.8916 - val_loss: 0.3230 - val_acc: 0.9048\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2994 - acc: 0.8916 - val_loss: 0.3053 - val_acc: 0.9524\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2960 - acc: 0.9157 - val_loss: 0.2989 - val_acc: 0.9524\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2887 - acc: 0.9157 - val_loss: 0.3044 - val_acc: 0.9048\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2879 - acc: 0.9036 - val_loss: 0.3088 - val_acc: 0.9048\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2813 - acc: 0.9036 - val_loss: 0.2955 - val_acc: 0.9048\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2778 - acc: 0.9277 - val_loss: 0.2820 - val_acc: 0.9524\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2763 - acc: 0.9518 - val_loss: 0.2772 - val_acc: 0.9524\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2741 - acc: 0.9157 - val_loss: 0.2805 - val_acc: 0.9524\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2668 - acc: 0.9157 - val_loss: 0.2811 - val_acc: 0.9524\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2628 - acc: 0.9157 - val_loss: 0.2765 - val_acc: 0.9524\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2597 - acc: 0.9157 - val_loss: 0.2743 - val_acc: 0.9524\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2565 - acc: 0.9157 - val_loss: 0.2703 - val_acc: 0.9524\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2536 - acc: 0.9157 - val_loss: 0.2642 - val_acc: 0.9524\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2507 - acc: 0.9157 - val_loss: 0.2597 - val_acc: 0.9524\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2484 - acc: 0.9277 - val_loss: 0.2580 - val_acc: 0.9524\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2452 - acc: 0.9157 - val_loss: 0.2544 - val_acc: 0.9524\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2426 - acc: 0.9157 - val_loss: 0.2489 - val_acc: 0.9524\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2405 - acc: 0.9277 - val_loss: 0.2472 - val_acc: 0.9524\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2409 - acc: 0.9398 - val_loss: 0.2419 - val_acc: 0.9524\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2423 - acc: 0.9277 - val_loss: 0.2448 - val_acc: 0.9524\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2338 - acc: 0.9277 - val_loss: 0.2344 - val_acc: 0.9524\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2327 - acc: 0.9398 - val_loss: 0.2326 - val_acc: 0.9524\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2298 - acc: 0.9518 - val_loss: 0.2371 - val_acc: 0.9524\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2263 - acc: 0.9277 - val_loss: 0.2355 - val_acc: 0.9524\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2240 - acc: 0.9277 - val_loss: 0.2355 - val_acc: 0.9524\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2251 - acc: 0.9157 - val_loss: 0.2356 - val_acc: 0.9524\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2197 - acc: 0.9036 - val_loss: 0.2242 - val_acc: 0.9524\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2197 - acc: 0.9518 - val_loss: 0.2160 - val_acc: 0.9524\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.3148 - acc: 0.906 - 0s 9ms/step - loss: 0.2177 - acc: 0.9398 - val_loss: 0.2169 - val_acc: 0.9524\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2138 - acc: 0.9398 - val_loss: 0.2222 - val_acc: 0.9524\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2146 - acc: 0.8916 - val_loss: 0.2304 - val_acc: 0.9524\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2135 - acc: 0.9036 - val_loss: 0.2234 - val_acc: 0.9524\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2095 - acc: 0.9277 - val_loss: 0.2128 - val_acc: 0.9524\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2072 - acc: 0.9398 - val_loss: 0.2028 - val_acc: 1.0000\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2101 - acc: 0.9398 - val_loss: 0.2002 - val_acc: 1.0000\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2056 - acc: 0.9518 - val_loss: 0.2092 - val_acc: 0.9524\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2025 - acc: 0.9398 - val_loss: 0.2174 - val_acc: 0.9524\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2049 - acc: 0.9157 - val_loss: 0.2135 - val_acc: 0.9524\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2009 - acc: 0.9277 - val_loss: 0.1994 - val_acc: 0.9524\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2025 - acc: 0.9277 - val_loss: 0.1893 - val_acc: 1.0000\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1990 - acc: 0.9398 - val_loss: 0.1904 - val_acc: 1.0000\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1967 - acc: 0.9518 - val_loss: 0.1955 - val_acc: 0.9524\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1947 - acc: 0.9277 - val_loss: 0.2042 - val_acc: 0.9524\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1966 - acc: 0.9398 - val_loss: 0.2002 - val_acc: 0.9524\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1922 - acc: 0.9277 - val_loss: 0.1848 - val_acc: 1.0000\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1900 - acc: 0.9518 - val_loss: 0.1797 - val_acc: 1.0000\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1915 - acc: 0.9398 - val_loss: 0.1783 - val_acc: 1.0000\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1893 - acc: 0.9398 - val_loss: 0.1797 - val_acc: 1.0000\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1891 - acc: 0.9398 - val_loss: 0.1892 - val_acc: 0.9524\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1867 - acc: 0.9398 - val_loss: 0.1906 - val_acc: 0.9524\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1856 - acc: 0.9157 - val_loss: 0.1818 - val_acc: 0.9524\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1836 - acc: 0.9277 - val_loss: 0.1725 - val_acc: 1.0000\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1826 - acc: 0.9518 - val_loss: 0.1702 - val_acc: 1.0000\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1809 - acc: 0.9518 - val_loss: 0.1727 - val_acc: 1.0000\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1806 - acc: 0.9398 - val_loss: 0.1761 - val_acc: 0.9524\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1786 - acc: 0.9277 - val_loss: 0.1716 - val_acc: 0.9524\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1770 - acc: 0.9277 - val_loss: 0.1682 - val_acc: 1.0000\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1765 - acc: 0.9518 - val_loss: 0.1650 - val_acc: 1.0000\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1749 - acc: 0.9518 - val_loss: 0.1650 - val_acc: 1.0000\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1745 - acc: 0.9518 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1751 - acc: 0.9518 - val_loss: 0.1657 - val_acc: 0.9524\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1729 - acc: 0.9398 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1712 - acc: 0.9518 - val_loss: 0.1550 - val_acc: 1.0000\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1728 - acc: 0.9398 - val_loss: 0.1525 - val_acc: 1.0000\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1708 - acc: 0.9398 - val_loss: 0.1572 - val_acc: 1.0000\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1686 - acc: 0.9518 - val_loss: 0.1595 - val_acc: 0.9524\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1695 - acc: 0.9277 - val_loss: 0.1548 - val_acc: 1.0000\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1697 - acc: 0.9398 - val_loss: 0.1576 - val_acc: 0.9524\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1676 - acc: 0.9398 - val_loss: 0.1492 - val_acc: 1.0000\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1647 - acc: 0.9518 - val_loss: 0.1474 - val_acc: 1.0000\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1652 - acc: 0.9518 - val_loss: 0.1452 - val_acc: 1.0000\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1648 - acc: 0.9518 - val_loss: 0.1456 - val_acc: 1.0000\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1625 - acc: 0.9518 - val_loss: 0.1441 - val_acc: 1.0000\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1615 - acc: 0.9639 - val_loss: 0.1457 - val_acc: 1.0000\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1607 - acc: 0.9518 - val_loss: 0.1462 - val_acc: 1.0000\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1622 - acc: 0.9398 - val_loss: 0.1451 - val_acc: 1.0000\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1578 - acc: 0.9518 - val_loss: 0.1379 - val_acc: 1.0000\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1579 - acc: 0.9518 - val_loss: 0.1339 - val_acc: 1.0000\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1615 - acc: 0.9398 - val_loss: 0.1332 - val_acc: 1.0000\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1599 - acc: 0.9398 - val_loss: 0.1337 - val_acc: 1.0000\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1559 - acc: 0.9518 - val_loss: 0.1404 - val_acc: 1.0000\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1551 - acc: 0.9518 - val_loss: 0.1491 - val_acc: 0.9524\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1630 - acc: 0.9518 - val_loss: 0.1508 - val_acc: 0.9524\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1587 - acc: 0.9518 - val_loss: 0.1332 - val_acc: 1.0000\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1531 - acc: 0.9639 - val_loss: 0.1290 - val_acc: 1.0000\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1543 - acc: 0.9518 - val_loss: 0.1283 - val_acc: 1.0000\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1539 - acc: 0.9639 - val_loss: 0.1321 - val_acc: 1.0000\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1521 - acc: 0.9518 - val_loss: 0.1340 - val_acc: 1.0000\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1505 - acc: 0.9518 - val_loss: 0.1300 - val_acc: 1.0000\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1506 - acc: 0.9518 - val_loss: 0.1251 - val_acc: 1.0000\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1505 - acc: 0.9639 - val_loss: 0.1220 - val_acc: 1.0000\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1507 - acc: 0.9518 - val_loss: 0.1232 - val_acc: 1.0000\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1480 - acc: 0.9518 - val_loss: 0.1256 - val_acc: 1.0000\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1480 - acc: 0.9518 - val_loss: 0.1298 - val_acc: 1.0000\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1484 - acc: 0.9518 - val_loss: 0.1285 - val_acc: 1.0000\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1478 - acc: 0.9518 - val_loss: 0.1204 - val_acc: 1.0000\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1464 - acc: 0.9518 - val_loss: 0.1169 - val_acc: 1.0000\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1459 - acc: 0.9639 - val_loss: 0.1173 - val_acc: 1.0000\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1442 - acc: 0.9518 - val_loss: 0.1197 - val_acc: 1.0000\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1433 - acc: 0.9518 - val_loss: 0.1237 - val_acc: 1.0000\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1447 - acc: 0.9518 - val_loss: 0.1244 - val_acc: 1.0000\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1449 - acc: 0.9398 - val_loss: 0.1185 - val_acc: 1.0000\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1423 - acc: 0.9518 - val_loss: 0.1157 - val_acc: 1.0000\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1419 - acc: 0.9639 - val_loss: 0.1139 - val_acc: 1.0000\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1419 - acc: 0.9639 - val_loss: 0.1144 - val_acc: 1.0000\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1408 - acc: 0.9518 - val_loss: 0.1157 - val_acc: 1.0000\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1405 - acc: 0.9518 - val_loss: 0.1159 - val_acc: 1.0000\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1400 - acc: 0.9518 - val_loss: 0.1134 - val_acc: 1.0000\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1402 - acc: 0.9518 - val_loss: 0.1121 - val_acc: 1.0000\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1391 - acc: 0.9518 - val_loss: 0.1139 - val_acc: 1.0000\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1402 - acc: 0.9518 - val_loss: 0.1135 - val_acc: 1.0000\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1393 - acc: 0.9518 - val_loss: 0.1078 - val_acc: 1.0000\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1380 - acc: 0.9639 - val_loss: 0.1075 - val_acc: 1.0000\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1372 - acc: 0.9639 - val_loss: 0.1070 - val_acc: 1.0000\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1371 - acc: 0.9639 - val_loss: 0.1068 - val_acc: 1.0000\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1360 - acc: 0.9518 - val_loss: 0.1100 - val_acc: 1.0000\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1366 - acc: 0.9518 - val_loss: 0.1092 - val_acc: 1.0000\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1356 - acc: 0.9518 - val_loss: 0.1105 - val_acc: 1.0000\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1361 - acc: 0.9518 - val_loss: 0.1082 - val_acc: 1.0000\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1340 - acc: 0.9518 - val_loss: 0.1022 - val_acc: 1.0000\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1342 - acc: 0.9639 - val_loss: 0.1007 - val_acc: 1.0000\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1370 - acc: 0.9518 - val_loss: 0.0998 - val_acc: 1.0000\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1334 - acc: 0.9639 - val_loss: 0.1027 - val_acc: 1.0000\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1328 - acc: 0.9518 - val_loss: 0.1099 - val_acc: 1.0000\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1350 - acc: 0.9518 - val_loss: 0.1113 - val_acc: 1.0000\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1356 - acc: 0.9518 - val_loss: 0.1043 - val_acc: 1.0000\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1314 - acc: 0.9518 - val_loss: 0.1015 - val_acc: 1.0000\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1334 - acc: 0.9398 - val_loss: 0.0978 - val_acc: 1.0000\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1320 - acc: 0.9518 - val_loss: 0.0984 - val_acc: 1.0000\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1356 - acc: 0.9518 - val_loss: 0.1036 - val_acc: 1.0000\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1301 - acc: 0.9518 - val_loss: 0.1005 - val_acc: 1.0000\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1294 - acc: 0.9518 - val_loss: 0.0964 - val_acc: 1.0000\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1308 - acc: 0.9518 - val_loss: 0.0955 - val_acc: 1.0000\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1312 - acc: 0.9518 - val_loss: 0.0948 - val_acc: 1.0000\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1288 - acc: 0.9398 - val_loss: 0.0992 - val_acc: 1.0000\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1284 - acc: 0.9518 - val_loss: 0.1011 - val_acc: 1.0000\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1291 - acc: 0.9518 - val_loss: 0.1046 - val_acc: 1.0000\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1305 - acc: 0.9518 - val_loss: 0.1007 - val_acc: 1.0000\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1274 - acc: 0.9518 - val_loss: 0.0946 - val_acc: 1.0000\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1283 - acc: 0.9518 - val_loss: 0.0913 - val_acc: 1.0000\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1272 - acc: 0.9639 - val_loss: 0.0923 - val_acc: 1.0000\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1263 - acc: 0.9518 - val_loss: 0.0942 - val_acc: 1.0000\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1265 - acc: 0.9518 - val_loss: 0.0967 - val_acc: 1.0000\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1265 - acc: 0.9518 - val_loss: 0.0950 - val_acc: 1.0000\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1257 - acc: 0.9518 - val_loss: 0.0947 - val_acc: 1.0000\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1248 - acc: 0.9518 - val_loss: 0.0910 - val_acc: 1.0000\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1244 - acc: 0.9518 - val_loss: 0.0889 - val_acc: 1.0000\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1247 - acc: 0.9639 - val_loss: 0.0886 - val_acc: 1.0000\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1242 - acc: 0.9518 - val_loss: 0.0910 - val_acc: 1.0000\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1246 - acc: 0.9518 - val_loss: 0.0929 - val_acc: 1.0000\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1237 - acc: 0.9518 - val_loss: 0.0897 - val_acc: 1.0000\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1240 - acc: 0.9518 - val_loss: 0.0871 - val_acc: 1.0000\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1224 - acc: 0.9518 - val_loss: 0.0871 - val_acc: 1.0000\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1220 - acc: 0.9518 - val_loss: 0.0877 - val_acc: 1.0000\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1231 - acc: 0.9518 - val_loss: 0.0894 - val_acc: 1.0000\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1226 - acc: 0.9518 - val_loss: 0.0870 - val_acc: 1.0000\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1214 - acc: 0.9518 - val_loss: 0.0877 - val_acc: 1.0000\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1210 - acc: 0.9518 - val_loss: 0.0862 - val_acc: 1.0000\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1207 - acc: 0.9518 - val_loss: 0.0850 - val_acc: 1.0000\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1206 - acc: 0.9518 - val_loss: 0.0852 - val_acc: 1.0000\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1206 - acc: 0.9518 - val_loss: 0.0847 - val_acc: 1.0000\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1199 - acc: 0.9518 - val_loss: 0.0825 - val_acc: 1.0000\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1213 - acc: 0.9518 - val_loss: 0.0825 - val_acc: 1.0000\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1198 - acc: 0.9518 - val_loss: 0.0813 - val_acc: 1.0000\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1205 - acc: 0.9639 - val_loss: 0.0814 - val_acc: 1.0000\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1206 - acc: 0.9518 - val_loss: 0.0848 - val_acc: 1.0000\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1191 - acc: 0.9518 - val_loss: 0.0842 - val_acc: 1.0000\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1193 - acc: 0.9518 - val_loss: 0.0844 - val_acc: 1.0000\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1179 - acc: 0.9518 - val_loss: 0.0815 - val_acc: 1.0000\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1180 - acc: 0.9518 - val_loss: 0.0791 - val_acc: 1.0000\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1186 - acc: 0.9518 - val_loss: 0.0786 - val_acc: 1.0000\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1182 - acc: 0.9639 - val_loss: 0.0791 - val_acc: 1.0000\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1183 - acc: 0.9518 - val_loss: 0.0795 - val_acc: 1.0000\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1177 - acc: 0.9518 - val_loss: 0.0812 - val_acc: 1.0000\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1168 - acc: 0.9518 - val_loss: 0.0798 - val_acc: 1.0000\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1159 - acc: 0.9518 - val_loss: 0.0768 - val_acc: 1.0000\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1169 - acc: 0.9398 - val_loss: 0.0754 - val_acc: 1.0000\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1168 - acc: 0.9639 - val_loss: 0.0763 - val_acc: 1.0000\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1152 - acc: 0.9518 - val_loss: 0.0777 - val_acc: 1.0000\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1154 - acc: 0.9518 - val_loss: 0.0796 - val_acc: 1.0000\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1161 - acc: 0.9518 - val_loss: 0.0779 - val_acc: 1.0000\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1149 - acc: 0.9518 - val_loss: 0.0776 - val_acc: 1.0000\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1149 - acc: 0.9518 - val_loss: 0.0755 - val_acc: 1.0000\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1151 - acc: 0.9518 - val_loss: 0.0739 - val_acc: 1.0000\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0973 - acc: 0.968 - 0s 10ms/step - loss: 0.1155 - acc: 0.9639 - val_loss: 0.0740 - val_acc: 1.0000\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1134 - acc: 0.9518 - val_loss: 0.0764 - val_acc: 1.0000\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1171 - acc: 0.9518 - val_loss: 0.0791 - val_acc: 1.0000\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1141 - acc: 0.9518 - val_loss: 0.0750 - val_acc: 1.0000\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1128 - acc: 0.9518 - val_loss: 0.0727 - val_acc: 1.0000\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1154 - acc: 0.9518 - val_loss: 0.0714 - val_acc: 1.0000\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1145 - acc: 0.9518 - val_loss: 0.0721 - val_acc: 1.0000\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1141 - acc: 0.9518 - val_loss: 0.0763 - val_acc: 1.0000\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1134 - acc: 0.9518 - val_loss: 0.0773 - val_acc: 1.0000\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1131 - acc: 0.9518 - val_loss: 0.0739 - val_acc: 1.0000\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1117 - acc: 0.9518 - val_loss: 0.0722 - val_acc: 1.0000\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1111 - acc: 0.9518 - val_loss: 0.0704 - val_acc: 1.0000\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1126 - acc: 0.9518 - val_loss: 0.0694 - val_acc: 1.0000\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1132 - acc: 0.9518 - val_loss: 0.0699 - val_acc: 1.0000\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1120 - acc: 0.9518 - val_loss: 0.0719 - val_acc: 1.0000\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1135 - acc: 0.9518 - val_loss: 0.0732 - val_acc: 1.0000\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1114 - acc: 0.9518 - val_loss: 0.0710 - val_acc: 1.0000\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1105 - acc: 0.9518 - val_loss: 0.0696 - val_acc: 1.0000\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1128 - acc: 0.9398 - val_loss: 0.0680 - val_acc: 1.0000\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1112 - acc: 0.9518 - val_loss: 0.0695 - val_acc: 1.0000\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1103 - acc: 0.9518 - val_loss: 0.0705 - val_acc: 1.0000\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1102 - acc: 0.9518 - val_loss: 0.0700 - val_acc: 1.0000\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1094 - acc: 0.9518 - val_loss: 0.0681 - val_acc: 1.0000\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1101 - acc: 0.9518 - val_loss: 0.0675 - val_acc: 1.0000\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1091 - acc: 0.9518 - val_loss: 0.0685 - val_acc: 1.0000\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1092 - acc: 0.9518 - val_loss: 0.0705 - val_acc: 1.0000\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1096 - acc: 0.9518 - val_loss: 0.0710 - val_acc: 1.0000\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1109 - acc: 0.9518 - val_loss: 0.0679 - val_acc: 1.0000\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1106 - acc: 0.9518 - val_loss: 0.0672 - val_acc: 1.0000\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1071 - acc: 0.9518 - val_loss: 0.0699 - val_acc: 1.0000\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1080 - acc: 0.9518 - val_loss: 0.0722 - val_acc: 1.0000\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1098 - acc: 0.9639 - val_loss: 0.0720 - val_acc: 1.0000\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1092 - acc: 0.9639 - val_loss: 0.0696 - val_acc: 1.0000\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1080 - acc: 0.9518 - val_loss: 0.0665 - val_acc: 1.0000\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1072 - acc: 0.9518 - val_loss: 0.0652 - val_acc: 1.0000\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1072 - acc: 0.9518 - val_loss: 0.0650 - val_acc: 1.0000\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1084 - acc: 0.9518 - val_loss: 0.0652 - val_acc: 1.0000\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1068 - acc: 0.9518 - val_loss: 0.0645 - val_acc: 1.0000\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1080 - acc: 0.9639 - val_loss: 0.0644 - val_acc: 1.0000\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1087 - acc: 0.9518 - val_loss: 0.0669 - val_acc: 1.0000\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1091 - acc: 0.9518 - val_loss: 0.0653 - val_acc: 1.0000\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1076 - acc: 0.9518 - val_loss: 0.0679 - val_acc: 1.0000\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1073 - acc: 0.9518 - val_loss: 0.0666 - val_acc: 1.0000\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1061 - acc: 0.9518 - val_loss: 0.0630 - val_acc: 1.0000\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1074 - acc: 0.9639 - val_loss: 0.0618 - val_acc: 1.0000\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1067 - acc: 0.9518 - val_loss: 0.0618 - val_acc: 1.0000\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1057 - acc: 0.9518 - val_loss: 0.0633 - val_acc: 1.0000\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1092 - acc: 0.9518 - val_loss: 0.0659 - val_acc: 1.0000\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1060 - acc: 0.9518 - val_loss: 0.0649 - val_acc: 1.0000\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1070 - acc: 0.9518 - val_loss: 0.0617 - val_acc: 1.0000\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1047 - acc: 0.9518 - val_loss: 0.0617 - val_acc: 1.0000\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1049 - acc: 0.9518 - val_loss: 0.0619 - val_acc: 1.0000\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1046 - acc: 0.9518 - val_loss: 0.0622 - val_acc: 1.0000\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1038 - acc: 0.9518 - val_loss: 0.0641 - val_acc: 1.0000\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1046 - acc: 0.9518 - val_loss: 0.0644 - val_acc: 1.0000\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1062 - acc: 0.9518 - val_loss: 0.0644 - val_acc: 1.0000\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1048 - acc: 0.9518 - val_loss: 0.0605 - val_acc: 1.0000\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1040 - acc: 0.9518 - val_loss: 0.0596 - val_acc: 1.0000\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1047 - acc: 0.9518 - val_loss: 0.0596 - val_acc: 1.0000\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1042 - acc: 0.9639 - val_loss: 0.0603 - val_acc: 1.0000\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1037 - acc: 0.9518 - val_loss: 0.0609 - val_acc: 1.0000\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1029 - acc: 0.9518 - val_loss: 0.0616 - val_acc: 1.0000\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1033 - acc: 0.9518 - val_loss: 0.0615 - val_acc: 1.0000\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1025 - acc: 0.9518 - val_loss: 0.0596 - val_acc: 1.0000\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1027 - acc: 0.9518 - val_loss: 0.0589 - val_acc: 1.0000\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1026 - acc: 0.9518 - val_loss: 0.0585 - val_acc: 1.0000\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1026 - acc: 0.9518 - val_loss: 0.0583 - val_acc: 1.0000\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1045 - acc: 0.9518 - val_loss: 0.0597 - val_acc: 1.0000\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1019 - acc: 0.9518 - val_loss: 0.0587 - val_acc: 1.0000\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1047 - acc: 0.9518 - val_loss: 0.0573 - val_acc: 1.0000\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1016 - acc: 0.9518 - val_loss: 0.0583 - val_acc: 1.0000\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1010 - acc: 0.9518 - val_loss: 0.0600 - val_acc: 1.0000\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1025 - acc: 0.9518 - val_loss: 0.0614 - val_acc: 1.0000\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1048 - acc: 0.9518 - val_loss: 0.0620 - val_acc: 1.0000\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1030 - acc: 0.9518 - val_loss: 0.0584 - val_acc: 1.0000\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1011 - acc: 0.9518 - val_loss: 0.0565 - val_acc: 1.0000\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1018 - acc: 0.9518 - val_loss: 0.0560 - val_acc: 1.0000\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1010 - acc: 0.9518 - val_loss: 0.0566 - val_acc: 1.0000\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1012 - acc: 0.9518 - val_loss: 0.0591 - val_acc: 1.0000\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1018 - acc: 0.9518 - val_loss: 0.0604 - val_acc: 1.0000\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1038 - acc: 0.9518 - val_loss: 0.0573 - val_acc: 1.0000\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1002 - acc: 0.9518 - val_loss: 0.0567 - val_acc: 1.0000\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.1011 - acc: 0.9518 - val_loss: 0.0556 - val_acc: 1.0000\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0999 - acc: 0.9518 - val_loss: 0.0556 - val_acc: 1.0000\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1014 - acc: 0.9518 - val_loss: 0.0551 - val_acc: 1.0000\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1011 - acc: 0.9518 - val_loss: 0.0567 - val_acc: 1.0000\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1004 - acc: 0.9518 - val_loss: 0.0555 - val_acc: 1.0000\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1000 - acc: 0.9518 - val_loss: 0.0550 - val_acc: 1.0000\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0996 - acc: 0.9518 - val_loss: 0.0550 - val_acc: 1.0000\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1000 - acc: 0.9518 - val_loss: 0.0554 - val_acc: 1.0000\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0991 - acc: 0.9518 - val_loss: 0.0545 - val_acc: 1.0000\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0989 - acc: 0.9518 - val_loss: 0.0539 - val_acc: 1.0000\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0989 - acc: 0.9518 - val_loss: 0.0538 - val_acc: 1.0000\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0991 - acc: 0.9518 - val_loss: 0.0534 - val_acc: 1.0000\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0991 - acc: 0.9518 - val_loss: 0.0539 - val_acc: 1.0000\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0984 - acc: 0.9518 - val_loss: 0.0538 - val_acc: 1.0000\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0984 - acc: 0.9518 - val_loss: 0.0538 - val_acc: 1.0000\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0984 - acc: 0.9518 - val_loss: 0.0544 - val_acc: 1.0000\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0988 - acc: 0.9518 - val_loss: 0.0546 - val_acc: 1.0000\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0982 - acc: 0.9518 - val_loss: 0.0547 - val_acc: 1.0000\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0982 - acc: 0.9518 - val_loss: 0.0544 - val_acc: 1.0000\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0980 - acc: 0.9518 - val_loss: 0.0537 - val_acc: 1.0000\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0997 - acc: 0.9518 - val_loss: 0.0525 - val_acc: 1.0000\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0976 - acc: 0.9518 - val_loss: 0.0532 - val_acc: 1.0000\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0974 - acc: 0.9518 - val_loss: 0.0535 - val_acc: 1.0000\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0983 - acc: 0.9518 - val_loss: 0.0537 - val_acc: 1.0000\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0980 - acc: 0.9518 - val_loss: 0.0548 - val_acc: 1.0000\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0994 - acc: 0.968 - 0s 23ms/step - loss: 0.0991 - acc: 0.9518 - val_loss: 0.0541 - val_acc: 1.0000\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0973 - acc: 0.9518 - val_loss: 0.0522 - val_acc: 1.0000\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0976 - acc: 0.9518 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0977 - acc: 0.9639 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0971 - acc: 0.9518 - val_loss: 0.0517 - val_acc: 1.0000\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1009 - acc: 0.9518 - val_loss: 0.0536 - val_acc: 1.0000\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0976 - acc: 0.9518 - val_loss: 0.0520 - val_acc: 1.0000\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0963 - acc: 0.9518 - val_loss: 0.0506 - val_acc: 1.0000\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0966 - acc: 0.9518 - val_loss: 0.0504 - val_acc: 1.0000\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0967 - acc: 0.9518 - val_loss: 0.0505 - val_acc: 1.0000\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0958 - acc: 0.9518 - val_loss: 0.0514 - val_acc: 1.0000\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0962 - acc: 0.9518 - val_loss: 0.0535 - val_acc: 1.0000\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0974 - acc: 0.9518 - val_loss: 0.0533 - val_acc: 1.0000\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0964 - acc: 0.9518 - val_loss: 0.0513 - val_acc: 1.0000\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0948 - acc: 0.9518 - val_loss: 0.0496 - val_acc: 1.0000\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0993 - acc: 0.9518 - val_loss: 0.0494 - val_acc: 1.0000\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0990 - acc: 0.9518 - val_loss: 0.0493 - val_acc: 1.0000\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0980 - acc: 0.9518 - val_loss: 0.0502 - val_acc: 1.0000\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0955 - acc: 0.9518 - val_loss: 0.0512 - val_acc: 1.0000\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0954 - acc: 0.9518 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0977 - acc: 0.9518 - val_loss: 0.0500 - val_acc: 1.0000\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0953 - acc: 0.9518 - val_loss: 0.0502 - val_acc: 1.0000\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0955 - acc: 0.9518 - val_loss: 0.0495 - val_acc: 1.0000\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0948 - acc: 0.9518 - val_loss: 0.0494 - val_acc: 1.0000\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0950 - acc: 0.9518 - val_loss: 0.0496 - val_acc: 1.0000\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0948 - acc: 0.9518 - val_loss: 0.0493 - val_acc: 1.0000\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0952 - acc: 0.9518 - val_loss: 0.0484 - val_acc: 1.0000\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0946 - acc: 0.9518 - val_loss: 0.0483 - val_acc: 1.0000\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0949 - acc: 0.9518 - val_loss: 0.0484 - val_acc: 1.0000\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0942 - acc: 0.9518 - val_loss: 0.0481 - val_acc: 1.0000\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0950 - acc: 0.9518 - val_loss: 0.0484 - val_acc: 1.0000\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0944 - acc: 0.9518 - val_loss: 0.0485 - val_acc: 1.0000\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0942 - acc: 0.9518 - val_loss: 0.0477 - val_acc: 1.0000\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0954 - acc: 0.9518 - val_loss: 0.0475 - val_acc: 1.0000\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0939 - acc: 0.9518 - val_loss: 0.0477 - val_acc: 1.0000\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0941 - acc: 0.9518 - val_loss: 0.0482 - val_acc: 1.0000\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0941 - acc: 0.9518 - val_loss: 0.0488 - val_acc: 1.0000\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0940 - acc: 0.9518 - val_loss: 0.0487 - val_acc: 1.0000\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0935 - acc: 0.9518 - val_loss: 0.0477 - val_acc: 1.0000\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0938 - acc: 0.9518 - val_loss: 0.0472 - val_acc: 1.0000\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0939 - acc: 0.9639 - val_loss: 0.0465 - val_acc: 1.0000\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0962 - acc: 0.9518 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0960 - acc: 0.9639 - val_loss: 0.0468 - val_acc: 1.0000\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0925 - acc: 0.9518 - val_loss: 0.0481 - val_acc: 1.0000\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0939 - acc: 0.9518 - val_loss: 0.0495 - val_acc: 1.0000\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0941 - acc: 0.9518 - val_loss: 0.0484 - val_acc: 1.0000\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0941 - acc: 0.9518 - val_loss: 0.0469 - val_acc: 1.0000\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0932 - acc: 0.9518 - val_loss: 0.0464 - val_acc: 1.0000\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0927 - acc: 0.9518 - val_loss: 0.0467 - val_acc: 1.0000\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0926 - acc: 0.9518 - val_loss: 0.0470 - val_acc: 1.0000\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0942 - acc: 0.9518 - val_loss: 0.0463 - val_acc: 1.0000\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0927 - acc: 0.9518 - val_loss: 0.0469 - val_acc: 1.0000\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0925 - acc: 0.9518 - val_loss: 0.0467 - val_acc: 1.0000\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0939 - acc: 0.9518 - val_loss: 0.0457 - val_acc: 1.0000\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0930 - acc: 0.9518 - val_loss: 0.0457 - val_acc: 1.0000\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0922 - acc: 0.9518 - val_loss: 0.0468 - val_acc: 1.0000\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0923 - acc: 0.9518 - val_loss: 0.0469 - val_acc: 1.0000\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0932 - acc: 0.9518 - val_loss: 0.0473 - val_acc: 1.0000\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0920 - acc: 0.9518 - val_loss: 0.0456 - val_acc: 1.0000\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0915 - acc: 0.9518 - val_loss: 0.0449 - val_acc: 1.0000\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0925 - acc: 0.9518 - val_loss: 0.0444 - val_acc: 1.0000\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0933 - acc: 0.9518 - val_loss: 0.0443 - val_acc: 1.0000\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0921 - acc: 0.9518 - val_loss: 0.0448 - val_acc: 1.0000\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0909 - acc: 0.9518 - val_loss: 0.0459 - val_acc: 1.0000\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0917 - acc: 0.9518 - val_loss: 0.0475 - val_acc: 1.0000\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0934 - acc: 0.9518 - val_loss: 0.0470 - val_acc: 1.0000\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0921 - acc: 0.9518 - val_loss: 0.0448 - val_acc: 1.0000\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0920 - acc: 0.9518 - val_loss: 0.0436 - val_acc: 1.0000\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0929 - acc: 0.9639 - val_loss: 0.0435 - val_acc: 1.0000\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0927 - acc: 0.9398 - val_loss: 0.0446 - val_acc: 1.0000\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0906 - acc: 0.9518 - val_loss: 0.0458 - val_acc: 1.0000\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0914 - acc: 0.9518 - val_loss: 0.0468 - val_acc: 1.0000\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0924 - acc: 0.9518 - val_loss: 0.0469 - val_acc: 1.0000\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0927 - acc: 0.9518 - val_loss: 0.0452 - val_acc: 1.0000\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0907 - acc: 0.9518 - val_loss: 0.0443 - val_acc: 1.0000\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0901 - acc: 0.9518 - val_loss: 0.0436 - val_acc: 1.0000\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0911 - acc: 0.9518 - val_loss: 0.0434 - val_acc: 1.0000\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0911 - acc: 0.9639 - val_loss: 0.0433 - val_acc: 1.0000\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0924 - acc: 0.9518 - val_loss: 0.0432 - val_acc: 1.0000\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0920 - acc: 0.9518 - val_loss: 0.0437 - val_acc: 1.0000\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0903 - acc: 0.9518 - val_loss: 0.0437 - val_acc: 1.0000\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0905 - acc: 0.9518 - val_loss: 0.0442 - val_acc: 1.0000\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0915 - acc: 0.9518 - val_loss: 0.0441 - val_acc: 1.0000\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0898 - acc: 0.9518 - val_loss: 0.0430 - val_acc: 1.0000\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0895 - acc: 0.9518 - val_loss: 0.0424 - val_acc: 1.0000\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0904 - acc: 0.9398 - val_loss: 0.0421 - val_acc: 1.0000\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0912 - acc: 0.9518 - val_loss: 0.0422 - val_acc: 1.0000\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0903 - acc: 0.9518 - val_loss: 0.0424 - val_acc: 1.0000\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0924 - acc: 0.9518 - val_loss: 0.0419 - val_acc: 1.0000\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0903 - acc: 0.9518 - val_loss: 0.0431 - val_acc: 1.0000\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0907 - acc: 0.9518 - val_loss: 0.0431 - val_acc: 1.0000\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0901 - acc: 0.9518 - val_loss: 0.0416 - val_acc: 1.0000\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0901 - acc: 0.9518 - val_loss: 0.0413 - val_acc: 1.0000\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0894 - acc: 0.9518 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0894 - acc: 0.9518 - val_loss: 0.0414 - val_acc: 1.0000\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0918 - acc: 0.9518 - val_loss: 0.0419 - val_acc: 1.0000\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0896 - acc: 0.9518 - val_loss: 0.0408 - val_acc: 1.0000\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0898 - acc: 0.9518 - val_loss: 0.0407 - val_acc: 1.0000\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0892 - acc: 0.9639 - val_loss: 0.0409 - val_acc: 1.0000\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0895 - acc: 0.9518 - val_loss: 0.0420 - val_acc: 1.0000\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0897 - acc: 0.9518 - val_loss: 0.0416 - val_acc: 1.0000\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0889 - acc: 0.9518 - val_loss: 0.0414 - val_acc: 1.0000\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0917 - acc: 0.9518 - val_loss: 0.0406 - val_acc: 1.0000\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0900 - acc: 0.9518 - val_loss: 0.0417 - val_acc: 1.0000\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0892 - acc: 0.9518 - val_loss: 0.0414 - val_acc: 1.0000\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0891 - acc: 0.9518 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0885 - acc: 0.9518 - val_loss: 0.0411 - val_acc: 1.0000\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0884 - acc: 0.9518 - val_loss: 0.0410 - val_acc: 1.0000\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0897 - acc: 0.9518 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0877 - acc: 0.9518 - val_loss: 0.0404 - val_acc: 1.0000\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0892 - acc: 0.9398 - val_loss: 0.0401 - val_acc: 1.0000\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0892 - acc: 0.9518 - val_loss: 0.0402 - val_acc: 1.0000\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0884 - acc: 0.9518 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0885 - acc: 0.9518 - val_loss: 0.0418 - val_acc: 1.0000\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0892 - acc: 0.9518 - val_loss: 0.0413 - val_acc: 1.0000\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0873 - acc: 0.9518 - val_loss: 0.0399 - val_acc: 1.0000\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0898 - acc: 0.9518 - val_loss: 0.0397 - val_acc: 1.0000\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0887 - acc: 0.9518 - val_loss: 0.0397 - val_acc: 1.0000\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0886 - acc: 0.9518 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0885 - acc: 0.9518 - val_loss: 0.0416 - val_acc: 1.0000\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0899 - acc: 0.9518 - val_loss: 0.0411 - val_acc: 1.0000\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0875 - acc: 0.9518 - val_loss: 0.0394 - val_acc: 1.0000\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0890 - acc: 0.9639 - val_loss: 0.0395 - val_acc: 1.0000\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0932 - acc: 0.9639 - val_loss: 0.0391 - val_acc: 1.0000\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0917 - acc: 0.9639 - val_loss: 0.0409 - val_acc: 1.0000\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0889 - acc: 0.9518 - val_loss: 0.0423 - val_acc: 1.0000\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0899 - acc: 0.9518 - val_loss: 0.0409 - val_acc: 1.0000\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0882 - acc: 0.9518 - val_loss: 0.0394 - val_acc: 1.0000\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0874 - acc: 0.9518 - val_loss: 0.0388 - val_acc: 1.0000\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0884 - acc: 0.9518 - val_loss: 0.0386 - val_acc: 1.0000\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0869 - acc: 0.9518 - val_loss: 0.0389 - val_acc: 1.0000\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0864 - acc: 0.9518 - val_loss: 0.0397 - val_acc: 1.0000\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0884 - acc: 0.9518 - val_loss: 0.0403 - val_acc: 1.0000\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0883 - acc: 0.9518 - val_loss: 0.0389 - val_acc: 1.0000\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0870 - acc: 0.9518 - val_loss: 0.0384 - val_acc: 1.0000\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0866 - acc: 0.9518 - val_loss: 0.0383 - val_acc: 1.0000\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0867 - acc: 0.9518 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0867 - acc: 0.9518 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0871 - acc: 0.9518 - val_loss: 0.0383 - val_acc: 1.0000\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0884 - acc: 0.9518 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0877 - acc: 0.9518 - val_loss: 0.0376 - val_acc: 1.0000\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0872 - acc: 0.9518 - val_loss: 0.0376 - val_acc: 1.0000\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0862 - acc: 0.9518 - val_loss: 0.0378 - val_acc: 1.0000\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0878 - acc: 0.9518 - val_loss: 0.0383 - val_acc: 1.0000\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0861 - acc: 0.9518 - val_loss: 0.0376 - val_acc: 1.0000\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1020 - acc: 0.937 - 0s 12ms/step - loss: 0.0859 - acc: 0.9518 - val_loss: 0.0372 - val_acc: 1.0000\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0874 - acc: 0.9518 - val_loss: 0.0371 - val_acc: 1.0000\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0859 - acc: 0.9518 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0866 - acc: 0.9518 - val_loss: 0.0383 - val_acc: 1.0000\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0878 - acc: 0.9518 - val_loss: 0.0387 - val_acc: 1.0000\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0898 - acc: 0.9518 - val_loss: 0.0375 - val_acc: 1.0000\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0861 - acc: 0.9518 - val_loss: 0.0378 - val_acc: 1.0000\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0860 - acc: 0.9518 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0859 - acc: 0.9518 - val_loss: 0.0372 - val_acc: 1.0000\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0855 - acc: 0.9518 - val_loss: 0.0373 - val_acc: 1.0000\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0856 - acc: 0.9518 - val_loss: 0.0373 - val_acc: 1.0000\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0856 - acc: 0.9518 - val_loss: 0.0371 - val_acc: 1.0000\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0861 - acc: 0.9518 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0867 - acc: 0.9518 - val_loss: 0.0373 - val_acc: 1.0000\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0857 - acc: 0.9518 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0859 - acc: 0.9518 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0852 - acc: 0.9518 - val_loss: 0.0367 - val_acc: 1.0000\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0852 - acc: 0.9518 - val_loss: 0.0364 - val_acc: 1.0000\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0861 - acc: 0.9639 - val_loss: 0.0364 - val_acc: 1.0000\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0862 - acc: 0.9639 - val_loss: 0.0363 - val_acc: 1.0000\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0857 - acc: 0.9639 - val_loss: 0.0363 - val_acc: 1.0000\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0845 - acc: 0.9518 - val_loss: 0.0375 - val_acc: 1.0000\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0863 - acc: 0.9518 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0872 - acc: 0.9518 - val_loss: 0.0370 - val_acc: 1.0000\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0854 - acc: 0.9518 - val_loss: 0.0364 - val_acc: 1.0000\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0849 - acc: 0.9518 - val_loss: 0.0362 - val_acc: 1.0000\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0852 - acc: 0.9518 - val_loss: 0.0362 - val_acc: 1.0000\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0858 - acc: 0.9518 - val_loss: 0.0368 - val_acc: 1.0000\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0851 - acc: 0.9518 - val_loss: 0.0367 - val_acc: 1.0000\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0857 - acc: 0.9518 - val_loss: 0.0370 - val_acc: 1.0000\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0871 - acc: 0.9518 - val_loss: 0.0360 - val_acc: 1.0000\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0852 - acc: 0.9518 - val_loss: 0.0361 - val_acc: 1.0000\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0849 - acc: 0.9518 - val_loss: 0.0358 - val_acc: 1.0000\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0876 - acc: 0.9518 - val_loss: 0.0355 - val_acc: 1.0000\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0852 - acc: 0.9639 - val_loss: 0.0355 - val_acc: 1.0000\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0840 - acc: 0.9518 - val_loss: 0.0364 - val_acc: 1.0000\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0850 - acc: 0.9518 - val_loss: 0.0371 - val_acc: 1.0000\n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0864 - acc: 0.9518 - val_loss: 0.0368 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋이 준비되었으면 우리 Tensorflow Keras를 이용해서\n",
    "# Multinomial Classification을 구현하고\n",
    "# 모델 평가까지 진행해 보아요!\n",
    "\n",
    "# 모델의 정확도까지 출력해보세요!\n",
    "# 개별적으로 작성해 보세요!\n",
    "\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(4,)))\n",
    "keras_model.add(Dense(units=3,\n",
    "                      activation='softmax'))\n",
    "\n",
    "keras_model.compile(Adam(learning_rate=1e-1),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "# history객체에 각 epoch당 발생되는 loss, acc, val_loss, val_acc를 저장\n",
    "history = keras_model.fit(x_data_train_norm,\n",
    "                          t_data_train,\n",
    "                          epochs=500,\n",
    "                          verbose=1,\n",
    "                          validation_split=0.2)\n",
    "\n",
    "# learning_rate=1e-1\n",
    "# loss: 0.0847 - acc: 0.9518 - val_loss: 0.0288 - val_acc: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0647 - acc: 0.9778\n",
      "[0.06474079936742783, 0.9777777791023254]\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "print(keras_model.evaluate(x_data_test_norm,\n",
    "                           t_data_test))\n",
    "# [0.06694136559963226, 0.9555555582046509]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화를 해 보아요!\n",
    "# 우리 모델이 overfitting이 발생하는지 그래프로 확인!\n",
    "# history 객체가 가지고 있는 history 속성은 학습할 때 나온 데이터를 가지고 있어요\n",
    "# dict로 가지고 있어요!\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['loss'], color='r')\n",
    "plt.plot(history.history['val_loss'], color='b')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
